# 제6장. 복제 (Replication)

복제란 네트워크로 연결된 여러 장비에 동일한 데이터의 복사본을 유지하는 것을 의미합니다.

### 1. 복제를 사용하는 세 가지 주요 이유

단일 노드 시스템과 달리 분산 시스템에서 데이터를 복제하는 이유는 명확합니다.

- **지연 시간 감소(Latency)**: 전 세계 여러 지역에 데이터를 배치하여 사용자와 지리적으로 가까운 곳에서 응답을 제공합니다.
- **가용성 및 고가용성(Availability & Durability)**: 시스템의 일부 구성 요소가 고장 나더라도 전체 시스템은 계속 작동하도록 유지합니다.
- **읽기 처리량 증대(Read Throughput)**: 읽기 쿼리를 처리할 수 있는 장비의 수를 늘려 시스템을 확장(Scale-out)합니다.

### 2. 복제의 핵심 전제와 범위

- 이 장에서는 **전체 데이터셋이 각 장비에 들어갈 만큼 충분히 작다**고 가정합니다. (데이터셋이 너무 커서 나누어야 하는 '샤딩/파티셔닝'은 7장에서 다룹니다.)
- 데이터가 변하지 않는다면 복제는 쉽습니다(한 번 복사하면 끝). 복제의 모든 어려움은 **변하는 데이터(변경 사항)를 어떻게 다룰 것인가**에서 발생합니다.

### 3. 복제 알고리즘의 세 가지 유형

대부분의 분산 데이터베이스는 다음 세 가지 방식 중 하나를 사용합니다.

1.  **단일 리더(Single-leader)** 복제
2.  **다중 리더(Multi-leader)** 복제
3.  **리더 없는(Leaderless)** 복제

### 4. 주요 고려 사항 및 트레이드오프

복제를 설계하거나 사용할 때 선택해야 하는 중요한 옵션들이 있습니다.

- **동기(Synchronous) vs 비동기(Asynchronous)** 복제: 성능과 데이터 일관성 사이의 결정.
- **실패한 복제본 처리**: 노드가 다운되었을 때 어떻게 복구하고 다시 동기화할 것인가.
- **복제 지연(Replication Lag) 문제**: 비동기 복제에서 발생하는 일시적 불일치 문제를 해결하기 위한 보장들.
  - **자신이 쓴 내용 읽기(Read-your-writes)** 보장
  - **단조 읽기(Monotonic reads)** 보장

### 5. 백업 vs 복제 (중요한 차이점)

많은 사람이 혼동하지만, 복제는 백업을 대체할 수 없습니다.

- **목적의 차이**: 복제는 고가용성과 낮은 지연 시간을 위해 **현재** 데이터를 빠르게 전파하는 것이 목적입니다. 반면 백업은 **과거**의 특정 시점으로 되돌아가기 위한 스냅샷입니다.
- **실수의 전파**: 사용자가 실수로 데이터를 삭제하면 복제 시스템은 그 삭제 명령도 즉시 모든 복제본에 전달합니다. 이때 데이터를 살릴 수 있는 방법은 백업뿐입니다.
- **상호 보완적 관계**: 백업은 새로운 복제 노드를 설정할 때 초기 데이터를 제공하는 용도로 쓰이기도 하며, 복제 로그를 아카이빙하여 백업 프로세스의 일부로 사용하기도 합니다.

동기식(Synchronous)과 비동기식(Asynchronous) 복제 방식의 차이점, 장단점, 그리고 실무에서 사용되는 절충안에 대해 자세히 정리해 드립니다.

---

## 동기식 vs 비동기식 복제 (Synchronous vs Asynchronous)

복제 시스템에서 가장 중요한 설계 결정 중 하나는 복제가 **동기적으로 일어나는가, 비동기적으로 일어나는가**입니다. 이는 시스템의 **일관성(Consistency)**과 **가용성(Availability)** 사이의 핵심적인 트레이드오프를 결정합니다.

### 1. 동기식 복제 (Synchronous Replication)

- **작동 방식**: 리더가 모든 팔로워(또는 지정된 동기식 팔로워)가 복제본을 수신하고 기록했다는 확인(ACK)을 보낼 때까지 기다린 후, 클라이언트에게 성공을 응답합니다.
- **장점 (데이터 무결성)**:
  - 팔로워가 리더와 완전히 일치하는 최신 데이터 복사본을 가지고 있음을 보장합니다.
  - 리더가 갑자기 장애가 발생해도 데이터 유실 없이 팔로워를 통해 서비스를 계속할 수 있습니다.
- **단점 (가용성 저하)**:
  - 단 하나의 동기식 팔로워라도 응답하지 않으면(장애, 네트워크 지연 등) 리더는 모든 쓰기 작업을 차단하고 대기해야 합니다.
  - 시스템 전체의 가용성이 개별 노드의 상태에 직접적으로 의존하게 됩니다.

### 2. 비동기식 복제 (Asynchronous Replication)

- **작동 방식**: 리더가 메시지를 보내지만, 팔로워의 응답을 기다리지 않고 즉시 클라이언트에게 성공을 응답합니다.
- **장점 (성능 및 가용성)**:
  - 팔로워가 지연되거나 장애가 발생해도 리더는 중단 없이 쓰기 처리를 계속할 수 있습니다.
  - 지리적으로 멀리 떨어진 노드 간 복제에 유리합니다.
- **단점 (데이터 유실 위험)**:
  - 리더가 장애가 발생하고 복구 불가능할 때, 아직 팔로워에게 전달되지 못한 쓰기 데이터는 영구적으로 유실됩니다.
  - 클라이언트에게 성공 응답을 보냈음에도 불구하고 지속성(Durability)이 보장되지 않을 수 있습니다.

### 3. 실무적인 절충안: 반동기식 (Semi-synchronous)

모든 팔로워를 동기식으로 두는 것은 현실적으로 불가능합니다(노드 하나만 죽어도 전체 시스템 마비). 따라서 다음과 같은 전략을 주로 사용합니다.

- **반동기식 설정**: 팔로워 중 **하나만 동기식**으로 설정하고 나머지는 비동기식으로 운영합니다.
- **동적 전환**: 만약 동기식 팔로워가 느려지거나 장애가 발생하면, 비동기식 팔로워 중 하나를 동기식으로 승격시킵니다.
- **보장**: 이를 통해 최소한 두 노드(리더와 하나의 동기식 팔로워)에는 항상 최신 데이터가 존재함을 보장하면서도 가용성을 확보합니다.

### 4. 쿼럼(Quorum) 기반 복제

- 일부 시스템은 "전체"나 "하나"가 아닌 **과반수(Majority)**의 동의를 얻는 방식을 택합니다.
- 예: 5개의 복제본 중 3개(리더 포함)가 업데이트되면 성공으로 간주합니다.
- 이는 합의 알고리즘(Consensus Protocol)이나 최종 일관성(Eventual Consistency) 시스템에서 주로 사용됩니다.

### 요약 비교

| 특성            | 동기식 (Synchronous)              | 비동기식 (Asynchronous)               |
| :-------------- | :-------------------------------- | :------------------------------------ |
| **데이터 일치** | 리더와 팔로워가 항상 일치         | 팔로워가 리더보다 뒤처질 수 있음      |
| **내구성**      | 매우 높음 (장애 시 유실 없음)     | 낮음 (복제되지 않은 데이터 유실 가능) |
| **쓰기 지연**   | 높음 (팔로워 응답 대기 시간 포함) | 낮음 (즉시 응답)                      |
| **가용성**      | 팔로워 장애 시 쓰기 중단          | 팔로워 장애와 무관하게 쓰기 가능      |

새로운 팔로워를 설정하는 방법과 최근 클라우드 환경에서 주목받는 **객체 스토리지(Object Storage)** 기반의 데이터베이스 아키텍처에 대해 자세히 정리해 드립니다.

---

## 새로운 팔로워 설정하기 (Setting Up New Followers)

복제본의 수를 늘리거나 장애가 발생한 노드를 교체하기 위해 새로운 팔로워를 추가해야 할 때가 있습니다. 핵심은 **중단 시간(Downtime) 없이** 리더의 데이터를 정확하게 복사하는 것입니다.

### 1. 설정 프로세스 (4단계)

단순히 파일을 복사하는 것은 데이터가 계속 변하기 때문에 불가능합니다. 대신 다음 과정을 거칩니다.

1.  **일관된 스냅샷 생성**: 데이터베이스 전체에 락(Lock)을 걸지 않고 특정 시점의 일관된 스냅샷을 얻습니다. (대부분의 DB 내장 기능이나 Percona XtraBackup 같은 도구 활용)
2.  **스냅샷 복사**: 생성된 스냅샷을 새로운 팔로워 노드로 복사합니다.
3.  **변경 사항 요청(Catch-up)**: 팔로워가 리더에 연결하여 스냅샷 이후에 발생한 모든 데이터 변경 사항을 요청합니다. 이때 스냅샷은 리더의 복제 로그 내 **정확한 위치(Log Sequence Number, Binlog coordinates 등)**와 연결되어 있어야 합니다.
4.  **동기화 완료**: 팔로워가 백로그된 변경 사항을 모두 처리하면 리더를 실시간으로 따라잡게(Caught up) 됩니다.

---

## 객체 스토리지 기반 데이터베이스 (Databases Backed by Object Storage)

최근에는 S3, GCS 같은 객체 스토리지를 아카이빙 용도를 넘어 **라이브 쿼리용 주 저장소**로 사용하는 추세가 늘고 있습니다.

### 1. 객체 스토리지 사용의 장점

- **비용 효율성**: SSD나 NVMe보다 훨씬 저렴하여, 자주 사용하지 않는 데이터를 저렴하게 보관할 수 있습니다.
- **높은 내구성 및 가용성**: 클라우드 제공업체가 이미 멀티 존/리전 복제를 제공하므로 DB 레벨의 복제 부담이 줄어듭니다.
- **트랜잭션 및 리더 선출**: 객체 스토리지의 **조건부 쓰기(Conditional Write, CAS)** 기능을 활용해 분산 시스템의 복잡한 문제를 해결할 수 있습니다.
- **데이터 통합 용이성**: Parquet, Iceberg 같은 오픈 포맷을 사용하여 여러 DB의 데이터를 한곳에서 관리하기 쉽습니다.

### 2. 트레이드오프와 해결책

- **문제점**: 로컬 디스크보다 지연 시간(Latency)이 훨씬 높고, API 호출 비용이 발생하며, 객체가 불변(Immutable)이라 무작위 쓰기가 어렵습니다.
- **해결 전략**:
  - **계층형 스토리지(Tiered Storage)**: 최신/자주 쓰는 데이터는 SSD에, 오래된 데이터는 객체 스토리지에 배치.
  - **분리형 아키텍처**: 쓰기 로그(WAL)는 저지연 스토리지(EBS 등)에 저장하고, 전체 데이터는 객체 스토리지에 저장.
  - **제로 디스크 아키텍처(ZDA)**: 모든 영구 데이터를 객체 스토리지에 두고, 로컬 디스크와 메모리는 오직 **캐싱** 용도로만 사용합니다. (예: WarpStream, SlateDB, 현대적 클라우드 데이터 웨어하우스들)

노드 장애는 분산 시스템에서 피할 수 없는 일상적인 사건입니다. 시스템 전체의 가용성을 유지하면서 개별 노드의 장애 영향을 최소화하는 방법, 특히 **팔로워 장애**와 **리더 장애(장애 복구)** 처리 방식을 중심으로 정리해 드립니다.

---

## 노드 장애 처리 (Handling Node Outages)

리더 기반 복제 시스템에서 고가용성을 달성하기 위한 핵심 전략은 다음과 같습니다.

### 1. 팔로워 장애: 따라잡기 복구 (Catch-up Recovery)

팔로워 노드가 중단되었다가 재시작되거나 네트워크가 일시적으로 끊긴 경우의 처리입니다.

- **복구 방식**: 팔로워는 로컬 디스크에 보관된 로그를 통해 마지막으로 처리된 트랜잭션을 확인합니다. 이후 리더에 연결해 연결이 끊겼던 동안 발생한 모든 데이터 변경 사항을 요청하고 적용합니다.
- **도전 과제**:
  - 쓰기 처리량이 많거나 중단 시간이 길었던 경우, 리더와 팔로워 모두에게 큰 부하가 발생합니다.
  - **로그 보존 문제**: 리더는 모든 팔로워가 확인한 로그를 삭제할 수 있지만, 특정 팔로워가 너무 오래 중단되면 리더의 디스크 공간 부족을 초래할 수 있습니다. 이 경우 해당 팔로워는 로그만으로는 복구가 불가능하며 백업에서 다시 복원해야 할 수도 있습니다.

### 2. 리더 장애: 장애 복구 (Failover)

리더가 중단되면 팔로워 중 하나를 새로운 리더로 승격시키고, 클라이언트와 다른 팔로워들이 새 리더를 바라보도록 재설정해야 합니다. 이를 **장애 복구(Failover)**라고 합니다.

#### 자동 장애 복구 단계:

1.  **장애 감지**: 대부분 **타임아웃(Timeout)**을 사용합니다. 노드 간 주기적인 메시지(Heartbeat)를 주고받다가 일정 시간(예: 30초) 응답이 없으면 죽은 것으로 간주합니다.
2.  **새로운 리더 선출**: 남은 복제본들 사이의 선거(Election)나 제어 노드에 의해 결정됩니다. 데이터 유실을 최소화하기 위해 **가장 최신 데이터(가장 큰 로그 시퀀스 번호)**를 가진 팔로워를 선택하는 것이 이상적입니다.
3.  **시스템 재설정**: 클라이언트의 쓰기 요청을 새 리더로 라우팅하고, 구 리더가 복구되었을 때 자신이 더 이상 리더가 아님을 인지하고 팔로워로 강등되도록 보장해야 합니다.

### 3. 장애 복구 시 발생할 수 있는 위험 요소

장애 복구는 매우 까다로우며 다음과 같은 심각한 문제들을 야기할 수 있습니다.

- **데이터 유실**: 비동기 복제 환경에서 구 리더의 마지막 쓰기가 팔로워에게 전달되지 못한 채 죽었다면, 새 리더는 그 데이터를 알지 못합니다. 구 리더가 돌아왔을 때 충돌하는 쓰기 데이터는 보통 버려지게 되는데, 이는 클라이언트에게 성공 응답을 보낸 데이터가 사라짐을 의미합니다.
- **외부 시스템과의 불일치 (GitHub 사례)**: DB의 자동 증가(Auto-increment) PK가 새 리더에서 뒤처진 상태로 시작되어 기존에 사용된 ID를 재사용할 경우, Redis 같은 외부 캐시 시스템과 데이터가 꼬여 보안 사고(타인의 개인정보 노출 등)로 이어질 수 있습니다.
- **스플릿 브레인 (Split Brain)**: 두 노드가 동시에 자신을 리더로 믿는 현상입니다. 두 리더가 모두 쓰기를 허용하면 데이터 충돌과 오염이 발생합니다. 이를 방지하기 위해 한 리더를 강제로 종료시키는 **펜싱(Fencing)** 또는 **STONITH**(Shoot The Other Node In The Head) 기법이 사용됩니다.
- **타임아웃 설정의 딜레마**: 타임아웃이 너무 짧으면 일시적인 네트워크 부하에도 불필요한 장애 복구가 일어나 상황을 악화시키고, 너무 길면 시스템 복구 시간이 늘어납니다.

### 요약

이러한 위험성 때문에 많은 운영 팀은 소프트웨어가 자동 장애 복구를 지원하더라도 **수동 장애 복구**를 선호하기도 합니다. 가장 중요한 원칙은 **가장 최신 상태의 팔로워를 새 리더로 선택**하여 데이터 손실을 최소화하는 것입니다.

리더 기반 복제 시스템의 내부 작동 원리인 **복제 로그 구현 방식** 세 가지를 자세히 정리해 드립니다. (2판 내용을 바탕으로 5장 요약 파일에 이어서 작성합니다.)

---

## 복제 로그의 구현 (Implementation of Replication Logs)

리더에서 발생한 쓰기 작업을 팔로워로 전달하는 방식에는 여러 가지가 있으며, 각각의 방식은 성능, 호환성, 운영 편의성 측면에서 차이가 있습니다.

### 1. 구문 기반 복제 (Statement-based Replication)

가장 단순한 방식으로, 리더가 실행한 모든 **쓰기 요청(SQL 구문: INSERT, UPDATE, DELETE 등)**을 로그에 기록하고 팔로워로 보냅니다. 팔로워는 이 SQL을 마치 클라이언트로부터 직접 받은 것처럼 다시 실행합니다.

- **문제점 (비결정성)**:
  - `NOW()`(현재 시간)나 `RAND()`(랜덤 값) 같은 **비결정적 함수**를 호출하면 각 복제본마다 다른 값이 저장될 수 있습니다.
  - **자동 증가(Auto-increment)** 컬럼이나 기존 데이터에 의존하는 구문은 모든 복제본에서 **정확히 동일한 순서**로 실행되어야 합니다. 그렇지 않으면 결과가 달라질 수 있습니다.
  - 트리거, 저장 프로시저, 사용자 정의 함수(UDF) 등 부수 효과(Side effect)가 있는 구문은 복제본마다 다른 결과를 낼 위험이 큽니다.
- **현재 상황**: 과거 MySQL(5.1 이전)에서 사용되었으나, 현재는 비결정성이 감지되면 자동으로 아래의 행 기반 복제로 전환됩니다. VoltDB 등 일부 DB에서 결정성을 강제하여 사용하기도 합니다.

### 2. 쓰기 전해 로그 전송 (Write-ahead Log (WAL) Shipping)

저장 엔진(B-Tree 등)이 크래시 복구를 위해 작성하는 **저수준 물리적 로그(WAL)**를 그대로 팔로워에게 보내는 방식입니다.

- **작동 방식**: WAL에는 "어떤 디스크 블록의 몇 번째 바이트가 바뀌었는지"와 같은 매우 상세한 물리적 정보가 담겨 있습니다. 팔로워는 이 로그를 읽어 리더와 똑같은 디스크 구조를 가진 복사본을 구축합니다.
- **장점**: 구현이 비교적 간단하고 데이터 신뢰성이 높습니다. (PostgreSQL, Oracle 등에서 사용)
- **단점 (강한 결합)**:
  - 로그가 저장 엔진의 물리적 데이터 형식과 밀접하게 연결되어 있습니다.
  - **버전 불일치 문제**: 리더와 팔로워의 DB 소프트웨어 버전이 다르면(저장 형식이 바뀌면) 복제가 불가능합니다. 이로 인해 **중단 없는 업그레이드(Zero-downtime upgrade)**가 어렵습니다.

### 3. 논리적(행 기반) 로그 복제 (Logical (row-based) Log Replication)

저장 엔진의 내부 물리적 구현과 분리된 별도의 로그 형식을 사용하는 방식입니다. 이를 **논리적 로그**라고 하며, 보통 **행(Row)** 단위로 기록됩니다.

- **로그 기록 방식**:
  - **삽입(Insert)**: 새로 추가된 모든 컬럼의 값.
  - **삭제(Delete)**: 삭제된 행을 식별할 수 있는 정보(보통 PK).
  - **갱신(Update)**: 바뀐 행을 식별할 정보와 변경된 모든 컬럼의 새 값.
- **장점**:
  - **하위 호환성**: 저장 엔진과 분리되어 있어 리더와 팔로워가 서로 다른 버전의 소프트웨어를 실행할 수 있습니다. (무중단 업그레이드 가능)
  - **외부 애플리케이션 연동**: 외부 분석 시스템(데이터 웨어하우스)이나 캐시 시스템으로 데이터를 전송하기 쉽습니다. 이를 **변경 데이터 캡처(Change Data Capture, CDC)**라고 합니다.

---

### 요약 비교

| 방식                | 특징                       | 장점                         | 단점                      |
| :------------------ | :------------------------- | :--------------------------- | :------------------------ |
| **구문 기반**       | SQL 문 자체를 전송         | 로그 크기가 작고 효율적      | 비결정적 함수 처리 어려움 |
| **WAL 전송**        | 물리적 디스크 변경분 전송  | 저장 엔진 수준의 높은 신뢰성 | DB 버전 간 호환성 부족    |
| **논리적(행) 기반** | 행 단위 데이터 변경분 전송 | 버전 호환성 좋음, CDC 용이   | 로그 크기가 커질 수 있음  |

비동기 복제 방식에서 발생하는 **복제 지연(Replication Lag)** 문제와 이를 해결하기 위한 세 가지 주요 일관성 보장 모델에 대해 자세히 정리해 드립니다.

---

## 복제 지연 문제 (Problems with Replication Lag)

읽기 확장(Read-scaling) 아키텍처에서는 리더에게는 쓰기만, 팔로워에게는 읽기만 요청하여 부하를 분산합니다. 하지만 이 방식은 **비동기 복제**에서만 현실적으로 작동하며, 이로 인해 리더와 팔로워 사이의 데이터 불일치인 **복제 지연**이 발생합니다. 이는 결국 **최종 일관성(Eventual Consistency)** 상태를 야기합니다.

### 1. 자신이 쓴 내용 읽기 (Reading Your Own Writes)

사용자가 데이터를 입력(쓰기)한 직후 바로 조회(읽기)했을 때, 아직 복제가 완료되지 않은 팔로워에서 읽게 되면 방금 입력한 데이터가 사라진 것처럼 보이는 현상입니다.

- **해결책 (쓰기 후 읽기 일관성)**:
  - **사용자가 수정한 가능성이 있는 데이터는 리더에서 읽기**: 예를 들어, 자신의 프로필은 리더에서 읽고 타인의 프로필은 팔로워에서 읽습니다.
  - **시간 기반 규칙**: 마지막 업데이트 후 일정 시간(예: 1분) 동안은 모든 읽기를 리더에서 수행합니다.
  - **클라이언트 타임스탬프**: 클라이언트가 마지막 쓰기의 타임스탬프(또는 논리적 일련번호)를 기억하고, 해당 시점까지 반영된 팔로워에서만 읽도록 요청합니다.
  - **교차 디바이스 일관성**: 사용자가 여러 기기(PC, 모바일)를 사용할 경우, 메타데이터를 중앙 집중화하여 어떤 기기에서든 자신이 쓴 내용을 볼 수 있게 해야 합니다.

### 2. 단조 읽기 (Monotonic Reads)

사용자가 여러 번 읽기 요청을 보낼 때, 각 요청이 서로 다른 팔로워로 전달되면서 발생합니다. 최신 데이터를 가진 팔로워에서 읽었다가, 다음 새로고침 때 지연이 심한 팔로워에서 읽게 되면 **시간이 거꾸로 흐르는 것처럼** 데이터가 사라졌다 나타났다 하는 현상입니다.

- **해결책**:
  - **사용자 ID 해싱**: 특정 사용자의 모든 읽기 요청이 항상 동일한 복제본(팔로워)으로 전달되도록 보장합니다. (해당 팔로워 장애 시에만 재라우팅)

### 3. 일관된 접두사 읽기 (Consistent Prefix Reads)

데이터 간의 **인과 관계(Causality)**가 깨지는 문제입니다. 예를 들어 "질문"과 "답변"이 있을 때, 답변은 빨리 복제되고 질문은 늦게 복제되면 제3자는 질문도 없이 답변부터 나오는 상황을 보게 됩니다.

- **해결책**:
  - **인과 관계가 있는 데이터는 동일한 샤드에 저장**: 특히 파티셔닝(샤딩)된 데이터베이스에서 중요합니다.
  - **인과 관계 추적**: 알고리즘을 통해 쓰기 간의 의존성을 명시적으로 관리합니다.

---

## 복제 지연의 해결책 요약

복제 지연이 초 단위라면 문제가 없겠지만, 시스템 부하가 높을 때는 분 단위까지 늘어날 수 있습니다. 이를 해결하기 위해 애플리케이션 수준에서 복잡한 로직을 구현하는 대신, 다음과 같은 선택지를 고려할 수 있습니다.

1.  **강한 일관성 보장 DB 사용**: 선형성(Linearizability)이나 ACID 트랜잭션을 지원하는 DB(NewSQL 등)를 선택하여 복잡성을 DB 계층으로 넘깁니다.
2.  **애플리케이션 설계**: 복제 지연을 허용할 수 없는 특정 기능에 대해서만 리더 읽기를 강제하는 등 전략적으로 설계합니다.

---

다중 리더 복제(Multi-Leader Replication)의 정의, 지리적 분산 환경에서의 장점, 토폴로지의 종류 및 발생 가능한 문제점들을 자세히 정리해 드립니다.

---

## 다중 리더 복제 (Multi-Leader Replication)

단일 리더 방식의 가장 큰 단점은 모든 쓰기가 하나의 노드를 거쳐야 한다는 점입니다. 이를 확장하여 **둘 이상의 노드에서 쓰기 요청을 처리**할 수 있게 한 것이 다중 리더(Active/Active 또는 양방향 복제) 설정입니다. 각 리더는 동시에 다른 리더의 팔로워 역할을 수행합니다.

### 1. 지리적 분산 운영 (Geographically Distributed Operation)

다중 리더 설정이 가장 빛을 발하는 곳은 여러 지역(Region)에 데이터 센터가 흩어져 있는 환경입니다.

| 비교 항목          | 단일 리더 (Single-Leader)                                   | 다중 리더 (Multi-Leader)                                 |
| :----------------- | :---------------------------------------------------------- | :------------------------------------------------------- |
| **성능 (Latency)** | 모든 쓰기가 리더가 있는 지역으로 가야 하므로 지연 시간이 큼 | 사용자와 가까운 로컬 리더에서 즉시 처리 (응답 속도 빠름) |
| **중단 내성**      | 리더 지역 장애 시 다른 지역으로 장애 복구 필요              | 각 지역이 독립적으로 운영됨 (장애 지역만 영향)           |
| **네트워크 문제**  | 지역 간 네트워크 문제에 매우 민감 (쓰기 차단 가능)          | 비동기 복제로 네트워크 결함을 더 잘 견딤                 |
| **일관성**         | 강력한 일관성(직렬성 등) 보장 용이                          | 일관성이 매우 약함 (충돌 해결 필요)                      |

### 2. 복제 토폴로지 (Replication Topologies)

쓰기 변경 사항이 노드 간에 전달되는 경로를 **토폴로지**라고 합니다.

- **원형 토폴로지 (Circular)**: 각 노드가 한 노드로부터 쓰기를 전달받고, 자신의 변경 사항을 포함해 다음 노드로 전달합니다. (MySQL 기본값)
- **별 모양 토폴로지 (Star)**: 지정된 루트 노드가 모든 노드에 쓰기를 전달합니다.
- **전체 연결 토폴로지 (All-to-all)**: 모든 리더가 서로에게 쓰기를 보냅니다. 가장 일반적이고 결함 내성이 높습니다.

> **루프 방지**: 원형/별 토폴로지에서는 무한 루프를 막기 위해 로그에 각 노드의 고유 식별자를 태깅하여, 자신이 이미 처리한 변경 사항은 무시하도록 설계합니다.

### 3. 토폴로지의 문제점과 인과성 (Causality)

- **단일 장애점 (Single Point of Failure)**: 원형이나 별 토폴로지는 중간 노드 하나만 고장 나도 전체 복제 흐름이 끊길 수 있습니다. 전체 연결 토폴로지는 이를 피할 수 있지만 다른 문제가 있습니다.
- **쓰기 순서 뒤바뀜**: 네트워크 속도 차이로 인해 **삽입(Insert)보다 수정(Update)이 먼저 도착**하는 등의 인과성 문제가 발생할 수 있습니다.
  - 단순한 타임스탬프만으로는 해결이 어렵습니다 (시계 불일치 문제).
  - **버전 벡터(Version Vectors)** 같은 기술이 필요하지만, 많은 시스템에서 이를 완벽히 구현하지 못하는 경우가 많습니다.

### 4. 제약 사항

다중 리더 시스템에서는 **데이터 일관성(Consistency)** 확보가 매우 어렵습니다. 예를 들어, 서로 다른 리더에서 동일한 사용자 아이디로 가입하거나, 계좌 잔고가 마이너스가 되는 것을 막는 등의 전역 제약 조건을 실시간으로 검사하기 불가능합니다. 따라서 이러한 제약이 필수적인 서비스라면 단일 리더 방식을 권장합니다.

---

## 동기화 엔진과 로컬 우선 소프트웨어 (Sync Engines & Local-First)

다중 리더 복제는 서버 간의 통신뿐만 아니라, 오프라인 상태에서도 작동해야 하는 애플리케이션(캘린더, 메모 앱 등)이나 실시간 협업 도구(Google Docs, Figma 등)에서 필수적인 아키텍처입니다.

### 1. 오프라인 우선(Offline-first) 및 로컬 우선(Local-first)

- **작동 방식**: 사용자의 각 장치(폰, 노트북 등)는 로컬 DB를 가진 '리더' 역할을 하며, 온라인 상태가 될 때 다른 장치나 서버와 비동기적으로 동기화(Sync)합니다.
- **장점**:
  - **빠른 응답성**: 로컬 데이터에 즉시 쓰기 때문에 네트워크 지연 없이 16ms(60Hz) 이내의 빠른 UI 반응이 가능합니다.
  - **오프라인 작업**: 네트워크 연결이 불안정해도 중단 없이 작업할 수 있습니다.
  - **단순한 프로그래밍 모델**: 네트워크 실패 처리를 매번 할 필요 없이 로컬 DB에 읽고 쓰는 방식으로 개발할 수 있습니다.
- **한계**: 사용자가 접근해야 하는 데이터 양이 매우 방대할 경우(예: 이커머스 전체 카탈로그) 모든 데이터를 로컬에 저장하기 어렵습니다.

---

## 쓰기 충돌 처리 (Handling Write Conflicts)

다중 리더 복제의 가장 큰 과제는 서로 다른 리더에서 동일한 데이터를 동시에 수정할 때 발생하는 **쓰기 충돌**입니다.

### 1. 충돌 회피 (Conflict Avoidance)

가장 권장되는 전략으로, 특정 레코드에 대한 모든 쓰기를 항상 동일한 리더(지역)로 라우팅하는 방식입니다.

- 예: 특정 사용자의 데이터는 해당 사용자와 가까운 '홈 지역'의 리더에서만 처리하도록 고정합니다.
- 단점: 특정 지역 장애로 리더를 변경해야 하거나 사용자가 이동할 경우 회피 전략이 깨질 수 있습니다.

### 2. 최종 쓰기 승리 (Last Write Wins, LWW)

각 쓰기에 타임스탬프를 부여하고 가장 최신(큰 값)의 데이터를 선택하며 나머지는 버리는 방식입니다.

- **문제점**: 동시성 쓰기에서 '최신'의 기준은 모호하며, 데이터 유실이 발생합니다. 또한 시계 동기화 문제에 매우 민감합니다.

### 3. 수동 충돌 해결 (Manual Conflict Resolution)

Git처럼 충돌 발생 시 모든 버전(Siblings)을 저장해 두었다가, 나중에 사용자가 직접 고르게 하거나 애플리케이션 코드에서 병합 로직을 실행하는 방식입니다.

- **주의사항 (아마존 장바구니 사례)**: 단순히 데이터의 합집합으로 병합할 경우, 삭제한 상품이 다시 나타나는 등의 부작용이 발생할 수 있습니다.

### 4. 자동 충돌 해결 (Automatic Conflict Resolution)

데이터 타입에 특화된 알고리즘을 사용하여 충돌을 자동으로 병합하고 모든 복제본이 동일한 상태로 수렴하게 합니다. (**강한 최종 일관성**)

- **텍스트**: 삽입/삭제된 문자를 추적하여 병합.
- **컬렉션(할 일 목록 등)**: 항목의 추가/삭제 이력을 추적하여 병합.
- **카운터(좋아요 수 등)**: 각 리더에서 발생한 증가/감소분을 합산.
- **도구**: CRDT(Conflict-free Replicated Data Types)나 OT(Operational Transformation) 같은 기술이 사용됩니다.

---

자동 충돌 해결을 위한 두 가지 핵심 알고리즘 가문인 **CRDT**와 **OT**의 작동 방식과 충돌의 유형에 대해 정리해 드립니다.

---

## CRDT와 OT (자동 충돌 해결 알고리즘)

동시 쓰기를 자동으로 병합하여 모든 복제본이 동일한 상태로 수렴하게 만드는 두 가지 주요 설계 철학입니다.

### 1. OT (Operational Transformation, 운영 변환)

- **작동 방식**: 작업이 발생한 **인덱스(위치)**를 기록합니다. 다른 노드로부터 작업을 전달받았을 때, 이미 로컬에서 수행된 동시 작업들을 고려하여 해당 작업의 인덱스를 적절히 수정(변환)합니다.
- **예시 ("ice" -> "nice!")**:
  - A가 0번 인덱스에 'n' 삽입 ("nice")
  - B가 3번 인덱스에 '!' 삽입 ("ice!")
  - B의 작업을 A에게 적용할 때, 이미 'n'이 추가되어 인덱스가 밀렸으므로 '!'의 위치를 3에서 4로 변환하여 적용합니다.
- **특징**: 주로 Google Docs와 같은 **실시간 협업 텍스트 편집기**에서 널리 사용됩니다.

### 2. CRDT (Conflict-free Replicated Data Types)

- **작동 방식**: 인덱스 대신 각 데이터 요소(문자, 객체 등)에 **고유하고 불변하는 ID**를 부여합니다. 위치는 인덱스가 아닌 "어떤 ID 뒤에 삽입"과 같은 상대적 관계로 정의됩니다.
- **예시 ("ice" -> "nice!")**:
  - 'i'(ID: 1A), 'c'(ID: 2A), 'e'(ID: 3A)
  - A는 'i' 앞에 'n'(ID: 0A)을 삽입하라는 작업을 생성합니다.
  - B는 'e' 뒤에 '!'(ID: 4B)를 삽입하라는 작업을 생성합니다.
  - 각 노드는 인덱스 변환 없이 ID 간의 상대적 위치와 ID 값의 결정적 순서에 따라 병합합니다.
- **특징**: Redis Enterprise, Riak, Cosmos DB와 같은 **분산 데이터베이스**와 Automerge, Yjs 같은 동기화 엔진에서 주로 사용됩니다.

---

## 충돌의 유형 (Types of Conflict)

충돌은 단순히 같은 필드를 동시에 수정하는 것보다 더 미묘한 형태로 나타날 수 있습니다.

### 1. 명시적 충돌 (Obvious Conflicts)

- 동일한 레코드의 동일한 필드를 서로 다른 값으로 동시에 수정하는 경우입니다. (예: 문서 제목을 B와 C로 각각 수정)

### 2. 잠재적 충돌 (Subtle Conflicts)

- 개별적인 쓰기는 문제가 없으나, 전체적인 **비즈니스 로직(제약 조건)**을 위반하는 경우입니다.
- **회의실 예약 예시**: 두 사용자가 동시에 같은 회의실을 같은 시간에 예약하려 합니다. 각 사용자는 예약 전에 회의실이 비어 있음을 확인하고 각자의 예약 레코드를 '삽입'합니다. 데이터베이스 입장에서는 서로 다른 두 레코드를 추가하는 것이므로 물리적 충돌은 없지만, 실제로는 '중복 예약'이라는 논리적 충돌이 발생한 것입니다.

---

리더라는 개념을 버리고 모든 복제본이 직접 클라이언트의 쓰기 요청을 받을 수 있게 설계된 **리더 없는 복제(Leaderless Replication)** 방식에 대해 자세히 정리해 드립니다.

---

## 리더 없는 복제 (Leaderless Replication)

리더가 쓰기 순서를 결정하고 팔로워가 이를 따라가는 기존 방식과 달리, 모든 복제본이 동등하게 쓰기와 읽기 요청을 처리합니다. 아마존의 **Dynamo** 시스템 이후 Riak, Cassandra, ScyllaDB 등이 이 방식을 채택하여 **다이너모 스타일(Dynamo-style)**이라고도 불립니다.

### 1. 노드 장애 발생 시의 쓰기

리더 없는 복제 시스템에서는 장애 복구(Failover) 과정이 존재하지 않습니다.

- **작동 방식**: 클라이언트는 여러 복제본에 병렬로 쓰기 요청을 보냅니다. 일부 노드가 장애로 요청을 받지 못하더라도, 사전에 정해진 수(정족수) 이상의 노드가 승인하면 쓰기 성공으로 간주합니다.
- **오래된 데이터 문제**: 장애로 쓰기를 놓친 노드가 복구된 후 클라이언트가 해당 노드에서 데이터를 읽으면 과거의 값을 반환할 수 있습니다. 이를 해결하기 위해 읽기 요청도 여러 노드에 보내고, **버전 번호**를 확인해 가장 최신 데이터를 선택합니다.

### 2. 누락된 쓰기를 따라잡는 메커니즘

장애 복구 후 데이터의 일관성을 맞추기 위해 다음 세 가지 방식을 사용합니다.

1.  **읽기 복구 (Read Repair)**: 클라이언트가 여러 노드에서 데이터를 읽을 때 오래된 값을 발견하면, 해당 노드에 최신 값을 다시 써주는 방식입니다. 자주 읽히는 데이터에 효과적입니다.
2.  **힌트된 핸드오프 (Hinted Handoff)**: 특정 노드가 다운되었을 때 다른 노드가 대신 쓰기를 수락하고 '힌트'를 남겨둡니다. 이후 장애 노드가 복구되면 보관하던 쓰기 작업을 전달합니다.
3.  **안티 엔트로피 (Anti-entropy)**: 백그라운드 프로세스가 주기적으로 복제본 간의 차이를 비교하고 누락된 데이터를 복사합니다. 특정 순서 없이 진행되므로 지연이 발생할 수 있습니다.

### 3. 정족수(Quorums) 이론

쓰기와 읽기가 성공했다고 판단하는 최소 노드 수를 결정하는 공식입니다.

- $n$: 전체 복제본 수
- $w$: 쓰기 성공을 위해 필요한 최소 노드 수
- $r$: 읽기 성공을 위해 필요한 최소 노드 수
- **일관성 조건: $w + r > n$**
  - 이 조건이 만족되면, 읽기 요청을 보낸 $r$개의 노드 중 적어도 하나는 가장 최신 쓰기($w$)가 반영된 노드임이 보장됩니다.
  - 예: $n=3, w=2, r=2$ (노드 1개 장애 허용)
  - 예: $n=5, w=3, r=3$ (노드 2개 장애 허용)

### 4. 정족수 설정의 트레이드오프

애플리케이션의 특성에 따라 $w$와 $r$ 값을 조정하여 성능과 가용성을 조절할 수 있습니다.

- **읽기 위주**: $w=n, r=1$로 설정하면 읽기는 매우 빠르지만, 노드 하나만 죽어도 쓰기가 불가능해집니다.
- **가용성 중시**: 일반적으로 $n$을 홀수(3 또는 5)로 하고 $w = r = (n+1)/2$로 설정하여 과반수의 동의를 얻는 방식을 사용합니다.

---

## 정족수 일관성의 한계와 동시 쓰기 감지

정족수($w + r > n$)를 설정하더라도 실제 시스템에서는 여러 변수로 인해 최신 값을 읽지 못하는 상황이 발생할 수 있습니다. 이를 해결하기 위한 동시성 제어 기법과 함께 정리해 드립니다.

---

### 1. 정족수 일관성의 한계 (Limitations of Quorum Consistency)

수학적으로는 $w + r > n$일 때 쓰기 노드 집합과 읽기 노드 집합이 반드시 겹치므로 최신 데이터를 읽어야 하지만, 다음과 같은 예외 상황이 존재합니다.

- **느슨한 정족수 (Sloppy Quorum)**: 네트워크 장애 시 지정된 $n$개 노드가 아닌 다른 가용 노드에 쓰기를 허용하면($w$), 이후 읽기 정족수($r$)와 겹치지 않을 수 있습니다.
- **동시 읽기/쓰기**: 쓰기가 진행 중일 때 읽기가 수행되면, 일부 노드에는 반영되고 일부에는 반영되지 않아 읽기 결과가 불확실합니다.
- **쓰기 실패 후의 상태**: $w$개 미만의 노드에만 쓰기가 성공하여 전체적으로 '실패'를 반환했더라도, 이미 성공한 노드들의 데이터는 롤백되지 않습니다. 따라서 이후 읽기에서 실패한 쓰기 데이터가 보일 수도 있고 안 보일 수도 있습니다.
- **복구 시 데이터 유실**: 최신 값을 가진 노드가 죽고 오래된 데이터를 가진 노드로부터 복구되면, 최신 값을 가진 노드 수가 $w$ 미만으로 떨어져 정족수 조건이 깨질 수 있습니다.
- **시계 스큐 (Clock Skew)**: LWW(최종 쓰기 승리) 방식을 사용할 때, 노드 간 시계가 맞지 않으면 나중에 발생한 쓰기가 이전 쓰기로 간주되어 무시될 수 있습니다.

---

### 2. 리더 없는 복제 vs 리더 기반 복제

- **가용성**: 리더 없는 방식은 장애 복구(Failover) 과정이 없어 개별 노드의 지연이나 장애에 훨씬 강합니다. (**Request Hedging**을 통해 가장 빠른 응답을 사용 가능)
- **모니터링**: 리더 기반은 복제 로그의 오프셋 차이로 지연(Lag)을 쉽게 측정할 수 있지만, 리더 없는 방식은 쓰기 순서가 고정되지 않아 복제 지연을 수치화하기 어렵습니다.

---

### 3. 동시 쓰기 감지 (Detecting Concurrent Writes)

네트워크 지연이나 장애로 인해 노드마다 쓰기 도착 순서가 다를 수 있습니다. 이를 해결하려면 '동시성'의 의미를 명확히 정의해야 합니다.

#### '이전 발생(Happens-before)' 관계

두 작업 A, B가 있을 때 다음 중 하나에 해당합니다.

1.  **A가 B보다 먼저 발생**: B가 A를 알고 있거나, A의 데이터 위에 구축된 경우 (인과 관계 있음).
2.  **B가 A보다 먼저 발생**: 위와 반대 상황.
3.  **A와 B가 동시 발생**: 어느 쪽도 상대방의 작업이 일어났음을 모른 채 수행된 경우 (인과 관계 없음).

#### 인과 관계 캡처 알고리즘 (버전 번호 활용)

1.  서버는 모든 키에 대해 **버전 번호**를 유지하고 쓰기가 발생할 때마다 증가시킵니다.
2.  클라이언트는 쓰기 전에 반드시 읽기를 먼저 수행하여 현재 버전 번호를 가져옵니다.
3.  클라이언트는 쓰기 요청 시 이전에 읽은 버전 번호를 함께 보냅니다.
4.  서버는 들어온 요청의 버전 번호보다 작거나 같은 기존 데이터는 덮어씌우고(인과 관계에 따라 이전 데이터임이 확인됨), 더 높은 버전 번호의 데이터는 **형제(Siblings)**로 보관합니다. (동시 쓰기로 간주)

#### 버전 벡터 (Version Vectors)

리더 없는 시스템에서 여러 복제본이 쓰기를 수락할 때는 단일 버전 번호만으로 부족합니다.

- **정의**: 키마다, **복제본마다** 하나의 버전 번호를 유지하는 방식입니다.
- **작동**: 각 복제본은 자신의 버전 번호를 올리고, 다른 복제본의 버전 번호도 추적합니다. 이 정보를 모은 것이 버전 벡터입니다.
- **효과**: 이를 통해 데이터베이스는 어떤 값이 다른 값을 덮어써야 하는지, 혹은 동시 쓰기로서 병합(Merge)이 필요한지를 정확히 판단할 수 있습니다.

---

## 요약

복제는 단순해 보이지만(데이터 복사본 유지), 분산 시스템에서 발생하는 **동시성, 결함 처리, 네트워크 지연** 문제를 해결해야 하는 매우 까다로운 과제입니다.

### 1. 복제를 사용하는 5가지 주요 목적

1.  **고가용성(High Availability)**: 한두 대의 장비나 특정 데이터 센터(Zone), 리전(Region) 전체가 중단되어도 시스템을 계속 운영함.
2.  **지속성(Durability)**: 장비의 영구적인 고장에도 데이터를 잃지 않도록 보장함.
3.  **오프라인 작업(Disconnected Operation)**: 네트워크가 끊긴 상태에서도 앱이 계속 작동하고 나중에 동기화함.
4.  **지연 시간 감소(Latency)**: 데이터를 사용자 근처에 배치하여 더 빠르게 상호작용함.
5.  **확장성(Scalability)**: 여러 복제본에서 읽기를 수행하여 단일 장비보다 더 많은 읽기 요청을 처리함.

### 2. 세 가지 주요 복제 아키텍처 비교

| 방식          | 쓰기 흐름                      | 장점                              | 단점                                 |
| :------------ | :----------------------------- | :-------------------------------- | :----------------------------------- |
| **단일 리더** | 모든 쓰기는 하나의 리더로 전송 | 이해하기 쉽고 일관성 보장이 강함  | 리더 장애 시 쓰기 불가 (단일 장애점) |
| **다중 리더** | 여러 리더가 쓰기 수락          | 지리적 분산, 오프라인 작업에 강함 | 쓰기 충돌 해결 필요, 약한 일관성     |
| **리더 없는** | 여러 노드에 병렬로 쓰기/읽기   | 결함 내성 및 가용성이 매우 높음   | 복잡한 충돌 감지 및 해결 로직 필요   |

### 3. 복제 지연(Replication Lag)과 일관성 모델

비동기 복제 환경에서 발생하는 지연 문제를 해결하기 위해 애플리케이션은 다음 세 가지 보장 모델 중 하나를 선택해야 합니다.

- **자신이 쓴 내용 읽기(Read-after-write)**: 사용자가 제출한 데이터는 항상 본인에게 보여야 함.
- **단조 읽기(Monotonic reads)**: 한 번 본 데이터는 나중에 다시 볼 때 사라지거나 과거 상태로 돌아가선 안 됨.
- **일관된 접두사 읽기(Consistent prefix reads)**: 인과 관계(질문 후 답변 등)가 올바른 순서로 보여야 함.

### 4. 충돌 해결 및 수렴(Convergence)

다중 리더와 리더 없는 복제에서는 여러 노드에서 동시에 데이터가 수정될 수 있으며, 모든 복제본이 결국 **동일한 상태로 수렴**해야 합니다.

- **감지**: **버전 벡터(Version Vector)** 등의 알고리즘을 사용해 동시 쓰기를 식별함.
- **해결**:
  - **최종 쓰기 승리(LWW)**: 타임스탬프 기준으로 하나만 남기고 버림 (데이터 유실 위험).
  - **수동 해결**: 충돌된 값(Siblings)을 보관했다가 사용자가 직접 선택함.
  - **자동 해결**: **CRDT**나 **OT** 같은 정교한 알고리즘을 사용하여 데이터 유실 없이 병합함.
