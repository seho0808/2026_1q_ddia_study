# 복제(Replication) - 블로그 글 기반 추가 고찰

## 블로그에서 발견한 좋은 인사이트들

### 1. "에지 케이스: 정상적인 조건이 아닐 때 일어날 수 있는 시나리오"
→ 복제 시스템 설계 시 정상 케이스만 고려하면 안 됨. 장애, 네트워크 지연, 동시성 등 에지 케이스가 실제로 자주 발생

### 2. ElasticSearch 관점에서의 분석
→ 이론을 실제 시스템에 적용해 이해하는 접근이 훌륭함. 책만 읽는 것보다 실제 시스템과 연결해 생각하는 것이 중요

### 3. "용어가 암시된 핸드오프인 이유" 같은 용어 분석
→ 단순히 개념을 암기하는 게 아니라 왜 그런 이름이 붙었는지 생각하는 것이 깊은 이해로 이어짐

### 4. "쓰기 실패하면 에러난다며 왜 반환함?" 같은 의문 제기
→ 모순되어 보이는 부분에 대해 질문하는 자세가 중요. 실제로 이것이 복제 시스템의 복잡성을 보여주는 핵심

---

## 블로그 글에서 발견한 핵심 질문 정리
---

## 1. Elasticsearch는 단일 리더인가 다중 리더인가?

### 블로그 질문
> "ES 는 샤드마다 리플리카를 가지고 있으므로 다중 리더 인가? 아님 단일 리더인가? 샤드 당 리더는 하나니까 단일 리더 같다"

### 답변: **단일 리더 복제 방식**

Elasticsearch는 명확하게 **단일 리더 복제** 방식을 사용합니다.

**구조:**
```
샤드 1: [Primary] → [Replica 1] [Replica 2]
샤드 2: [Primary] → [Replica 1] [Replica 2]
샤드 3: [Primary] → [Replica 1] [Replica 2]
```

**핵심 포인트:**
- 각 샤드마다 하나의 Primary Shard(리더)만 존재
- Replica는 읽기만 가능 (팔로워 역할)
- 쓰기는 반드시 Primary를 거쳐야 함
- 샤드가 여러 개 있다고 다중 리더가 아님 (각 샤드는 독립적인 단일 리더 구조)

**왜 헷갈릴 수 있나?**
- 샤드가 여러 개라서 쓰기가 분산되는 것처럼 보임
- 하지만 각 문서는 하나의 샤드(하나의 Primary)에만 속함
- 즉, 문서 단위로 보면 항상 단일 리더를 통해 쓰기 수행

---

## 2. 동기식 vs 비동기식 복제의 혼란

### 블로그 질문
> "p.157에서 일반적으로 비동기로 한다면서 여기는 동기로 한다는 이유? 단일도 비동기로 하면 안 되나"

### 답변: **문맥에 따라 다름**

**두 가지 다른 레벨의 복제:**

#### Level 1: 데이터센터 내부 (리더 → 팔로워)
```
리더 → 팔로워1, 팔로워2, 팔로워3 (비동기 가능)
```
- 대부분의 시스템에서 **비동기식** 사용
- 이유: 성능과 가용성
- 단점: 리더 장애 시 일부 데이터 손실 가능

#### Level 2: 클라이언트 → 리더 (쓰기 요청)
```
클라이언트 → 리더 (동기식)
```
- 클라이언트는 리더가 쓰기를 완료할 때까지 **대기**
- 이는 "동기"와 "비동기"의 다른 의미

#### Level 3: 다중 데이터센터 간
```
사용자 → 로컬 DC 리더 (동기식 - 사용자 관점)
로컬 DC 리더 ↔ 원격 DC 리더 (비동기식)
```

**핵심 이해:**
- "일반적으로 비동기" = **리더-팔로워 간** 복제
- "동기로 한다" = **클라이언트-리더 간** 쓰기 또는 **사용자가 느끼는 응답 시간**
- 이 둘은 다른 레벨의 이야기

**단일 리더도 비동기로 하면?**
- 가능하지만, 클라이언트는 리더에 대한 쓰기 완료를 기다림
- 리더 → 팔로워는 비동기로 진행 (일반적)
- 완전 비동기(fire-and-forget): 쓰기가 디스크에 저장되기 전 성공 응답 → 매우 위험

---

## 3. Elasticsearch의 하이브리드 복제 전략

> "Replication is sync by default... That said, lots of these processes happen at the same time, so sending the document to the replica is asynchronous."

### 정확한 의미 해석

**색인 요청 처리:**
```
1. 클라이언트 → Primary Shard (동기식)
   - Primary가 색인 완료할 때까지 대기
   
2. Primary → Replica Shards (비동기 병렬)
   - 여러 Replica에 동시에 전송
   - 하나 보내고 응답 기다리고 다음 보내는 게 아님
   - 모두 병렬로 전송 (비동기)
   
3. 모든 Replica가 색인 완료
   
4. Primary → 클라이언트 (성공 응답)
```

**왜 이렇게 설계했나?**
- 데이터 일관성: Primary에 써진 것은 확실히 보장
- 성능: Replica 복제는 병렬로 빠르게 처리
- 가용성: Replica 하나 실패해도 다른 Replica는 계속 동작

**트레이드오프:**
- 모든 Replica 응답 기다리므로 쓰기 지연 발생 가능
- 하지만 데이터 손실 위험 최소화
- `wait_for_active_shards` 파라미터로 조정 가능

---

## 4. 정족수(Quorum)에 대한 이해

### 블로그 질문들

#### Q1: "정족수 = fixed number. w, r 이 만족해야하는 최소 노드 수"
**정확합니다!** 

- n = 3 (전체 복제 서버 수)
- w = 2 (쓰기 정족수 - 2개 노드에 써야 성공)
- r = 2 (읽기 정족수 - 2개 노드에서 읽어야 함)
- w + r > n (2 + 2 > 3) ✓

#### Q2: "느슨한 정족수면 r 개 노드와 w 개 노드가 겹치는 걸 보장하지 않는다"
**맞습니다!**

**정상 정족수:**
```
지정된 노드: [N1] [N2] [N3]
쓰기: N1, N2에 성공 (w=2)
읽기: N2, N3에서 조회 (r=2)
→ N2가 겹침! 최신 데이터 읽을 수 있음
```

**느슨한 정족수:**
```
지정된 노드: [N1] [N2(장애)] [N3]
쓰기: N1, N4(임시)에 성공 (w=2)
읽기: N1, N3에서 조회 (r=2)
→ N4는 읽기에 포함 안 됨! 오래된 데이터 읽을 수 있음
```

#### Q3: "쓰기 실패해도 이어지는 읽기에서 해당 쓰기 값이 반환될수도 아닐 수도"
**맞는 지적입니다.**

**시나리오:**
```
n=3, w=2, r=2
쓰기 시도: N1 성공, N2 성공, N3 실패
→ w=2 만족하므로 "쓰기 성공" 응답

하지만 N3는 실패했으므로:
- 읽기 1: N1, N2 조회 → 최신 값 반환 ✓
- 읽기 2: N2, N3 조회 → 최신 값 반환 (N2에 있으므로) ✓
- 읽기 3: N1, N3 조회 → 최신 값 반환 (N1에 있으므로) ✓

하지만 N1, N2가 모두 장애나고 N3만 복구되면:
- 읽기: N3만 가능 → 오래된 값 반환 ✗
```

이것이 "w + r > n을 만족해도 오래된 값을 읽을 수 있는" 에지 케이스입니다.

---

## 실무에서의 복제 전략 선택 가이드

### 복제 방식별 적용 상황

#### 단일 리더 복제 - 가장 많이 사용
**사용하면 좋을 때:**
- 읽기가 쓰기보다 훨씬 많은 경우 (10:1 이상)
- 강한 일관성이 중요한 경우
- 복잡도를 낮게 유지하고 싶을 때
- 대부분의 웹 애플리케이션

**예시:**
- MySQL, PostgreSQL (Master-Slave)
- MongoDB (Primary-Secondary)
- Elasticsearch (Primary-Replica per shard)

#### 다중 리더 복제 - 신중하게 사용
**사용하면 좋을 때:**
- 다중 데이터센터 운영 (지리적 분산)
- 네트워크 파티션이 자주 발생하는 환경
- 오프라인 작업 지원 필요
- 쓰기 처리량이 매우 높아야 할 때

**주의사항:**
- 충돌 해소 로직 필수
- 복잡도 매우 높음
- 버그 발생 가능성 높음
- 대부분의 경우 피하는 것이 좋음

**예시:**
- CouchDB (다중 마스터)
- 협업 도구 (Google Docs, Notion)
- 오프라인 앱 (Evernote)

#### 리더 없는 복제 - 높은 가용성 필요 시
**사용하면 좋을 때:**
- 가용성이 최우선
- 네트워크 파티션 허용
- 최종적 일관성 허용 가능
- 대규모 분산 시스템

**예시:**
- Cassandra
- Riak
- DynamoDB

---

## 복제 지연 문제 - 실무 해결 전략

### 쓰기 후 읽기 일관성 (Read-after-write consistency)

블로그에서 설명한 것처럼 사용자가 자신이 쓴 내용을 못 보는 문제:

**Elasticsearch에서의 해결:**
```javascript
// refresh 파라미터 사용
POST /my_index/_doc/1?refresh=true
{
  "content": "새 게시글"
}

// 또는 refresh API 호출
POST /my_index/_refresh
```

**장단점:**
- 장점: 즉시 읽기 가능
- 단점: 성능 오버헤드 (매번 refresh는 비효율적)

**더 나은 방법:**
```javascript
// refresh=wait_for 사용
POST /my_index/_doc/1?refresh=wait_for
{
  "content": "새 게시글"
}
```
- 다음 자동 refresh까지 대기
- 성능과 일관성의 균형

### 단조 읽기 (Monotonic Reads)

**실무 구현:**
```
사용자 세션 ID를 해시 → 항상 같은 Replica로 라우팅
```

**주의사항:**
- Replica 장애 시 다른 Replica로 라우팅 필요
- 스티키 세션과 유사한 메커니즘

### 일관된 순서로 읽기 (Consistent Prefix Reads)

**문제 상황:**
```
질문: "사랑해?" → 샤드1
답변: "뭘?"     → 샤드2

관찰자가 샤드2 먼저 읽으면 답변이 먼저 보임
```

**해결 방법:**
- 인과성 있는 데이터는 같은 샤드에 저장
- 라우팅 키 사용: `routing=user_id`
- 부모-자식 관계 활용

---

## 7. 장애 복구의 현실

### 사례 분석

**문제 상황:**
```
1. Primary 장애 발생
2. 뒤처진(out-of-date) Replica가 Primary로 승격
3. 자동 증가 ID를 재사용
4. Redis 데이터와 불일치 → 잘못된 데이터 노출
```

**교훈:**
- 장애 복구는 완벽하지 않음
- 여러 저장소 사용 시 일관성 더 어려움
- 자동 장애 복구의 위험성
- 모니터링과 검증 필수

### 실무 장애 복구 체크리스트

**장애 감지:**
- [ ] 타임아웃 설정 적절한가?
- [ ] 헬스체크 주기는?
- [ ] 네트워크 지연 vs 실제 장애 구분?

**리더 선출:**
- [ ] 가장 최신 데이터를 가진 노드 선출?
- [ ] 스플릿 브레인 방지 메커니즘?
- [ ] 정족수 기반 선출?

**데이터 일관성:**
- [ ] 유실될 데이터 확인?
- [ ] 충돌 해소 로직 준비?
- [ ] 롤백 계획?

**시스템 재설정:**
- [ ] 클라이언트 재연결?
- [ ] 이전 리더 처리?
- [ ] 모니터링 알림?

---

## 결론: 복제 전략 선택 가이드

### 의사결정 플로우차트

```
시작
 │
 ├─ 강한 일관성 필요? 
 │   YES → 단일 리더 + 동기식 복제
 │   NO → 계속
 │
 ├─ 다중 데이터센터?
 │   YES → 다중 리더 고려 (복잡도 감수)
 │   NO → 계속
 │
 ├─ 극도로 높은 가용성?
 │   YES → 리더 없는 복제
 │   NO → 단일 리더 + 비동기식 복제 (일반적 선택)
```

### 각 방식의 복잡도 vs 이점

| 복제 방식 | 구현 복잡도 | 일관성 | 가용성 | 쓰기 성능 | 읽기 성능 |
|----------|-----------|--------|--------|----------|----------|
| 단일 리더 (동기) | 낮음 | 높음 | 낮음 | 낮음 | 높음 |
| 단일 리더 (비동기) | 낮음 | 중간 | 중간 | 중간 | 높음 |
| 다중 리더 | 매우 높음 | 낮음 | 높음 | 높음 | 높음 |
| 리더 없는 | 높음 | 낮음 | 매우 높음 | 높음 | 중간 |

### 최종 조언

**80%의 경우: 단일 리더 + 비동기 복제**
- 검증된 방식
- 낮은 복잡도
- 충분한 성능과 가용성
- 명확한 운영 가이드라인

**특수한 경우에만 다른 방식 고려**
- 다중 리더: 지리적 분산이 필수적일 때만
- 리더 없는: 파티션 허용이 필수적일 때만

**항상 기억할 것**
- 복제는 복잡하다
- 에지 케이스가 많다
- 모니터링이 필수다
- 단순함이 최선이다

---

## 참고 자료

- 참고 블로그: https://elsboo.tistory.com/51
- Elasticsearch 공식 문서: Replication Model