# 04. 부호화와 발전

## 데이터 부호화 형식

프로그램은 보통 두 가지 형태로 표현된 데이터를 사용해 동작한다.

- 메모리: CPU에서 효율적으로 접근하고 조작할 수 있게 (보통은 포인터를 이용해) 최적화된다.
    - 객체, 구조체, list, array, hash table, tree
- 데이터를 파일에 쓰거나 네트워크를 통해 전송: 일련의 바이트열의 형태로 부호화해야 한다. 포인터는 다른 프로세스가 이해할 수 없으므로 이 일련의 바이트열은 보통 메모리에서 사용하는 데이터 구조와는 상당히 다르다.

- 부호화(직렬화): 인메모리 표현 → 바이트열로의 전환
- 복호화(역직렬화): 바이트열 → 인메모리 표현으로의 전환

### 언어별 형식

프로그래밍 언어에 내장된 부호화 라이브러리는 최소한의 추가 코드로 인메모리 객체를 저장하고 복원할 수 있기 때문에 매우 편리하지만 심각한 문제점 또한 많다.

- 동일한 객체 유형의 데이터를 복원하려면 복호화 과정이 임의의 클래스를 인스턴스화할 수 있어야 한다. 이것은 종종 보안 문제의 원인이 된다. 공격자가 임의의 바이트열을 복호화할 수 있는 애플리케이션을 얻을 수 있으면 임의의 클래스를 인스턴스화할 수 있고 공격자가 원격으로 임의의 코드를 실행하는 것과 같은 끔찍한 일이 발생할 수 있다.
    
    ### "임의의 클래스를 인스턴스화할 수 있다"의 의미
    
    프로그램이 데이터를 복원할 때, "이 데이터는 'A'라는 모양으로 만들어라"라는 정보가 데이터 안에 포함되어 있습니다. 문제는 프로그램이 **"어떤 모양(클래스)이든 시키는 대로 다 만들어줄게"**라고 설계되어 있을 때 발생합니다.
    
    공격자는 정상적인 데이터 대신, **시스템에 위험한 명령을 내리는 특수한 클래스**를 만들어 달라는 가짜 바이트열을 보냅니다. 프로그램은 의심 없이 그 위험한 객체를 메모리에 생성(인스턴스화)하게 됩니다.
    
    자바 보안 역사상 가장 유명한 사건인 **Apache Commons Collections(ACC) 취약점** 사례를 통해, 어떻게 '정상적인 도구'가 '흉기'로 변하는지 보여드릴게요.
    
    이 사례는 실제로 2015년에 발표되어 전 세계 수많은 서버를 공포에 떨게 했던 실화입니다.
    
    ---
    
    ### 1. 사용된 "정상적인 부품(가젯)"들
    
    공격자는 서버에 기본적으로 깔려 있는 `commons-collections.jar`라는 라이브러리 안에서 다음 부품들을 찾아냈습니다.
    
    - **부품 A (`Transformer`):** 입력받은 데이터를 변환해주는 도구입니다. 그중 `InvokerTransformer`라는 애는 이름 그대로 **"특정 메서드를 실행(Invoke)하라"**는 기능을 가졌습니다. (매우 강력한 도구죠.)
    - **부품 B (`ChainedTransformer`):** 여러 개의 Transformer를 **사슬(Chain)처럼 연결**해서 순서대로 실행해주는 도구입니다.
    - **부품 C (`LazyMap`):** 지도(Map) 같은 데이터 꾸러미인데, 없는 데이터를 찾으려고 하면 **"직접 만들어서 채워 넣어라"**는 기능이 있습니다.
    - **부품 D (`AnnotationInvocationHandler`):** 자바 기본 클래스입니다. 역직렬화될 때 Map의 내용을 하나씩 확인하는 성질이 있습니다.
    
    ---
    
    ### 2. 공격자의 "폭탄(바이트열)" 조립 과정
    
    공격자는 이 부품들을 다음과 같이 정교하게 조립합니다.
    
    1. **실행 내용 정의:** `InvokerTransformer`를 이용해서 `Runtime.getRuntime().exec("calc.exe")` (계산기 실행, 실제로는 악성코드 다운로드) 명령을 준비합니다.
    2. **연쇄 장치 연결:** `ChainedTransformer`에 위 명령 부품들을 순서대로 끼워 넣습니다.
    3. **트리거 장착:** `LazyMap` 안에 이 연쇄 장치를 숨깁니다. 누군가 이 맵에 접근하면 연쇄 장치가 돌아가게 됩니다.
    4. **기폭제 연결:** `AnnotationInvocationHandler`가 이 `LazyMap`을 관리하도록 설정합니다. 이 클래스는 **역직렬화되는 순간 자동으로 맵을 건드리는** 특성이 있기 때문입니다.
    
    ---
    
    ### 3. 서버에서 벌어지는 일 (폭발)
    
    공격자가 이 조립물을 직렬화해서 서버에 던지면, 서버는 아무심 없이 `readObject()`를 수행합니다.
    
    1. **역직렬화 시작:** 서버가 `AnnotationInvocationHandler`를 복원합니다.
    2. **트리거 작동:** 복원 과정에서 이 클래스가 내부의 `LazyMap`을 건드립니다.
    3. **연쇄 반응:** `LazyMap`이 "어? 데이터가 없네? 만들어야지!" 하며 연결된 `ChainedTransformer`를 실행합니다.
    4. **최종 폭발:** 사슬 끝에 달려있던 `InvokerTransformer`가 서버의 OS 명령창을 열고 공격자의 명령(`calc.exe`)을 실행합니다.
    
    ---
    
    ### 4. 핵심은 "임의의 클래스 인스턴스화"
    
    이 과정에서 공격자가 **새로운 악성 파일(.java)을 서버에 업로드한 적이 있나요? 없습니다.**
    
    단지 서버에 이미 있던 `InvokerTransformer`, `LazyMap` 같은 **정상적인 클래스들을 "임의로" 골라서 내 마음대로 "인스턴스화(객체로 생성)"** 하고 연결했더니, 서버가 해킹당한 것입니다.
    
    처음에 질문하셨던 문장이 이제 완벽히 이해되실 겁니다.
    
    > "공격자가 임의의 클래스를 인스턴스화할 수 있으면... 원격으로 임의의 코드를 실행하는 것과 같은 끔찍한 일이 발생할 수 있다."
    > 
    
    ---
    
    ### 결론: 우리는 어떻게 해야 할까?
    
    이 사건 이후로 보안 업계의 공식 답변은 하나로 통일되었습니다.
    
    **"신뢰할 수 없는 사용자가 보낸 직렬화 데이터(바이트열)는 절대로 `readObject()` 하지 마라."**
    
    그래서 요즘은 대부분 **JSON** 같은 단순 텍스트 형식을 씁니다. JSON은 "이 클래스 만들어!"라고 명령하는 게 아니라, 그냥 "이 데이터는 이름이고, 이건 나이야"라고 정보만 전달하기 때문에 이런 도미노 폭발이 일어나지 않거든요.
    
- 다른 언어에서 데이터를 읽기 어렵다
- 데이터 버전 관리(상위, 하위 호환성)가 등한시 된다.
- 효율성(부호화나 복호화에 소요되는 CPU 시간과 부호화된 구조체의 크기)도 종종 나중에 생각하게 된다. 예를 들어 자바의 내장 직렬화는 성능이 좋지 않고 비대해지는 부호화로 유명하다.

### JSON과 XML, 이진 변형

### 이진 부호화

작은 데이터셋의 경우에는 부호화 형식 선택으로 얻는 이득이 무시할 정도지만 테라바이트 정도가 되면 데이터 타입의 선택이 큰 영향을 미친다.

### 스리프트와 프로토콜 버퍼

아파치 스리프트(Apache Thrift)와 프로토콜 버퍼(Protocol Buffers, 줄여서 protobuf)는 같은 원리를 기반으로 한 이진 부호화 라이브러리다.

스리프트와 프로토콜 버퍼 모두 부호화할 데이터를 위한 스키마가 필요하다.

스리프트는 **바이너리 프로토콜**과 **컴팩트프로토콜**이라는 두 가지 다른 이진 부호화 형식이 있다.

- 바이너리 프로토콜(BinaryProtocol)
    - 부호화된 데이터는 필드 이름 대신 필드 태그(1,2,3..)를 포함한다. 이 숫자는 스키마 정의에 나타난 숫자다.
- 컴팩트 프로토콜(CompactProtocol)
    - 의미상으로는 바이너리프로토콜과 같지만 동일한 정보를 단지 34바이트로 줄여 부호화한다. 이는 필드 타입과 태그 숫자를 단일 바이트로 줄이고 가변 길이 정수를 사용해서 부호화한다.

마지막으로 **프로토콜 버퍼**는 비트를 줄여 저장하는 처리 방식이 약간 다르지만 스리프트의 컴팩트프로토콜과 매우 비슷하다. 프로토콜 버퍼는 같은 데이터를 33바이트로 만든다.

### 필드 태그와 스키마 발전

- schema evolution: 스키마는 필연적으로 시간이 지남에 따라 변한다.

- 부호화된 데이터는 필드 이름을 전혀 참조하지 않기 때문에 스키마에서 필드 이름은 변경할 수 있다. 그러나 필드 태그는 기존의 모든 부호화된 데이터를 인식 불가능하게 만들 수 있기 때문에 변경할 수 없다.
- **상위 호환성**
    - 예전 코드에서 새로운 코드로 기록한 데이터(예전 코드가 인식할 수 없는 태그 번호를 가진 필드가 포함됨)를 읽으려는 경우에는 해당 필드를 간단히 무시할 수 있다. 데이터 타입 주석은 파서가 몇 바이트를 건너뛸 수 있는지 알려준다.

- **하위 호환성**
    - 스키마의 초기 배포 후에 추가되는 모든 필드는 `optional`로 하거나 기본값을 가져야한다.

### 데이터타입과 스키마 발전

필드의 데이터타입을 변경하는 건 어떨까?

- 프로토콜 버퍼
    - `repeated` 표시자: `optional` 과 호환됨
- 스리프트
    - 전용 목록 데이터타입: 중첩된 목록을 지원한다.

### 아브로(Avro)

아브로는 스리프트가 하둡의 사용 사례에 적합하지 않아 2009년 하둡의 하위 프로젝트로 시작했다.

- 태그번호, 데이터타입을 식별하기 위한 정보 X
- 모든 부호화 중 길이가 가장 짧음
- 순서대로 필드를 살펴보고 스키마를 이용해 각 필드의 데이터타입을 미리 파악해야 한다.

### 쓰기 스키마와 읽기 스키마

- 쓰기 스키마 - 부호화
- 읽기 스키마 - 복호화

> 아브로의 핵심 아이디어는 쓰기 스키마와 읽기 스키마가 동일하지 않아도 되며 단지 호환 가능하면 된다는 것이다.
> 
- 쓰기 스키마와 읽기 스키마는 필드 순서가 달라도 문제없다. 왜냐하면 스키마 해석에서는 이름으로 필드를 일치시키기 때문이다.

### 스키마 발전 규칙

아브로에서 상위 호환성은 새로운 버전의 쓰기 스키마와 예전 버전의 읽기 스키마를 가질 수 있음을 의미한다.

반대로 하위 호환성은 새로운 버전의 읽기 스키마와 예전 버전의 쓰기 스키마를 가질 수 있음을 의미한다.

- 호환성을 유지하기 위해서는 기본값이 있는 필드만 추가하거나 삭제할 수 있다.
- union type

아브로는 타입을 변환할 수 있으므로 필드의 데이터타입 변경이 가능하다. 필드 이름 변경도 가능하지만 조금 까다롭다.

필드 이름 변경은 하위 호환성이 있지만 상위 호환성은 없다. 유니온 타입에 엘리먼트를 추가하는 것도 마찬가지다.

### 그러면 쓰기 스키마는 무엇인가?

읽기는 특정 데이터를 부호화한 쓰기 스키마를 어떻게 알 수 있을까?(쓰기 당시에 사용했던 스키마가 무엇인지 어떻게 알아내느냐) 모든 레코드에 전체 스키마를 포함시킬 수는 없다. 왜냐하면 스키마는 부호화된 데이터보다 훨씬 클 가능성이 있기 때문이다. 그러면 이진 부호화로 절약한 공간이 소용없다.

- 많은 레코드가 있는 대용량 파일(HDFS)
    - 시작 부분에서 한번만
- 개별적으로 기록된 레코드를 가진 데이터베이스
    - 버전 번호
- 네트워크 연결을 통해 레코드 보내기
    - 합의

## 데이터 플로 모드

**메모리를 공유하지 않는** 다른 프로세스로 일부 데이터를 보내고 싶을 때는 바이트열로 부호화해야 한다.

프로세스 간 데이터를 전달하는 가장 보편적인 방법을 살펴보자.

### 데이터베이스를 통한 데이터플로

- 하위 호환성: 이전에 기록한 내용을 미래의 자신이 복호화
- 상위 호환성: 데이터베이스 내 값이 새로운 버전의 코드로 기록된 다음 현재 수행 중인 예전 버전의 코드로 그 값을 읽음
- 애플리케이션에서 데이터베이스 값을 모델 객체로 복호화하고 나중에 이 모델 객체를 다시 재부호화한다면 변환 과정에서 알지 못하는 필드가 유실될 수 있다.

### 다양한 시점에 기록된 다양한 값

애플리케이션의 새로운 버전을 배포할 때 몇 분 내에 예전 버전을 새로운 버전으로 완전히 대체할 수 있지만 데이터베이스 내용은 그렇지 않다. 5년된 데이터는 그 이후로 명시적으로 다시 기록하지 않는 한 원래의 부호화 상태로 그대로 있다.

→ **데이터가 코드보다 더 오래 산다(data outlives code)**

데이터를 새로운 스키마로 다시 기록(마이그레이션)하는 작업은 가능하지만 비용이 비싸다.

대부분 관계형 데이터베이스는 기존 데이터를 다시 기록하지 않고 null을 기본값으로 갖는 새로운 칼럼을 추가하는 간단한 스키마 변경을 허용한다.

### 보관 저장소

- 백업 목적이나 데이터 웨어하우스로 적재하기 위해 데이터베이스의 스냅숏을 수시로 만든다고 가정해보자. 이 경우 데이터 덤프는 보통 최신 스키마를 사용해 부호화한다. 데이터 덤프는 한 번에 기록하고 이후에는 변하지 않으므로 아브로 객체 컨테이너 파일과 같은 형식이 적합하다. 또한 이것은 파케이와 같은 분석 친화적인 칼럼 지향 형식으로 데이터를 부호화할 좋은 기회이기도 하다.
    
    ### 요약하자면
    
    이 문장의 흐름은 이렇습니다.
    
    1. **준비:** DB 데이터를 백업할 때, 옛날 방식 다 잊고 **최신 스키마**로 통일하자.
    2. **저장:** 어차피 안 바꿀 데이터니까, 스키마를 한 번만 적어 용량을 아끼는 **아브로 형식**으로 파일로 만들자.
    3. **최적화:** 이왕 만드는 거, 나중에 분석하기 편하게 **세로 방향(칼럼 지향)**으로 데이터를 정렬(파케이 등)해서 저장해두면 나중에 통계 낼 때 훨씬 빠르다.

## 서비스를 통한 데이터플로: REST와 RPC

서비스 지향 및 마이크로서비스 아키텍처의 핵심 설계 목표는 서비스를 배포와 변경에 독립적으로 만들어 애플리케이션 변경과 유지보수를 더 쉽게 할 수 있게 만드는 것이다.

여러가지 면에서 서비스는 데이터베이스와 유사하다.

서비스 지향 및 마이크로서비스 아키텍처의 핵심 설계 목표는 서비스를 배포와 변경에 독립적으로 만들어 애플리케이션 변경과 유지보수를 더 쉽게 할 수 있게 만드는 것이다.

→ 예전 버전과 새로운 버전의 서버와 클라이언트가 동시에 실행되기를 기대한다. 따라서 서버와 클라이언트가 사용하는 데이터 부호화는 서비스 API의 버전 간 호환이 가능해야 한다.

### 웹 서비스

### 원격 프로시저 호출(remote procedure call, RPC) 문제

RPC 모델은 원격 네트워크 서비스 요청을 같은 프로세스 안에서 특정 프로그래밍 언어의 함수나 메서드를 호출하는 것과 동일하게 사용 가능하게 해준다. RPC 접근 방식은 근본적으로 결함이 있다. 네트워크 요청은 로컬 함수 호출과는 매우 다르다.

- 네트워크 요청은 타임아웃으로 결과 없이 반환될 수 있다. 원격 서비스로부터 응답을 받지 못한다면 요청을 제대로 보냈는지 아닌지를 알 수 있는 방법이 없다.
- 실패한 네트워크 요청을 다시 시도할 때 요청이 실제로는 처리되고 응답만 유실될 수 있다. 이 경우 프로토콜에 중복 제거 기법(멱등성)을 적용하지 않으면 재시도는 작업이 여러 번 수행되는 원인이 된다.
- 네트워크 요청은 함수 호출보다 훨씬 느리고 지연 시간은 매우 다양하다.
- 모든 매개변수는 네트워크를 통해 전송할 수 있게끔 바이트열로 부호화해야 한다.

### RPC의 현재 방향

차세대 RPC 프레임워크는 원격 요청이 로컬 함수 호출과 다르다는 사실을 더욱 분명히 한다.

예를 들어 피네글과 Rest.li는 실패할지도 모를 비동기 작업을 캡슐화하기 위해 future를 사용한다. 퓨쳐는 병렬로 여러 서비스에 요청을 보내야 하는 상황을 간소화하고 요청 결과를 취합한다.

> **차세대 RPC의 태도:** "이건 네트워크 통신이니까 언제든 실패할 수 있어. 그러니까 너(개발자)는 반드시 **실패했을 때 어떻게 할지(예외 처리, 재시도 등)**를 Future나 콜백을 통해 미리 작성해 둬!"라고 강제하는 것입니다.
> 

→ 네트워크의 불완전함을 마법으로 해결하려 하지 말고, 프로그래밍 모델(Future 등)로 끌어올려 개발자가 직접 통제하게 하자

RPC 프레임워크의 주요 초점은 보통 같은 데이터센터 내의 같은 조직이 소유한 서비스 간 요청에 있다.

| **구분** | **RPC (예: gRPC, Hazelcast RPC)** | **REST** |
| --- | --- | --- |
| **추상화** | **함수 호출** 중심 (`doSomething()`) | **자원(데이터)** 중심 (`GET /resource`) |
| **인터페이스** | 서비스마다 고유한 메서드를 가짐 | HTTP 표준 메서드(GET, POST 등)를 공유 |
| **통신 프로토콜** | 주로 TCP나 HTTP/2 위에서 **이진(Binary)** 데이터로 통신 (매우 빠름) | 주로 HTTP 위에서 **JSON/XML** 텍스트로 통신 (가독성 좋음) |
| **에러 처리** | 예외(Exception)가 터지거나 Future에 담김 | HTTP 상태 코드로 명확히 구분 |

### 데이터 부호화와 RPC의 발전

발전성이 있으려면 RPC 클라이언트와 서버를 독립적으로 변경하고 배포할 수 있어야 한다.

RPC 스키마의 상하위 호환 속성은 사용된 모든 부호화로부터 상속된다.

### 메시지 전달 데이터플로

메시지 브로커를 사용하는 방식은 직접 RPC를 사용하는 방식과 비교했을 때 여러 장점이 있다.

→ 하지만 RPC는 응답을 반환해준다는 장점이 있음, 지연시간도 낮음

### 메시지 브로커

메시지 브로커는 보통 특정 데이터 모델을 강요하지 않는다. 메시지는 일부 메타데이터를 가진 바이트열이므로 모든 부호화 형식을 사용할 수 있다. 부호화가 상하위 호환성을 모두 가진다면 메시지 브로커에서 게시자(publisher)와 소비자를 독립적으로 변경해 임의 순서로 배포할 수 있는 유연성을 얻게 된다.

- 알지 못하는 필드 보존에 주의가 필요(데이터베이스 처럼)

### 분산 액터 프레임워크

- 액터 모델: 단일 프로세스 안에서 동시성을 위한 프로그래밍 모델이다.
