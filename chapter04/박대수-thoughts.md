# DDIA 4장 - 메시징 시스템 Deep Dive Thoughts

## 메시징 시스템과 데이터 부호화의 철학적 연결

PostHog를 사용하면서 Kafka를 함께 다루게 되었는데, 분산 환경이 아니어서 개념을 제대로 이해하지 못한 부분들이 많았다. DDIA 4장 "부호화와 발전"의 전체 맥락에서 메시징 시스템을 바라보니, 메시징은 단순한 기술이 아니라 **데이터 부호화 철학의 실질적 구현체**임을 깨달았다.

### 데이터 부호화의 핵심 철학
- **"데이터가 코드보다 오래 산다"**: 시스템은 진화하지만 데이터는 영속적
- **호환성의 중요성**: 상위/하위 호환성으로 롤링 업그레이드 가능
- **부호화는 선택의 문제**: 효율성 vs 유연성 vs 호환성 사이의 균형

메시징 시스템은 바로 이 철학을 실현하는 **실행 환경이자 테스트베드**다. 이 관점에서 8가지 deep dive 주제를 정리해보았다.

## 1. 메시지 전달 보장 (Message Delivery Guarantees)

**연결고리**: 부호화 철학에서 "데이터가 코드보다 오래 산다"는 개념이 전달 보장에서 실현됨. 데이터 유실은 영구적 손실이지만, 중복은 나중에 처리 가능하다.

Kafka에서는 세 가지 전달 보장을 지원한다:
- **At-most-once**: 메시지가 최대 한 번 전달. 속도가 빠르지만 유실 가능성 존재
- **At-least-once**: 메시지가 최소 한 번 전달. 중복 가능하지만 유실은 없음
- **Exactly-once**: 정확히 한 번 전달. 가장 강력하지만 성능 오버헤드 큼

PostHog에서는 사용자 이벤트 데이터를 처리하므로 At-least-once를 주로 사용한다. 중복 이벤트는 나중에 deduplication 처리.

## 2. 메시지 브로커 아키텍처 비교

**연결고리**: 부호화 형식 선택의 연장선. JSON/XML의 유연성과 Thrift/Protocol Buffers의 효율성 사이에서 Kafka는 "로그 기반의 영속적 저장소"라는 독특한 선택을 함.

Kafka의 로그 기반 아키텍처:
- **토픽(Topic)**: 메시지 카테고리 (스키마 발전의 단위)
- **파티션(Partition)**: 토픽을 분할하여 병렬 처리 (확장성과 호환성의 균형)
- **브로커(Broker)**: Kafka 클러스터의 핵심 서버
  - 메시지 저장 및 전송 담당
  - 파티션 리더십 관리
  - 컨슈머 그룹 코디네이션
  - 로그 세그먼트 관리 및 압축
- **주키퍼(Zookeeper)**: 메타데이터 관리 (스키마 레지스트리의 역할)

RabbitMQ의 큐 기반과 달리, Kafka는 로그를 영속적으로 저장하고 리플레이가 가능하다는 점이 큰 차이점. 이는 "데이터가 코드보다 오래 산다"는 철학의 물리적 구현이다. ClickHouse와의 조합에서는 Kafka의 로그가 ClickHouse의 칼럼 기반 분석으로 이어져, 데이터의 **수집→저장→분석** 파이프라인이 완성된다.

## 3. 메시징 패턴과 토폴로지

**연결고리**: 데이터 플로 모드 중 "실시간 데이터 플로우"의 구체적 구현. 생산자와 소비자의 느슨한 결합이 호환성을 가능하게 함.

Kafka의 주요 패턴들:
- **발행-구독(Pub/Sub)**: 한 생산자가 여러 소비자에게 메시지 전송 (브로드캐스트 방식의 호환성)
- **점대점**: 하나의 소비자만 메시지 처리 (Consumer Group 사용) (작업 분배의 효율성)

PostHog에서 사용자 이벤트는 Pub/Sub 패턴으로 여러 분석 서비스에 동시에 전송되고, 배치 처리 작업은 Consumer Group으로 분산 처리된다.

## 4. 확장성과 고가용성

**연결고리**: 호환성의 물리적 토대. 시스템 확장 중에도 데이터 일관성과 접근성을 유지하는 것이 핵심.

Kafka의 확장 메커니즘:
- **파티셔닝**: 토픽을 여러 파티션으로 분할하여 병렬 처리 (수평 확장)
- **리플리케이션**: 각 파티션을 여러 브로커에 복제 (고가용성과 내구성)
- **컨슈머 그룹**: 여러 컨슈머가 파티션을 분배하여 처리 (로드 밸런싱)

단일 DB 환경에서는 리플리케이션의 필요성을 느끼지 못했지만, 실제 분산 환경에서는 데이터 유실 방지와 고가용성을 위해 필수적이다. 이는 "데이터가 코드보다 오래 산다"는 철학의 인프라적 보장이다.

## 5. 액터 모델의 핵심 개념

**연결고리**: 분산 액터 프레임워크가 메시징의 한 형태. 액터 간 통신이 곧 데이터 부호화와 전송의 문제.

Kafka Streams나 Kafka Connect에서 액터 모델 개념을 부분적으로 볼 수 있음:
- **위치 투명성**: 어느 브로커에서 처리되든 동일한 결과 (호환성의 물리적 실현)
- **메시지 기반 통신**: 모든 상호작용이 메시지로 이루어짐 (부호화의 기본 단위)
- **격리된 상태**: 각 파티션이 독립적으로 상태 관리 (스키마 발전의 안전장치)

하지만 Kafka는 완전한 액터 모델은 아니고, 이벤트 스트리밍 플랫폼에 가깝다.

## 6. 액터 프레임워크 구현 비교

**연결고리**: 부호화 형식 선택의 확장. 각 메시징 시스템이 취하는 설계 결정이 부호화 철학과 연결됨.

Kafka vs 다른 프레임워크:
- **Kafka**: 로그 기반, 내구성 강조, 스트리밍 처리에 특화 (데이터 영속성 우선)
- **RabbitMQ**: 큐 기반, 임시 메시지, 낮은 지연시간 (효율성 우선)
- **Redis Pub/Sub**: 인메모리, 휘발성, 단순한 pub/sub (단순성 우선)

PostHog에서는 Kafka의 내구성과 리플레이 기능이 이벤트 분석에 유용했다. 이는 "데이터가 코드보다 오래 산다"는 철학을 가장 잘 구현한 선택이었다.

## 7. 액터 기반 시스템 설계 패턴

**연결고리**: 스키마 발전 규칙의 실질적 적용. 패턴 설계가 호환성 문제를 해결하는 방법론.

Kafka 생태계의 패턴들:
- **KStreams**: 토폴로지 기반 스트림 처리 (상태 관리와 호환성)
- **Kafka Connect**: 소스/싱크 커넥터 패턴 (느슨한 결합으로 호환성 보장)
- **Exactly-once 처리**: 트랜잭션과 멱등성 활용 (전달 보장과 스키마 발전의 조합)

PostHog의 이벤트 파이프라인에서 KStreams로 실시간 집계와 필터링을 구현한 경험이 있다.

## 8. 메시징 시스템의 실제 적용 사례

**연결고리**: 모든 부호화 개념의 종합적 실현. 실제 비즈니스 요구사항이 부호화 설계를 주도함.

PostHog에서의 Kafka 활용:
- **이벤트 수집**: 사용자 행동 데이터를 실시간으로 수집 (데이터 플로 모드)
- **데이터 파이프라인**: 이벤트를 여러 저장소(ClickHouse, PostgreSQL)로 분배 (호환성 실현)
  - **ClickHouse**: 칼럼 기반 OLAP 저장소로 실시간 분석에 특화
    - 칼럼 압축으로 효율적 저장 (부호화 효율성의 극치)
    - 초고속 쿼리 성능으로 대용량 이벤트 데이터 분석 가능
    - Kafka와의 스트림 통합으로 실시간 데이터 ingestion
- **실시간 분석**: 대시보드 업데이트를 위한 스트림 처리 (스키마 발전의 필요성)
- **재처리 기능**: 과거 데이터를 재분석할 때 로그 리플레이 활용 (데이터 영속성)

분산 환경이 아니었어도, Kafka의 로그 기반 아키텍처가 데이터 재처리에 큰 도움이 되었다.

## 결론: 메시징 시스템은 부호화 철학의 실행 환경

DDIA 4장의 메시징 시스템 장은 단순한 기술 소개가 아니다. **데이터 부호화 철학의 실질적 테스트베드이자 구현체**다:

| 부호화 철학 | 메시징 시스템 구현 | ClickHouse 연결 |
|------------|-------------------|-----------------|
| 데이터 영속성 | 로그 기반 저장소 | 칼럼 기반 압축 저장 |
| 호환성 | Consumer Group & 스키마 발전 | 실시간 ingestion으로 호환성 보장 |
| 효율성 vs 유연성 | 브로커 선택의 트레이드오프 | OLAP 최적화로 분석 효율성 극대화 |
| API 디자인 | 이벤트 기반 아키텍처 | 스트림 처리로 이벤트 중심 설계 |

PostHog 경험을 통해 깨달은 점은: 메시징 시스템을 잘 이해하는 것은 곧 데이터 부호화의 철학을 체득하는 과정이었다. 특히 ClickHouse와 Kafka의 조합은 **칼럼 기반 압축(효율성) + 로그 기반 영속성(내구성) + 실시간 스트리밍(호환성)**의 완벽한 균형을 보여주었다. 분산 환경이 아니었어도, "데이터가 코드보다 오래 산다"는 원칙은 여전히 유효했다.

