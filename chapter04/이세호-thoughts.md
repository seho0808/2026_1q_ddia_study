## 왜 부호화를 언급할까?

- 모든 데이터를 주고 받는 베이스라서 초반 찹터에 언급하는듯함.
- 사실상 해당 챕터는, 네트워크 통신의 모든 프로토콜과 형태를 다루기에 매우 중요한 챕터임.

## JSON vs MessagePack vs Protobuf 실제로 현업에서는?

책에서 언급되었다시피 MessagePack은 압축률 대비 가독성 저하 때문에 안쓰는 듯함.

실제 HTTP 송수신은 JSON raw로 주고 받는게 제일 흔함.

Protobuf는 효율적인 통신에서 자주 언급되곤 하는듯함. - grpc, 게임 서버 등

그림이 이해가 안돼요... 그러면 핵심은?

- Message Pack 그림: 핵심은, MessagePack은 JSON raw에 비해서 조금이라도 줄일 수 있음.
  - `,` `:` `{` `"` 같은 구분자 제거
  - 숫자의 경우 스트링처럼 저장되는게 아니라 비트 숫자로 압축되어서 저장됨.
- Protobuf 그림: 핵심은, protobuf에는 필드명이 아예 없음. 송수신자가 각각 실제 필드명을 스키마로 소유하고 있음.

| 비교 항목       | JSON                         | Protobuf                                   |
| :-------------- | :--------------------------- | :----------------------------------------- |
| **주요 목적**   | 가독성, 범용성, 개발 속도    | 성능, 비용 절감, 시스템 안정성             |
| **적합한 곳**   | 공공 API, 웹 프론트엔드 통신 | 마이크로서비스 간 통신 (gRPC), 모바일 게임 |
| **데이터 크기** | 큼 (100%)                    | 매우 작음 (20~50%)                         |
| **CPU 부하**    | 높음                         | 매우 낮음                                  |

- 데이터 크기가 훨씬 작아서 네트워크 비용이랑 송수신 속도 빠르다는 장점이 있음.
- 또, 파싱에 사용되는 cpu 부하도 훨씬 낮다고함! (쌩 스트링 파싱인 JSON에 비해 훨씬 가벼움)

그래서 1위는 네트워크 비용! 2위는 스키마 맞추어서 실수 없음!(이건 json도되긴함.) 3위는 속도나 cpu 부하 절감!

실제로 본 케이스:

- 네트워킹에서 만난 지인분이 신의탑 모바일 게임 개발 => protobuf + node로 만드심.
  - 게임은 0.1초의 반응 속도(Latency)가 중요하고, 모바일 데이터(LTE/5G)를 사용하므로 패킷 크기를 줄이는 게 사용자 경험과 직결됩니다. 이건 선택이 아니라 생존의 문제라 Protobuf(혹은 FlatBuffers)가 정답입니다.
- 사내 grpc는 진짜 많이 봄. => 근데 과연 비용 절감에 도움이 될지 의문.

진짜로 비용절감이 될까?:

- 사실 수천대의 서버가 통신하는 환경이 아니고서 십수대 정도의 서버가 통신하는 100명 미만 스타트업 규모에서는 오버킬일 가능성이 높음. 심지어 수십대 ~ 수백대도 조건에 따라 애매함. 실제로 금액 차이가 크려면 http 네트워크 비용이 개발자 공수 추가 비용보다 훨씬 커야되는데, 애매한 경우가 많음.
- 그래서 gRPC 도입 전에 심각한 재고가 필요함.

- 현실적인 결론: 트래픽 비용 절감보다는 "타입 안정성(Type Safety)" 때문에 도입하는 경우가 많습니다.

  - JSON: 프론트엔드: "어? userId가 왜 숫자가 아니라 문자열로 와요?" (에러 펑!)
  - gRPC: 컴파일 단계에서 에러가 나므로 배포 전에 실수를 막아줍니다. (소통 비용 절감)

- 마이크로서비스(MSA)의 유행: 서버끼리 통신할 때 HTTP/1.1(JSON)은 연결을 맺고 끊는 비용이 비쌉니다. gRPC는 한 번 연결해놓고 계속 쓰니까(HTTP/2) 내부 트래픽이 많은 구조에서는 확실히 빠릅니다.

- 하지만 디버깅 지옥: JSON은 curl 때리거나 크롬 개발자 도구로 보면 보이는데, gRPC는 바이너리라 눈에 안 보입니다. 전용 툴이 없으면 개발 생산성이 뚝 떨어집니다.

### 최종 결론:

- JSON: 그냥 이거 쓰세요. (99%의 상황에서 정답, 특히 초기 스타트업)
- Protobuf (gRPC):
  - 서버가 수십 대 이상이고 내부 통신이 엄청 많을 때.
  - 모바일 게임처럼 패킷 크기/반응 속도가 목숨줄일 때.
  - 프론트/백엔드 간에 데이터 타입 때문에 맨날 싸울 때 (자동화 도구로 해결).
- MessagePack: "JSON보다는 빠르고 싶고, Protobuf처럼 스키마 짜기는 귀찮을 때" (Redis 저장용 등으로 소소하게 사용).

## 엥 Avro는 뭐지 어디서 들어본 것 같긴한데...

- 한 줄 요약: protobuf인데 스키마 정의를 실시간으로 함. 즉, 통신 중 언젠가 스키마를 전달해줌.
- 오 좋아보이긴 하는데 그럼 왜 이걸로 통일 안함?: Avro가 '데이터 저장(Data at Rest)'에는 최강이지만 '실시간 통신(Data in Motion)'에서는 애매하게 불편하기 때문임.

1. "계약(Contract)"의 부재: API는 엄격해야 제맛

마이크로서비스 간 통신(gRPC 등)에서는 **"엄격함"**이 생명입니다.

Protobuf: .proto 파일이 법입니다. A서버와 B서버가 컴파일 시점에 완벽하게 합의를 봅니다. 코드가 안 맞으면 빌드조차 안 됩니다. (안전함)

Avro: "스키마가 나중에 바뀔 수도 있어~"라는 유연함이 장점입니다. 하지만 API 통신에서 갑자기 들어오는 데이터 구조가 바뀌면, 받는 쪽 서버 코드가 런타임에 터질 위험이 큽니다.

개발자 멘붕: "아니, 컴파일 때는 멀쩡했는데 왜 실행하니까 필드 없다고 에러나?"

2. 인프라가 하나 더 필요함 (Schema Registry)

Avro를 제대로(가볍게) 쓰려면 통신할 때 스키마 본체를 보내는 게 아니라 Schema ID: 123만 보냅니다.

그러려면 **중앙에서 스키마를 관리해주는 서버(Schema Registry)**를 또 띄우고 관리해야 합니다.

단순히 서버 두 대 통신하자고 별도의 DB/서버를 또 구축한다? 배보다 배꼽이 더 큽니다. (Protobuf는 파일만 공유하면 끝)

3. 언어 지원과 생태계 (Java 편애)

Avro는 Hadoop(하둡) 생태계에서 태어났습니다. 그래서 Java 진영에서는 아주 잘 돌아가지만, 다른 언어(C++, Python, Go 등)에서는 라이브러리 지원이 Protobuf만큼 매끄럽지 않거나 성능 최적화가 덜 된 경우가 많습니다.

반면 Protobuf는 구글이 "모든 언어에서 다 되게 만들어"라며 밀어서 C++, Go, Java 등등 어디서든 잘 붙습니다.

| 구분        | JSON               | Protobuf (gRPC)           | Avro                                 |
| ----------- | ------------------ | ------------------------- | ------------------------------------ |
| 핵심 철학   | 사람이 읽어야지!   | 빠르고 엄격하게 통신하자! | 대량 데이터를 유연하게 쌓자!         |
| 주 사용처   | 웹, 앱 통신 (HTTP) | 서버 간 실시간 통신 (MSA) | Kafka, Hadoop (빅데이터 저장)        |
| 스키마 위치 | 없음 (자유방임)    | 코드 안에 컴파일됨 (엄격) | 데이터 파일 헤더나 레지스트리 (유연) |
| 장점        | 개발 속도 1등      | 통신 속도/안전성 1등      | 스키마 변경 대응/압축률 1등          |

### 결론: Avro를 보게 될 곳

- 아마 일반적인 백엔드 API 개발(Spring, Node.js 등)에서는 Avro를 볼 일이 거의 없을 겁니다. Avro는 다음과 같은 상황에서 **사실상의 표준(De facto standard)**입니다.
  - Kafka(카프카): 메시지 큐에 데이터를 흘려보낼 때. (Schema Registry랑 짝꿍)
  - 데이터 레이크(Hadoop, S3): 로그 파일 수 억 개를 파일로 저장해둘 때.

## DB 마이그레이션

- 우리 회사는 데이터 양이 그렇게까지 많지 않아서 한 번에 마이그레이션 스크립트를 돌려도 큰 이상이 없는 적이 많았음.

- 커질 경우에는:
  - 단계 1: 코드에서 처리 (Lazy Migration)
    - 신버전 코드가 DB를 읽을 때, 데이터가 없으면(NULL) 기본값을 반환하거나 실시간으로 계산해서 보여주도록 짭니다. 사용자 입장에서는 업데이트된 것처럼 보입니다.
  - 단계 2: 실시간 업데이트 (On-the-fly)
    - 사용자가 자기 정보를 수정하거나 접근할 때, 그 사용자의 데이터만 콕 집어서 신규 스키마로 업데이트합니다.
  - 단계 3: 백필 (Background Backfill)
    - 서비스 이용이 적은 새벽 시간대에, 아직 업데이트되지 않은 나머지 과거 데이터들을 조금씩(Batch 단위로) 나누어 업데이트합니다. 이것이 바로 앞에서 이야기한 백필입니다.

## RPC는 스타트업이나 엔터프라이즈에서 실무에서 쓰일일이 있나

gRPC 외에 쓰이는 RPC들

#### ① Apache Thrift (페이스북/카카오 등)

특징: 페이스북(현 Meta)에서 개발한 RPC 프레임워크. gRPC와 구조적으로 매우 유사함.

상황: gRPC가 나오기 전 대규모 MSA를 구축했던 기업(카카오, 라인 등)들이 이미 기반 시스템으로 사용 중임. gRPC만큼 생태계가 크진 않지만, 성능은 대등함.

#### ② Apache Avro (데이터 파이프라인)

특징: 하둡(Hadoop) 생태계에서 나온 RPC. 스키마와 데이터를 같이 보냄.

상황: Kafka나 데이터 분석 플랫폼에서 대량의 데이터를 주고받을 때 주로 씀. 서비스 간 통신보다는 "데이터 전송"에 특화된 RPC 스타일임.

#### ③ JSON-RPC / XML-RPC

특징: 복잡한 IDL(Interface Definition Language) 없이 JSON이나 XML로 RPC 느낌을 냄.

상황: 블록체인 노드 통신(Ethereum 등)에서 표준처럼 쓰임. "이 함수 실행해줘"라는 명령을 JSON에 담아 보내는 방식임.

#### ④ tRPC (Full-stack TypeScript)

특징: 최근 스타트업 씬에서 가장 핫함. Protobuf 같은 복잡한 설정 없이 TypeScript 타입만으로 서버-클라이언트 간 타입을 공유함.

상황: 프론트(Next.js)와 백엔드(Node.js)를 모두 TypeScript로 짤 때 생산성이 미쳤음. gRPC의 번거로움을 걷어낸 RPC 스타일임

| 프로토콜 | 주도 세력     | 성능 | 사용 편의성      | 현재 점유율       |
| -------- | ------------- | ---- | ---------------- | ----------------- |
| gRPC     | Google        | 최상 | 보통 (도구 많음) | 압도적 1위        |
| Thrift   | Meta (Apache) | 최상 | 어려움           | 레거시/대기업     |
| tRPC     | 커뮤니티      | 보통 | 매우 쉬움        | 신규 스타트업     |
| Avro     | Apache        | 최상 | 복잡함           | 데이터 엔지니어링 |

## Temporal / Cadence

### 1. 현재 회사 페인포인트 (AS-IS)

- **분산 서버 통신 지옥:** 메인 서버랑 크롤링 서버가 따로 노는데, 한쪽 죽으면 데이터 꼬이고 상태 체크 로직 짜느라 코드만 길어짐.
- **LLM 호출의 불안정성:** LLM 응답 느리고 가끔 터지는데, 이거 관리하려고 별도 Job 테이블 만들고 스케줄러 돌리는 게 너무 비효율적임.
- **상태 값 노가다:** DB에 `PENDING`, `PROCESSING`, `SUCCESS` 일일이 업데이트하고 예외 처리하는 '상태 관리 코드'가 비즈니스 로직보다 많아짐.
- **Outbox 패턴 유지비:** DB 트랜잭션이랑 메시지 발행 맞추려고 Outbox 테이블 관리하는 것도 다 인프라 리소스 낭비임.

### 2. Temporal/Cadence 도입 후 변화 (TO-BE)

- **Job 테이블 삭제 가능:** Temporal 자체가 실행 상태를 DB에 다 기록(Event History)해주므로 별도 Job 테이블 필요 없음.
- **무한 재시도 (Durable Execution):** LLM 타임아웃 나면 코드 한 줄(`RetryPolicy`)로 자동 재시도됨. 서버 꺼졌다 켜져도 멈췄던 지점부터 다시 시작함.
- **상태 관리 자동화:** "지금 크롤링 어디까지 됐나?" 궁금하면 Temporal UI 들어가서 바로 확인 가능. 코드로 상태 업데이트 칠 필요 없음.
- **Outbox 안녕:** "DB 저장 성공 시에만 알림 발송" 같은 로직을 Temporal 워크플로가 보장해주므로 Outbox 패턴 안 써도 됨.

### 3. 핵심 메커니즘 요약

- **워크커(Worker) 방식:** 코드는 우리 서버에서 도는데, Temporal은 "어디까지 실행했는지" 로그(WAL)만 자기 DB에 기록함.
- **폴링(Polling) 구조:** 우리 서버가 Temporal한테 "할 일 있어?" 물어보고 가져오는 방식이라 방화벽 문제나 통신 결합도가 낮음.
- **결정론적 로직:** 대신 워크플로 코드 안에서 `random()`이나 `time.now()` 쓸 때만 주의하면 됨(Temporal 전용 함수 써야 함).

---

### 4. 스타트업 적용 전략

- **1순위 (LLM):** 가장 머리 아픈 LLM 호출부부터 Temporal로 옮겨서 Job 테이블이랑 재시도 로직 걷어내기.
- **2순위 (분산 작업):** 크롤링 서버랑 메인 앱 사이의 상태 동기화 로직을 Temporal 워크플로로 통합.
- **운영 팁:** 인력 부족하면 직접 띄우지 말고 Temporal Cloud(SaaS) 써서 운영 공수 줄이는 거 추천함.
