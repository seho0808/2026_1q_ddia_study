# Chapter 4. 저장소와 검색 (Storage and Retrieval)

> **참고**: 이 문서는 DDIA 2nd Edition Draft의 Chapter 4 (1판의 Chapter 3) 내용을 바탕으로, 핵심 흐름과 예시를 보존하며 가독성을 높이기 위해 재구성한 요약입니다.

데이터베이스의 본질은 간단합니다. **데이터를 넣고(Store), 나중에 다시 찾는(Retrieve)** 것입니다. 애플리케이션 개발자가 내부 엔진을 직접 구현할 일은 드물지만, **내 워크로드에 맞는 엔진을 선택하고 튜닝하기 위해서는 내부 동작 원리(특히 로그 구조와 페이지 구조의 차이)를 이해해야 합니다.**

이 챕터는 크게 **OLTP(트랜잭션)**를 위한 저장소 엔진과 **OLAP(분석)**를 위한 저장소 엔진으로 나뉩니다.

---

## 1. OLTP를 위한 데이터 구조 (Data Structures for OLTP)

### 1.1 가장 단순한 데이터베이스: 로그(Log)

데이터베이스의 가장 기본적인 형태는 텍스트 파일에 데이터를 계속 덧붙이는(Append-only) 것입니다. 아래와 같은 간단한 Bash 함수로도 데이터베이스를 구현할 수 있습니다.

```bash
#!/bin/bash
db_set () {
    echo "$1,$2" >> database # 파일 끝에 키,값 추가
}

db_get () {
    grep "^$1," database | sed -e "s/^$1,//" | tail -n 1 # 키로 검색 후 마지막 값 반환
}
```

- **동작 원리**: `db_set`은 파일 끝에 데이터를 추가하고, `db_get`은 파일을 처음부터 끝까지 스캔하여 해당 키의 마지막(최신) 값을 찾습니다.
- **성능 특성**:
  - **쓰기(Write)**: 매우 빠름. (파일 끝에 추가하는 것은 디스크에서 가장 효율적인 작업 중 하나)
  - **읽기(Read)**: 매우 느림. (데이터가 늘어날수록 검색 시간도 O(n)으로 비례하여 증가)

> **전환점**: 쓰기는 빠르지만 읽기가 너무 느립니다. 읽기 속도를 높이기 위해 **인덱스(Index)**라는 별도의 메타데이터 구조가 필요해집니다.

---

### 1.2 해시 인덱스 (Hash Index)

로그 방식의 읽기 속도 문제를 해결하는 가장 직관적인 방법은 **"어떤 키가 파일의 어디(Offset)에 저장되어 있는지"**를 메모리에 기록해두는 것입니다.

- **구조**: 인메모리 해시 맵(Hash Map)에 `Key: Byte Offset`을 저장합니다.
- **동작**:
  - **쓰기**: 로그 파일에 데이터를 추가하면서, 해시 맵의 오프셋도 갱신합니다.
  - **읽기**: 해시 맵에서 오프셋을 찾아 디스크의 해당 위치로 바로 이동(Seek)하여 데이터를 읽습니다.
- **장단점**:
  - **장점**: 키를 알면 단 한 번의 디스크 접근으로 데이터를 가져올 수 있어 매우 빠릅니다. (예: Bitcask)
  - **단점**:
    1.  **메모리 제약**: 모든 키가 RAM에 들어가야 합니다. 키가 너무 많으면 사용할 수 없습니다.
    2.  **범위 쿼리 불가**: "1000부터 2000 사이의 키" 같은 범위 검색은 불가능하며, 개별 조회를 해야 합니다.

> **전환점**: 해시 인덱스는 메모리 용량의 한계가 있고 범위 검색이 안 된다는 단점이 있습니다. 이를 해결하기 위해 **키를 정렬해서 저장**하는 방법을 고안하게 됩니다. 이것이 **SSTable**과 **LSM-Tree**입니다.

---

### 1.3 SSTable과 LSM-Tree

해시 인덱스의 한계를 극복하기 위해, 저장 파일 내부의 키-값 쌍을 **키 순서대로 정렬**하여 저장하는 방식을 **SSTable (Sorted String Table)**이라고 합니다.

#### SSTable이 해결하는 것

1.  **희소 인덱스(Sparse Index) 가능**: 파일이 정렬되어 있으므로 모든 키의 위치를 알 필요가 없습니다. `handbag`과 `handsome`의 위치만 알면, 그 사이에 있는 `handiwork`는 대략 어디쯤 있는지 알 수 있습니다. 따라서 **인덱스를 메모리에 적게 올릴 수 있습니다.**
2.  **범위 쿼리 효율성**: 정렬되어 있으므로 특정 범위의 키들을 순차적으로 스캔하기 좋습니다.

#### LSM-Tree (Log-Structured Merge-Tree) 동작 흐름

하지만, 파일에 순차적으로 쓰면서 정렬 상태를 유지하는 것은 불가능합니다(중간에 끼워넣어야 하니까요). 그래서 **쓰기는 메모리에서, 저장은 디스크에서** 하는 전략을 취합니다.

1.  **쓰기 (Memtable)**: 요청이 들어오면 먼저 메모리 내의 **Memtable**(Red-Black Tree 등 정렬된 구조)에 저장합니다.
2.  **플러시 (Flushing)**: Memtable이 가득 차면, 이를 그대로 디스크에 써서 **SSTable 세그먼트** 파일을 만듭니다. (파일 내부는 이미 정렬됨)
3.  **읽기 (Read)**: `Memtable` -> `최신 세그먼트` -> `오래된 세그먼트` 순서로 찾습니다.
4.  **병합과 압축 (Compaction)**: 백그라운드에서 여러 세그먼트 파일들을 병합(Merge Sort 방식)하여 중복된 키를 제거하고 삭제된 데이터(Tombstone)를 정리합니다.

- **Bloom Filter**: 존재하지 않는 키를 찾느라 여러 세그먼트를 뒤지는 낭비를 막기 위해, 키의 존재 여부를 확률적으로 확인하는 Bloom Filter를 사용하여 읽기 성능을 최적화합니다.

> **전환점**: 지금까지 본 로그 구조(Log-Structured) 방식은 **파일을 한 번 쓰면 수정하지 않고(Immutable), 새로운 파일로 덮어쓰거나 병합**하는 방식이었습니다. 하지만 가장 널리 쓰이는 또 다른 방식은 **파일의 내용을 직접 수정(Update-in-place)**하는 방식입니다. 바로 **B-Tree**입니다.

---

### 1.4 B-Tree

B-Tree는 관계형 데이터베이스(RDBMS)의 표준이자 가장 널리 사용되는 인덱스 구조입니다.

- **구조적 특징**:
  - 가변 크기의 세그먼트 대신, **고정 크기의 페이지(Page, 보통 4KB)** 단위로 디스크를 관리합니다.
  - 페이지들이 포인터처럼 서로를 참조하는 트리 구조를 이룹니다.
- **동작 방식**:
  - **검색**: 루트 페이지부터 시작해 키 범위를 따라 자식 페이지로 내려가며 리프(Leaf) 페이지를 찾습니다.
  - **수정(Update)**: 해당 키가 포함된 페이지를 찾아 내용을 바꾼 뒤, **디스크의 같은 위치에 다시 씁니다(Overwrite).**
  - **분할(Split)**: 페이지가 꽉 차면 둘로 나누고 상위 페이지를 갱신합니다. 트리는 항상 균형(Balanced)을 유지합니다.
- **신뢰성(Reliability)**: 덮어쓰기 도중 장애가 발생하면 데이터가 깨질 수 있습니다. 이를 방지하기 위해 변경 사항을 먼저 **WAL (Write-Ahead Log)**에 기록하여 복구 가능성을 보장합니다.

---

### 1.5 B-Tree vs LSM-Tree 비교

두 엔진은 각각의 철학에 따라 성능 특성이 명확히 갈립니다.

| 비교 항목       | LSM-Tree (로그 구조)                                           | B-Tree (페이지 구조)                                            |
| :-------------- | :------------------------------------------------------------- | :-------------------------------------------------------------- |
| **쓰기 패턴**   | **순차 쓰기 (Sequential Write)**<br>파일 끝에 추가하므로 빠름. | **랜덤 쓰기 (Random Write)**<br>페이지 위치를 찾아 덮어써야 함. |
| **쓰기 성능**   | **우수** (Write-Heavy에 적합)                                  | 상대적으로 낮음 (페이지 분할, WAL 작성 오버헤드)                |
| **읽기 성능**   | 상대적으로 느림 (여러 세그먼트 확인 필요)                      | **우수** (일정한 깊이, 예측 가능한 성능)                        |
| **데이터 상태** | 불변 (Immutable)                                               | 가변 (Mutable)                                                  |
| **공간 효율**   | 압축이 용이하고 파편화가 적음                                  | 페이지 내 미사용 공간(Fragmentation) 발생                       |

---

### 1.6 기타 인덱싱 전략

- **보조 인덱스 (Secondary Index)**: PK 외의 컬럼으로 검색할 때 사용. 인덱스의 값은 실제 데이터가 있는 힙 파일(Heap File)의 위치를 가리키거나, PK 자체를 가리킵니다.
- **클러스터형 인덱스 (Clustered Index)**: 인덱스 리프 노드에 아예 **테이블 데이터 전체**를 저장합니다. (예: InnoDB의 PK). 읽기는 빠르지만 저장 공간을 많이 씁니다.
- **인메모리 DB**: 모든 데이터를 RAM에 둡니다. 디스크 기반 DB와 달리, 데이터를 디스크에 쓰기 위한 **직렬화/인코딩 오버헤드가 없어서** 더 빠릅니다. (단순히 RAM이라서 빠른 게 아님)

---

## 2. 분석을 위한 데이터 저장 (Data Storage for Analytics)

OLTP 데이터베이스는 "주문 내역 조회" 같은 트랜잭션에는 강하지만, "지난 1년간 과일 판매량 집계" 같은 **분석(Analytics)** 쿼리에는 비효율적입니다. OLTP는 행(Row) 단위로 저장되어 있어, 몇 개의 컬럼만 필요해도 **모든 행 데이터를 메모리에 로드**해야 하기 때문입니다.

이 때문에 **데이터 웨어하우스(Data Warehouse)**라는 별도의 분석용 저장소가 등장했습니다.

### 2.1 데이터 웨어하우스 아키텍처의 진화

겉보기에는 데이터 웨어하우스와 OLTP 데이터베이스 모두 SQL 인터페이스를 사용하므로 비슷해 보입니다. SQL은 분석 쿼리에도 매우 적합하기 때문입니다. 하지만 **내부 엔진은 완전히 다른 쿼리 패턴을 처리하기 위해 다르게 최적화**되어 있습니다.

- **HTAP (Hybrid Transactional and Analytical Processing)**: Microsoft SQL Server, SAP HANA 등 일부 제품은 트랜잭션과 분석을 하나의 제품에서 지원하기도 합니다. 하지만 최신 트렌드는 두 엔진을 분리하되 공통 SQL 인터페이스로 접근하게 하는 방식입니다.
- **클라우드 데이터 웨어하우스 (Cloud Data Warehouses)**: Google BigQuery, Amazon Redshift, Snowflake 등은 클라우드 인프라(객체 저장소 등)를 활용합니다. 이들은 **저장소(Storage)와 연산(Compute)을 분리**하여, 데이터 양이나 쿼리 부하에 따라 자원을 독립적으로 확장(Elastic)할 수 있는 장점이 있습니다.

### 2.2 모듈화된 오픈소스 분석 스택 (The Unbundled Data Stack)

과거의 데이터 웨어하우스(예: Apache Hive)가 통합된 시스템이었다면, 최근의 데이터 레이크(Data Lake) 아키텍처는 각 구성 요소가 분리되어 발전하고 있습니다.

1.  **쿼리 엔진 (Query Engine)**: SQL을 파싱하고 최적화하여 실행 계획을 만듭니다. (예: Trino, Presto, Apache Spark, Flink, DataFusion). 실행은 자체적으로 하거나 다른 프레임워크에 위임하기도 합니다.
2.  **저장소 포맷 (Storage Format)**: 데이터를 파일(주로 객체 저장소)에 어떻게 바이트로 인코딩할지 정의합니다. (예: **Parquet**, ORC, Lance, Nimble).
3.  **테이블 포맷 (Table Format)**: 파일들의 집합을 '테이블'로 정의하고 스키마를 관리합니다. 특히 Parquet 같은 불변(Immutable) 파일 위에서 삽입/삭제/수정을 지원하고, **타임 트래블(Time Travel)**이나 트랜잭션 기능을 제공합니다. (예: **Apache Iceberg**, Delta Lake).
4.  **데이터 카탈로그 (Data Catalog)**: 어떤 테이블들이 데이터베이스를 구성하는지 정의하고 메타데이터를 관리합니다. (예: Snowflake Polaris, Databricks Unity Catalog, Iceberg Catalog). 최근에는 카탈로그가 분리되어 데이터 거버넌스 시스템에서도 접근 가능해졌습니다.

### 2.3 컬럼 지향 저장소 (Column-Oriented Storage)

분석 쿼리는 보통 테이블의 100개 컬럼 중 4~5개만 사용합니다. 이를 위해 **데이터를 행(Row)이 아닌 열(Column) 단위로 모아서 저장**합니다.

- **핵심 아이디어**: 각 컬럼을 별도의 파일(또는 블록)에 저장합니다.
- **장점**: 쿼리에 필요한 컬럼만 디스크에서 읽으면 되므로 I/O 대역폭을 획기적으로 절약할 수 있습니다.

### 2.4 압축과 정렬 (Compression and Sorting)

컬럼 저장소는 같은 데이터 타입의 값들이 연속되므로 압축 효율이 매우 좋습니다.

- **비트맵 인코딩 (Bitmap Encoding)**:
  - 컬럼의 고유 값(Cardinality)이 적을 때 (예: 국가 코드, 상품 카테고리), 각 값에 대해 비트맵(행 존재 여부 0/1)을 만듭니다.
  - `WHERE product_sk IN (30, 31)` 같은 쿼리는 비트맵 간의 **Bitwise OR/AND 연산**으로 매우 빠르게 처리됩니다.
- **정렬 순서 (Sort Order)**:
  - 데이터를 로드할 때 주요 컬럼(예: 날짜) 기준으로 정렬해서 저장하면, 중복 값이 연속되어 **런 렝스(Run-length) 압축** 효율이 극대화됩니다.
  - 또한 `날짜`로 정렬되어 있다면, 특정 기간을 조회할 때 불필요한 블록을 건너뛸 수 있습니다. (Min/Max 인덱스 활용)

### 2.5 컬럼 저장소의 쓰기

컬럼 저장소는 중간에 데이터를 끼워넣기가 매우 어렵습니다 (모든 컬럼 파일을 밀어내야 함). 따라서 **LSM-Tree 방식**을 차용합니다.

- 쓰기는 메모리 내 저장소(Row-oriented)에 모았다가, 충분히 쌓이면 디스크의 컬럼 파일과 병합(Merge)하여 새로운 파일로 기록합니다. 분석가는 쿼리 시 이 둘을 합쳐서 결과를 봅니다.

### 2.6 쿼리 실행: 컴파일과 벡터화 (Query Execution: Compilation and Vectorization)

데이터 웨어하우스 쿼리는 수백만, 수십억 건의 행을 스캔해야 하므로 디스크 I/O뿐만 아니라 **CPU 처리 속도** 또한 중요한 병목이 됩니다. SQL 쿼리는 여러 **연산자(Operator)** 단계로 분해되어 실행되는데, 단순한 인터프리터 방식(한 행씩 읽어서 처리)은 루프 오버헤드와 함수 호출 비용 때문에 분석용으로는 너무 느립니다.

이를 해결하기 위해 최신 DB 엔진들은 크게 두 가지 접근 방식을 사용합니다.

#### 1. 쿼리 컴파일 (Query Compilation / JIT)

쿼리 엔진이 **실행 시점에 해당 SQL 쿼리에 최적화된 기계어 코드를 생성**하는 방식입니다.

- **동작**: 쿼리의 조건(예: `x > 15`)을 처리하는 코드를 생성하고, 이를 LLVM 등으로 컴파일하여 실행합니다.
- **특징**: 일반적인 프로그래밍 언어의 컴파일러처럼 동작하며, 반복문 안에서 불필요한 함수 호출이나 분기를 제거하여 매우 빠른 속도를 냅니다. (Java의 JIT 컴파일과 유사)
- **장점**: 각 쿼리에 딱 맞는 타이트한 루프(Tight Loop)를 만들어 CPU 파이프라인 효율을 극대화합니다.

#### 2. 벡터화 처리 (Vectorized Processing)

쿼리를 컴파일하는 대신, **한 번에 하나의 값(Row)이 아니라 값의 배치(Batch, 벡터)를 처리**하는 방식입니다.

- **동작**: 미리 정의된 연산자(Equality, GreaterThan 등)에 컬럼 데이터의 덩어리(Vector)를 넘깁니다.
- **예시**:
  1. `상품=바나나` 연산자에 상품 ID 컬럼 벡터를 넘김 → 결과: `[0, 1, 0, ...]` (비트맵)
  2. `상점=A` 연산자에 상점 ID 컬럼 벡터를 넘김 → 결과: `[1, 1, 0, ...]`
  3. 두 비트맵을 **Bitwise AND** 연산 → 최종 결과 도출
- **장점**: 함수 호출 횟수를 획기적으로 줄이고(배치당 1회), CPU의 SIMD(Single Instruction Multi Data) 명령어를 활용하기 좋습니다.

#### 성능 최적화의 공통점

두 방식은 구현은 다르지만, 현대 CPU의 특성을 활용한다는 점에서 목표가 같습니다.

1. **순차 메모리 접근 (Sequential Access)**: CPU 캐시 적중률(Cache Hit)을 높입니다.
2. **타이트한 내부 루프 (Tight Inner Loop)**: 분기 예측 실패(Branch Misprediction)를 줄이고 파이프라인을 가득 채웁니다.
3. **병렬성 활용**: 멀티 스레드 및 SIMD 명령어를 사용합니다.
4. **압축 데이터 직접 연산**: 메모리 대역폭을 아끼기 위해 압축을 풀지 않고 바로 연산합니다.

### 2.7 구체화된 뷰와 데이터 큐브 (Materialized Views and Data Cubes)

데이터 웨어하우스에서는 동일한 집계 쿼리(COUNT, SUM, AVG 등)가 반복적으로 사용되는 경우가 많습니다. 매번 수백만 건의 로우(Raw Data)를 다시 계산하는 것은 비효율적입니다. 이를 해결하기 위해 **쿼리 결과를 미리 계산해서 저장해두는 캐시** 전략을 사용합니다.

#### 구체화된 뷰 (Materialized View)

- **가상 뷰(Virtual View)와의 차이**:
  - 일반적인 뷰(Virtual View)는 쿼리를 작성하는 단축어(Shortcut)일 뿐입니다. 쿼리 실행 시점에 SQL 엔진이 이를 본문 쿼리로 확장하여 원본 데이터를 조회합니다.
  - **구체화된 뷰(Materialized View)**는 쿼리 결과의 **실제 복사본을 디스크에 물리적으로 저장**합니다.
- **특징**:
  - 읽기 속도가 매우 빠릅니다(이미 계산된 결과만 읽으면 됨).
  - 원본 데이터가 변경되면 구체화된 뷰도 갱신해야 하므로 **쓰기 비용(Write Overhead)**이 발생합니다.

#### 데이터 큐브 (Data Cube / OLAP Cube)

구체화된 뷰의 특별한 형태로, 다양한 **차원(Dimension)**에 따라 미리 집계된 값을 격자(Grid) 형태로 저장하는 것입니다.

- **구조 예시**: `날짜`와 `제품`이라는 2개 차원이 있다면, 2차원 테이블의 각 칸(Cell)에 '해당 날짜의 해당 제품 판매 합계'를 미리 저장해둡니다.
- **초차원 큐브 (Hypercube)**: 실제로는 날짜, 제품, 매장, 고객, 프로모션 등 5개 이상의 차원을 가지는 경우가 많습니다.
- **장점**: "어제 A 매장의 총 매출" 같은 쿼리는 수억 건의 데이터를 뒤질 필요 없이, 큐브에서 해당 차원의 합계 값만 조회하면 되므로 **즉각적인 응답**이 가능합니다.
- **단점 (Trade-off)**: **유연성이 떨어집니다.** 미리 지정된 차원(예: 날짜, 제품)이 아닌, "가격이 $100 이상인 물건의 판매 비중" 같은 임의의 조건으로 쿼리하려면 큐브를 사용할 수 없습니다.

> **결론**: 따라서 현대의 데이터 웨어하우스는 **최대한 원본 데이터(Raw Data)를 유지**하여 유연성을 확보하되, 자주 쓰이는 특정 쿼리의 성능 가속을 위해 데이터 큐브와 구체화된 뷰를 **보조적으로 사용**하는 전략을 취합니다.
> [1 tool called]

### **3. 특수 인덱스와 저장소 (Specialized Indexes and Storage)**

단순히 키(Key) 하나로 값을 찾거나, 전체 데이터를 집계하는 것만으로는 부족할 때가 있습니다. 지도상의 위치 검색, 텍스트 검색, 그리고 의미(Semantic) 검색이 대표적입니다.

#### **3.1 다차원 인덱스 (Multi-dimensional Indexes)**

B-Tree나 LSM-Tree는 기본적으로 **하나의 키(1차원)**만 효율적으로 검색할 수 있습니다.

- **문제점**: "위도 51.49 이상 **그리고** 경도 -0.11 이상인 식당 찾기" 같은 2차원 범위 검색을 하려면, 기존 인덱스로는 비효율적입니다 (하나를 먼저 찾고 나머지를 필터링해야 함).
- **해결책 (R-tree 등)**:
  - **공간 인덱스 (Spatial Index)**: 2차원(지도), 3차원(색상 RGB), 4차원(시공간) 데이터를 효율적으로 검색하기 위해 R-tree나 KD-tree 등을 사용합니다.
  - 이들은 공간을 사각형이나 격자로 나누어, **가까운 점들을 같은 서브트리에 그룹화**합니다.
  - PostGIS, Elasticsearch 등이 이를 지원하여 "내 주변 5km 식당" 같은 쿼리를 빠르게 처리합니다.

#### **3.2 전문 검색 (Full-Text Search)**

"책 제목에 'Database'가 포함된 모든 책 찾기"는 단순 일치(Equality)가 아니라 **포함 여부**를 따지는 검색입니다.

- **역색인 (Inverted Index)**:
  - 문서의 단어(Term)를 키로, 그 단어가 포함된 문서 ID 리스트(Postings List)를 값으로 저장하는 구조입니다.
  - `"apple" -> [Doc1, Doc3]`, `"red" -> [Doc2, Doc3]`
  - "red apple"을 검색하면 두 리스트의 **교집합(Bitwise AND)**을 구하면 됩니다. (이 과정은 앞서 본 비트맵 인덱스 처리와 유사합니다.)
- **고급 기능**: 단순 단어 매칭을 넘어, 철자 오류(Fuzzy Search, Levenshtein distance), 동의어 처리 등을 위해 트라이(Trie)나 오토마타 기반의 확장을 사용합니다 (예: Lucene).

#### **3.3 벡터 임베딩과 시맨틱 검색 (Vector Embeddings)**

사용자가 "계약 해지"를 검색했을 때, 정확히 그 단어가 없어도 의미가 같은 "구독 취소" 페이지를 찾아주려면 어떻게 해야 할까요?

- **벡터 임베딩 (Vector Embedding)**:
  - 텍스트, 이미지, 오디오 등의 의미(Semantics)를 AI 모델(BERT, GPT 등)을 통해 **고차원 벡터(숫자 배열)**로 변환합니다.
  - 의미가 비슷한 문서는 벡터 공간에서 서로 **가까운 거리**에 위치하게 됩니다.
- **벡터 검색 (Vector Search)**:
  - 사용자 질문을 벡터로 변환한 뒤, 저장된 벡터들 중 가장 거리가 가까운(유사한) 것들을 찾습니다 (k-NN).
  - 하지만 수억 개의 벡터와 거리를 일일이 계산하는 것은 너무 느리므로, **근사 검색(ANN, Approximate Nearest Neighbor)** 알고리즘을 사용합니다.
    - **HNSW (Hierarchical Navigable Small World)**: 그래프 기반으로 가까운 이웃을 탐색.
    - **IVF (Inverted File)**: 공간을 여러 파티션으로 나누어 검색 범위를 좁힘.

---

### **마무리 (Chapter Summary)**

이 챕터에서는 데이터베이스가 데이터를 저장하고 찾는 다양한 방법을 살펴보았습니다.

1.  **OLTP (트랜잭션)**: 대량의 작은 요청을 빠르게 처리.
    - **로그 구조 (LSM-Tree)**: 쓰기 성능 우수. (Append-only)
    - **페이지 구조 (B-Tree)**: 읽기 성능 우수. (Update-in-place)
2.  **OLAP (분석)**: 소수의 복잡한 대량 조회 쿼리.
    - **컬럼 저장소**: 필요한 컬럼만 읽고 압축하여 I/O 최소화.
3.  **특수 목적**:
    - **다차원 인덱스**: 위치 기반 검색.
    - **역색인**: 텍스트 키워드 검색.
    - **벡터 인덱스**: AI 기반 의미 검색.

**애플리케이션 개발자로서 이 내부 구조를 이해하면, 내 서비스에 어떤 DB가 적합한지 판단하고 튜닝하는 데 큰 통찰력을 얻을 수 있습니다.**
