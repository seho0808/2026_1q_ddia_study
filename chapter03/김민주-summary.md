# 📌 Chapter 3. 저장소와 검색

## 1. 데이터베이스의 두 가지 핵심 작업

**저장(Store)**
- 애플리케이션이 데이터를 넣으면 안전하게 저장
- 데이터 무결성 보장
- 내구성(Durability) 확보
**검색(Retrieve)** 
- 요청 시 다시 데이터를 찾아 제공
- 빠른 응답 시간
- 효율적인 리소스 사용
    
    → 이 두 작업을 어떻게 처리하느냐에 따라 **DB 엔진의 특성**이 갈림
    

---

## 2. 저장소 엔진(Storage Engine) 선택의 중요성

- 개발자가 직접 구현하기보다 **기존 엔진 중 적합한 것**을 선택하는 것이 일반적
- 작업 부하 유형에 따라 엔진 특성이 다름
    - **트랜잭션 처리(OLTP)** → 다수의 작은 읽기/쓰기 요청
    최적화 방향 : 낮은 지연시간, 높은 동시성
    - **분석 처리(OLAP)** → 대규모 스캔/집계 쿼리
    최적화 방향 : 높은 처리량, 압축 효율
- 내부 동작 원리를 이해하면 성능 최적화 및 튜닝 가능

---

## 3. 로그 구조(Log-Structured) vs 페이지 구조(Page-Oriented, B-Tree)

- 대부분의 저장소 엔진은 두 계열로 나눔
    1. **로그 구조 계열 (LSM-Tree, Bitcask 등)**
        특징:

        - Append-only 방식
        - 순차 쓰기 (Sequential Write)
        - 주기적 Compaction
            → 쓰기는 빠르지만(순차 I/O로 디스크 효율 높음), 읽기는 보조 구조(색인, 여러 세그먼트 검색)가 필요
        
    2. **페이지 지향 계열 (B-Tree 등)**
        특징:

        - 고정 크기 페이지(블록) 단위
        - In-place 업데이트
        - 디스크를 덮어쓰기 가능한 페이지 집합으로 취급
        장단점 : 안정적인 읽기 성능, 트랜잭션 지원 용이 / 무작위 쓰기 발생, Write Amplification
            → 디스크 페이지 단위로 수정 및 검색
        

---

## 4. 간단한 키-값 저장소 구현 예시

```bash
db_set() { echo "$1, $2" >> database }
db_get() { grep "^$1, " database | sed -e "s/^$1,//" | tail -n 1 }

```

- **db_set** : 파일 끝에 key-value 추가 (append-only)
- **db_get** : 가장 마지막 key 값 검색 → O(N)
- 장점: 단순, 빠른 쓰기
- 단점: 검색 시 비효율적 → 색인 필요

---

## 5. 색인(Index)의 필요성

- 색인은 데이터를 빠르게 찾기 위한 **추가 메타데이터 구조**
- 특징
    - **읽기 성능 ↑**
    - **쓰기 성능 ↓** (색인 갱신 필요)
    읽기 성능 향상:

특정 데이터를 O(1) 또는 O(log N)에 검색
범위 쿼리 효율화

**쓰기 성능 저하**

- 색인 구조 갱신 필요
- 추가 디스크 I/O
- 메모리 사용량 증가

**색인 선택의 책임**

- 데이터베이스는 모든 데이터에 자동으로 색인을 생성하지 않음
- 개발자/DBA가 질의 패턴에 따라 수동으로 선택
- 불필요한 색인은 성능 저하 원인

**일반적인 색인 선택 전략**

- Primary Key: 항상 색인 생성
- Foreign Key: 조인 성능을 위해 색인
- 자주 검색하는 컬럼: WHERE 절에 자주 등장하면 색인
- 범위 쿼리 컬럼: 날짜, 숫자 범위 검색 시 색인
- 정렬 기준 컬럼: ORDER BY에 사용되면 색인
- 개발자가 질의 패턴에 따라 **수동으로 적절한 색인 선택** 필요

---

## 6. 해시 색인(Hash Index)
구조
메모리에 해시맵 유지: Key → Byte Offset
```
In-Memory Hash Map:
┌─────────┬──────────┐
│ Key     │ Offset   │
├─────────┼──────────┤
│ user:1  │ 0        │
│ user:2  │ 64       │
│ user:3  │ 128      │
└─────────┴──────────┘

Disk (Append-Only Log):
┌──────────────────────────┐
│ user:1,Alice         (0) │
│ user:2,Bob          (64) │
│ user:3,Charlie     (128) │
└──────────────────────────┘
```
- 가장 단순한 색인 방식
- **구조** : `Key → 파일 오프셋(byte offset)` 매핑
- 장점: 특정 키 검색에 매우 빠름
- 단점:
    - 범위 검색 불가 (`kitty00000` ~ `kitty99999` 같은 범위 조회 ❌)
    - 키가 너무 많으면 메모리 한계 발생
**실제 사례: Bitcask - Riak의 기본 저장소 엔진**

**적합한 사용 사례**:

- 키 개수가 메모리에 들어갈 수 있을 때
- 각 키의 값이 자주 업데이트될 때
- 예: 비디오 URL의 조회수, 사용자 세션 데이터

**장점**:
- 쓰기 속도 매우 빠름 (O(1) append)
- 읽기 속도 빠름 (O(1) hash lookup + 1회 디스크 seek)
- 순차 쓰기로 HDD에서도 효율적
- Crash recovery 간단 (불변 세그먼트)
**단점**:
- 모든 키가 메모리에 있어야 함
- 범위 쿼리 불가능 (key:000 ~ key:999 같은 조회 불가)
- 키 개수 제한 (메모리 크기에 비례)
**해시 충돌 처리**
대부분의 구현에서는 Chaining 사용: 같은 해시 값을 가진 항목들을 링크드 리스트로 연결
---

## 7. 로그 세그먼트와 컴팩션(Compaction)

- 무한히 append-only 하면 **디스크 부족 문제**
- 해결: **세그먼트 분할 + 병합(compaction)**
    1. 일정 크기마다 로그를 세그먼트로 분리
    2. 백그라운드에서 **중복 제거 및 최신 값만 유지**
    3. 여러 세그먼트를 병합해 작은 수의 세그먼트 유지
- 추가 전용 설계 장점
    - 순차 쓰기 → 디스크 효율 ↑
    - 불변 세그먼트 → 동시성/복구 단순화
    - 조각화 문제 해결

---

## 8. LSM 트리 (Log-Structured Merge Tree)

```
Write Request
                  ↓
         ┌────────────────┐
         │   MemTable     │ ← 메모리 (Red-Black Tree)
         │  (Sorted Tree) │    크기: ~수 MB
         └────────┬───────┘
                  │ (Threshold 도달 시 Flush)
                  ↓
         ┌────────────────┐
         │   SSTable L0   │ ← 디스크
         │   (Newest)     │
         └────────┬───────┘
                  │ (Compaction)
                  ↓
         ┌────────────────┐
         │   SSTable L1   │
         └────────┬───────┘
                  │ (Compaction)
                  ↓
         ┌────────────────┐
         │   SSTable L2   │ ← 오래된 데이터
         │   (Oldest)     │
         └────────────────┘

Read Request:
MemTable → L0 → L1 → L2 (순서대로 검색)
```
- 로그 구조 + 정렬 세그먼트(SS테이블, Sorted String Table) 기반
- 구조:
    - 메모리(메모리 테이블, MemTable) → 디스크 세그먼트(SS테이블)
    - 주기적 flush + compaction
- 장점:
    - 쓰기 성능 우수 (append-only)
    - 대규모 데이터 처리에 유리
- 단점:
    - 읽기 성능은 B-Tree보다 떨어질 수 있음 (여러 세그먼트 검색 필요)
    - compaction 시 write amplification 발생

---

## 9. B-Tree

**구조** : 고정 크기 페이지(블록) 단위로 구성

```
Root Page
             [    50 | 100    ]
            /         |         \
           /          |          \
    [10|20|30]  [60|70|80]  [110|120|130]
       ↓           ↓              ↓
   Leaf Pages   Leaf Pages    Leaf Pages
  (Actual Data) (Actual Data) (Actual Data)
```

- 전통적인 RDBMS의 표준 색인 구조
- 특징:
    - 페이지(블록) 단위 디스크 접근
    - 특정 키 검색/갱신 → O(log N)
    - 범위 질의 효율적
- 장점: 안정적인 읽기 성능
- 단점:
    - 무작위 쓰기 발생 → 로그 구조보다 느릴 수 있음
    - 동시성 제어 복잡

---

## 10. LSM vs B-Tree 비교

| 구분 | LSM 트리 | B-Tree |
| --- | --- | --- |
| 쓰기 성능 | 빠름 (append-only, 순차 쓰기) | 느림 (무작위 쓰기 발생) |
| 읽기 성능 | 다소 불리 (세그먼트 탐색 필요) | 안정적, 빠름 |
| 범위 질의 | 가능 (정렬 기반) | 효율적 |
| 디스크 사용 | compaction 최적화 필요 | 상대적으로 단순 |
| 적용 사례 | Cassandra, HBase, LevelDB, RocksDB | MySQL(InnoDB), PostgreSQL |

---

## 11. 기타 색인 구조

- **색인 안에 값을 저장하기**: 키-값 쌍을 색인에 직접 보관
- **다중 칼럼 색인(Composite Index)**: 여러 칼럼 기반 검색 최적화
- **전문 검색(Full-text Search)**: 검색엔진(Lucene, ElasticSearch) 활용
- **퍼지 색인(Fuzzy Index)**: 오타, 근사 검색 처리
- **인메모리 DB**: Redis, Memcached → 모든 데이터를 메모리에 보관

--
## 트랜잭션 처리와 분석의 차이

초창기 비즈니스 데이터 처리를 보면 대부분 실제 상거래와 관련된 작업들이었다. 

판매, 발주, 급여 지급 같은 일들이 예시이다.

금전 거래가 아닌 다른 영역으로 데이터베이스가 확장되었지만 

'**트랜잭션**'이라는 용어는 여전히 논리적 단위로서 읽기와 쓰기를 묶어서 표현할 때 사용한다.

중요한 건 트랜잭션이 반드시 **ACID**(원자성, 일관성, 격리성, 지속성) 속성을 모두 만족해야 하는 건 아니라는 점이다. 

트랜잭션 처리의 핵심은 하루에 한 번 도는 배치 작업과는 달리 클라이언트가 **낮은 지연 시간으로 읽기와 쓰기를 할 수 있게 하는 것**이다.

일반적인 애플리케이션은 인덱스를 활용해서 특정 키에 해당하는 소수의 레코드를 찾는다. 

그리고 사용자가 입력한 내용을 바탕으로 레코드를 삽입하거나 업데이트한다. 

이런 대화식 접근 패턴을 **온라인 트랜잭션 처리**, 즉 **OLTP**라고 부른다.

그런데 시간이 지나면서 데이터베이스를 분석 용도로도 쓰기 시작했다. 

분석 질의는 트랜잭션과는 접근 패턴이 완전히 다르다. 

사용자에게 원시 데이터를 그대로 보여주는 게 아니라 수많은 레코드를 스캔해서 필요한 컬럼들만 읽고 집계를 계산한다.

예를 들어 판매 데이터를 분석할 때는 이런 질문들을 던진다.

- 1월에 각 매장의 총 수익은 얼마나 됐을까?
- 최근 프로모션 기간에 평소보다 바나나를 얼마나 더 많이 팔았을까?
- 특정 브랜드 기저귀와 함께 가장 자주 구매하는 유아식 브랜드는 뭘까?

이런 질의들은 보통 비즈니스 분석가들이 작성하고, 회사 경영진이 더 나은 의사결정을 할 수 있도록 돕는 보고서를 만드는 데 쓰인다. 이를 **온라인 분석 처리, OLAP**라고 한다.

### OLTP와 OLAP 비교

두 시스템의 차이점을 정리해보면 다음과 같다.

| 특성 | 트랜잭션 처리 시스템(OLTP) | 분석 시스템(OLAP) |
| --- | --- | --- |
| 주요 읽기 패턴 | 질의당 적은 수의 레코드, 키 기준으로 가져옴 | 많은 레코드에 대한 집계 |
| 주요 쓰기 패턴 | 임의 접근, 사용자 입력을 낮은 지연 시간으로 기록 | 의사결정 지원을 위한 내부 분석가 |
| 주요 사용처 | 웹 애플리케이션을 통한 최종 사용자/소비자 | 의사결정 지원을 위한 내부 분석가 |
| 데이터 표현 | 데이터의 최신 상태(현재 시점) | 시간이 지나며 일어난 이벤트 이력 |
| 데이터셋 크기 | 기가바이트에서 테라바이드 | 테라바이트에서 페타바이트 |

## 데이터 웨어하우스의 등장

OLTP 시스템을 분석 목적으로 직접 사용하지 않고 

별도의 데이터베이스를 만들어서 분석을 수행하게 되었는데 이를 **데이터 웨어하우스**라고 한다.

대부분 기업들은 정말 많은 트랜잭션 처리 시스템을 가지고 있다. 

고객 대면 웹사이트, 실제 매장 관리 시스템, 창고 재고 관리, 운송 경로 계획, 공급업체 관리, 직원 관리 등

이런 시스템들은 복잡해서 각각 전담 팀이 필요하고, 보통 독립적으로 운영된다.

OLTP 시스템들은 사업 운영에 핵심적이라서 높은 가용성과 낮은 지연 시간을 요구한다. 

그래서 데이터베이스 관리자들은 OLTP 데이터베이스를 철저하게 보호하려고 한다. 

당연히 OLTP DB에 바로 분석 질의를 날리는 걸 꺼린다. 

분석 질의가 데이터셋의 많은 부분을 스캔하면서 동시에 실행되는 트랜잭션 성능을 떨어뜨릴 수 있기 때문이다.

반면 데이터 웨어하우스는 분석가들이 OLTP 작업에 전혀 영향을 주지 않고 마음껏 질의할 수 있는 별도 데이터베이스다. 

데이터 웨어하우스는 회사 내 모든 OLTP 시스템에 있는 데이터를 읽기 전용으로 복사해둔 것이다.

데이터를 OLTP 데이터베이스에서 추출하고, 분석에 친화적인 스키마로 변환하고 깨끗하게 정리한 다음 데이터 웨어하우스에 적재하는 과정을 **ETL**이라고 한다.

거의 모든 대기업에는 데이터 웨어하우스가 있지만 소규모 기업은 그렇지 않다. 

소규모 기업들은 그렇게 많고 다양한 OLTP 시스템을 가지고 있지 않으며 데이터 양도 적어서 일반적인 SQL 데이터베이스나 심지어 스프레드시트로도 분석이 가능하다. 

소규모 기업에서는 간단한 일이 대기업에서는 엄청난 노력을 필요로 한다.

### 데이터 웨어하우스와 OLTP의 차이

둘 다 SQL 질의 인터페이스를 지원하기 때문에 비슷해 보이지만 

질의 패턴에 맞게 최적화되어 있어서 시스템 내부는 완전히 다르다.

주요 솔루션들을 보면 다음과 같다.

- 상용: 마이크로소프트 SQL 서버, SAP HANA
- 클라우드: 아마존 레드시프트
- 오픈소스: 아파치 하이브, 스파크SQL, 임팔라, 페이스북 프레스토, 아파치 타조, 드릴
- 기타: 구글 드레멜

## 분석용 스키마

SQL이 분석 질의에 적합하기 때문에 데이터 웨어하우스의 데이터 모델은 가장 일반적인 관계형 모델을 사용한다.

SQL 질의를 생성하고 결과를 시각화하며, 분석가들이 드릴다운, 슬라이싱, 다이싱으로 데이터를 탐색할 수 있게 해주는 여러 그래픽 도구들이 있다.

차원 테이블은 **누가(who), 언제(when), 어디서(where), 무엇을(what), 어떻게(how), 왜(why)**에 해당하는 정보를 담는다. 

예를 들어 상품 차원 테이블에는 재고 관리 코드(SKU), 설명, 브랜드 이름, 범주, 지방 함량, 상품 크기 같은 것들이 외래 키로 개별 묘사된다.

보통 차원 테이블을 사용해서 날짜별로 요약하면 평일과 주말 판매량 차이 같은 걸 잘 알 수 있다.

눈송이 스키마는 별 모양 스키마보다 더 정규화된 형태다. 

보통 100개 이상의 테이블을 가지지만 실제로 데이터 웨어하우스 질의는 한 번에 4개나 5개 컬럼만 접근한다.

## 컬럼 지향 저장소

데이터 웨어하우스 질의의 특성을 보면 date_key, product_sk, quantity 같은 특정 컬럼들만 접근한다. 

특정 날짜나 특정 제품의 모든 판매 내역을 조회할 때, 모든 로우를 메모리로 적재한 다음 구문을 해석하고 조건을 충족하는 로우만 출력하면 작업량이 많이 줄어든다.

**컬럼 지향 저장소**는 대개 **압축에 적합**하다. 데이터 웨어하우스에서 특히 효과적인 게 **비트맵 부호화**다.

컬럼에서 고유 값의 수는 로우 수에 비해 작기 때문에 개별 컬럼을 각각의 비트맵으로 변환할 수 있다. 

값을 가진 비트는 1이고 그렇지 않으면 0으로 표현하면 질의 종류에 매우 효율적이다.

최신 CPU에서는 단일 명령 다중 데이터 실행(SIMD)을 지원하는데 이를 **벡터화 처리**라고 한다.

컬럼 저장소에서 순서 정렬도 중요하다. 

지난달 범위를 목표로 할 때 1차 정렬 키를 date_key로

product_sk를 보조 정렬 키로 하면 첫 번째 정렬 키에서 그룹화한 후 두 번째 정렬 키를 적용할 수 있다.

C-Store에서는 데이터를 가리키는 포인터가 없고, 단지 값을 포함한 컬럼만 존재한다.

### 컬럼 지향 저장소의 쓰기 문제

대부분의 작업이 분석가가 수행하는 대량의 읽기 전용 질의이기 때문에 읽기에 최적화되어 있다. 

하지만 이는 쓰기를 어렵게 한다는 단점이 있다. 

정렬된 테이블의 중간에 로우를 삽입하고 싶으면 모든 컬럼 파일을 재작성해야 한다.

해결 방법은 새로운 로우에 기록하고, 컬럼 파일의 최근 쓰기를 모두 조사해서 나중에 최적화하는 것이다.

## 집계와 구체화 뷰

모든 데이터 웨어하우스가 컬럼 저장에만 국한되는 건 아니다. 구체화 뷰라는 것도 있다.

표준 뷰는 가상 뷰로 일부 질의의 결과가 내장되어 있고 SQL 엔진이 뷰의 원래 질의로 즉석에서 확장한 후 질의를 처리한다.

구체화 뷰는 원본 데이터의 비정규화된 복사본이고, 데이터베이스가 이 작업을 자동으로 수행한다. 

OLTP 데이터베이스에서는 구체화 뷰를 자주 사용하지 않지만 데이터 웨어하우스는 읽기 비중이 크기 때문에 구체화 뷰를 사용하는 전략이 합리적이다.

데이터 큐브나 OLAP 큐브는 구체화 뷰의 특별한 형태다. 

2차원 테이블에서 date와 product의 모든 조합(날짜의 모든 조합과 제품의 모든 조합)에 대해 다른 로우와 컬럼에 같은 질의를 적용한다.

2차원 이상의 초입방체에서는 날짜, 제품, 매장, 프로모션, 고객 같은 다차원으로 각 차원을 따라 반복적으로 요약할 수 있다. 

매장별 총 판매량을 알고 싶으면 해당 차원으로 집계하면 된다.

하지만 데이터 큐브의 단점은 원시 데이터에 질의하는 것과 동일한 유연성이 없다는 점이다. 

예를 들어 "가격이 100달러 이상인 항목에서 발생한 판매량의 비율" 같은 복잡한 질의는 처리하기 어렵다. 

그래서 데이터 웨어하우스는 가능한 한 많은 원시 데이터를 유지하려고 노력하고 구체화 뷰는 특정 질의에 대한 성능 향상에만 사용한다.

## 정리

데이터베이스에 데이터를 저장할 때와 이후 다시 데이터에 질의할 때 데이터베이스가 수행하는 작업들을 살펴봤다. 

트랜잭션 처리 최적화(OLTP)와 분석 최적화(OLAP)는 서로 다른 접근이 필요하다. 

쓰기 성능을 높이는 것과 읽기 성능을 높이는 것 사이에는 트레이드오프가 있다.

질의가 많은 수의 로우를 순차적으로 스캔해야 한다면 인덱스를 사용하는 방법은 적절하지 않다. 

이런 경우에는 질의가 디스크에서 읽는 데이터의 양을 최소화하기 위해 데이터를 매우 작게 부호화하는 일이 중요해진다.