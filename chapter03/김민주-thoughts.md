# 데이터 웨어하우스 vs Apache Polaris 비교

## 인덱스 학습 경험

이번 장에 인덱스 개념이 많이 나오는데, 개념에 대해서만 알고 실제로는 자주 써보지는 않았습니다.
특징과 장단점에 대해서만 알았는데 이번 기회에 구조에 대해서도 좀 더 깊게 보며, 어떤 점이 트레이드 오프가 오는지 구체적으로 공부해보게 되었던 거 같습니다.

### 인덱스의 근본적 트레이드오프

```
┌─────────────────────────────────┐
│ B-Tree Index                    │
│ ✅ 읽기 빠름 (O(log N))          │
│ ❌ 쓰기 느림 (페이지 업데이트)    │
│ ❌ 단일 시스템에 종속             │
└─────────────────────────────────┘

┌─────────────────────────────────┐
│ LSM-Tree Index                  │
│ ✅ 쓰기 빠름 (append-only)       │
│ ❌ 읽기 다소 느림 (다중 레벨)     │
│ ❌ Compaction 오버헤드           │
└─────────────────────────────────┘
```

## 질문

이번 장에 데이터웨어하우스로 나오는데, 이전 발표 때 오픈소스에 기여하셨던 내용이랑 어떤 점이 다른지 조금 궁금했습니다.
데이터웨어하우스로 아파치 하이브나 아파치 타조에 대한 언급이 있었기에 하시고 계시던 프로젝트도 데이터 웨어하우스 오픈소스 중 하나이실지 궁금했습니다.

---

## 1. 전통적 데이터 웨어하우스 아키텍처

```
     OLTP Systems                Data Warehouse
┌─────────────────┐             ┌──────────────────┐
│  MySQL (주문)    │────┐        │                  │
│  - B-Tree index │    │        │   Apache Hive    │
└─────────────────┘    │        │   Apache Tajo    │
                       │        │                  │
┌─────────────────┐    │  ETL   │  ┌────────────┐  │
│ PostgreSQL(고객) │────┼───→   │  │Column Store│  │
│  - B-Tree index │    │        │  │(OLAP 최적화)│ │
└─────────────────┘    │        │  └────────────┘  │
                       │        │                  │
┌─────────────────┐    │        │  ┌────────────┐  │
│  MongoDB(제품)   │────┘        │  │자체 쿼리    │  │
│  - Hash index   │             │  │엔진         │  │
└─────────────────┘             │  └────────────┘  │
                                └──────────────────┘
```

### 특징

✅ OLAP에 최적화 (컬럼 스토리지, 비트맵 인덱스)
✅ 복잡한 집계 쿼리 빠름
❌ 데이터 복제 필수 (ETL 오버헤드)
❌ 실시간 분석 어려움 (배치 처리)
❌ 단일 엔진만 사용 (Hive면 Hive만)
❌ 데이터 사일로 (각 시스템 독립)

**이것이 책에서 설명하는 "OLAP 최적화된 시스템"입니다.**

---

## 2. Apache Polaris - 현대적 데이터 통합 플랫폼

```
┌──────────────────────────────────────────────────┐
│         Apache Polaris Catalog                   │
│      (메타데이터 + 거버넌스 중앙 관리)             │
│  ┌────────────────────────────────────────────┐  │
│  │ 테이블: sales.orders                       │  │
│  │ 위치: s3://data-lake/orders/              │  │
│  │ 포맷: Apache Iceberg                      │  │
│  │ 스키마: [order_id, amount, date, ...]    │  │
│  │ 파티션: date (hidden partitioning)       │  │
│  │ 권한: team_analytics (READ)              │  │
│  └────────────────────────────────────────────┘  │
└────────────────┬─────────────────────────────────┘
                 │ (REST API - 공통 표준)
        ┌────────┼────────┬─────────┬────────┐
        ▼        ▼        ▼         ▼        ▼
    ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐
    │Spark │ │Trino │ │Flink │ │ Hive │ │Dremio│
    │(배치)│ │(대화형)│(실시간)│(레거시)│ (BI) │
    └───┬──┘ └───┬──┘ └───┬──┘ └───┬──┘ └───┬──┘
        └────────┴────────┴─────────┴────────┘
                        │
                ┌───────▼────────┐
                │  S3 / MinIO    │
                │ (데이터 레이크) │
                │  Iceberg Tables│
                └────────────────┘
         (한 곳에만 데이터 저장!)
```

### 특징

✅ 데이터 복제 불필요 (단일 복사본)
✅ 실시간 + 배치 모두 지원
✅ 다중 엔진 자유롭게 선택
✅ 통합 거버넌스 (한 곳에서 권한 관리)
✅ 비용 절감 (스토리지 한 번만)
❌ 복잡도 증가 (여러 컴포넌트 조합)

---

## 3. 실제 사용 시나리오

### 전통적 DW (DDIA의 Hive/Tajo)

```bash
# 1단계: ETL로 데이터 복사 (매일 새벽 실행)
$ hive -e "
  INSERT INTO warehouse.orders_fact
  SELECT * FROM mysql_source.orders
  WHERE date = '2024-01-13'
"
# → 데이터가 Hive 전용 포맷으로 복사됨

# 2단계: Hive로만 분석 가능
$ hive -e "
  SELECT 
    customer_region,
    SUM(amount) as total_sales
  FROM warehouse.orders_fact
  WHERE date BETWEEN '2024-01-01' AND '2024-01-13'
  GROUP BY customer_region
"
# ✅ 컬럼 스토리지로 빠름
# ❌ 하지만 어제 데이터까지만 (실시간 X)

# 3단계: 실시간 분석이 필요하면?
# → 별도 시스템 구축 필요! (Kafka + Flink)
# → 데이터가 또 복제됨
```

### Apache Polaris 생태계

```bash
# 1단계: SeaTunnel로 데이터 수집 (실시간/배치 선택 가능)
$ seatunnel.sh --config mysql-to-iceberg.conf
# → S3에 Iceberg 포맷으로 직접 저장
# → Polaris가 자동으로 메타데이터 관리

# 2단계: 배치 분석 (Spark)
$ spark-sql --conf spark.sql.catalog.polaris=...
spark-sql> 
  SELECT 
    customer_region,
    SUM(amount) 
  FROM polaris.sales.orders
  WHERE date >= '2024-01-01'
  GROUP BY customer_region;

# 3단계: 대화형 분석 (Trino) - 같은 데이터!
$ trino --catalog polaris
trino> 
  SELECT * FROM sales.orders 
  WHERE order_time > NOW() - INTERVAL '1' HOUR
  ORDER BY amount DESC 
  LIMIT 10;
# ✅ 실시간 데이터 조회 가능

# 4단계: 실시간 집계 (Flink) - 역시 같은 데이터!
flink> 
  SELECT 
    TUMBLE_END(order_time, INTERVAL '5' MINUTE) as window_end,
    customer_region,
    COUNT(*) as order_count,
    SUM(amount) as total_amount
  FROM polaris.sales.orders
  GROUP BY 
    TUMBLE(order_time, INTERVAL '5' MINUTE),
    customer_region;
# ✅ 5분마다 실시간 집계

# 핵심: 데이터는 S3에 한 번만 저장됨!
# 어떤 엔진을 쓰든 동일한 데이터 접근
```

---

## 4. 인덱스 관점에서의 차이

책에서 배운 인덱스 개념을 적용하면:

### 전통적 DW의 인덱싱

```
┌─────────────────────────────────────┐
│  Hive Partitioning                  │
│  /warehouse/orders/                 │
│    └── date=2024-01-01/            │
│        └── data.parquet            │
│    └── date=2024-01-02/            │
│        └── data.parquet            │
│                                     │
│  문제점:                             │
│  - 물리적 디렉토리 구조               │
│  - 파티션 변경 시 데이터 재작성 필요   │
│  - Hive만 이해하는 형식              │
└─────────────────────────────────────┘
```

### Apache Iceberg의 인덱싱 (Polaris 사용)

```
┌─────────────────────────────────────┐
│  Hidden Partitioning                │
│  - 논리적 파티션 (메타데이터 기반)    │
│  - 사용자: SELECT * FROM orders     │
│           WHERE date = '2024-01-01' │
│  - Iceberg: 자동으로 파일 스킵       │
│                                     │
│  Partition Evolution:               │
│  - 파티션 스키마 변경 가능            │
│  - 데이터 재작성 불필요               │
│  - 예: 월별 → 일별로 자동 전환       │
│                                     │
│  모든 엔진이 동일하게 사용:           │
│  - Spark: 자동 파티션 프루닝         │
│  - Trino: 동일한 최적화              │
│  - Flink: 실시간에서도 적용          │
└─────────────────────────────────────┘
```

이것은 마치 **B-Tree와 LSM-Tree가 다른 트레이드오프를 가진 것처럼**, 전통적 DW와 현대적 플랫폼도 다른 설계 철학을 가집니다.

---

## 5. Apache SeaTunnel과의 관계

Apache SeaTunnel은 **데이터 통합 플랫폼의 "수집" 레이어**입니다:

### 완전한 데이터 통합 플랫폼 스택

```
┌────────────────────────────────────────────┐
│  1. 데이터 수집 레이어                      │
│     Apache SeaTunnel                       │
│  ┌──────────────────────────────────────┐  │
│  │ Source: MySQL, PostgreSQL, Kafka ... │  │
│  │ Transform: Filter, Map, Aggregate    │  │
│  │ Sink: Iceberg, Delta, Hudi, HDFS    │  │
│  └──────────────────────────────────────┘  │
└─────────────────┬──────────────────────────┘
                  │
┌─────────────────▼──────────────────────────┐
│  2. 카탈로그 레이어 (← Polaris는 여기!)      │
│     Apache Polaris                         │
│  ┌──────────────────────────────────────┐  │
│  │ - 테이블 메타데이터 중앙 관리          │  │
│  │ - 접근 권한 제어 (RBAC)               │  │
│  │ - 스키마 진화 (Schema Evolution)      │  │
│  │ - 다중 엔진 지원                       │  │
│  └──────────────────────────────────────┘  │
└─────────────────┬──────────────────────────┘
                  │
┌─────────────────▼──────────────────────────┐
│  3. 테이블 포맷 레이어                      │
│     Apache Iceberg / Delta Lake / Hudi    │
│  ┌──────────────────────────────────────┐  │
│  │ - ACID 트랜잭션                        │  │
│  │ - Time Travel (과거 데이터 조회)       │  │
│  │ - Schema Evolution                    │  │
│  │ - Hidden Partitioning                 │  │
│  └──────────────────────────────────────┘  │
└─────────────────┬──────────────────────────┘
                  │
┌─────────────────▼──────────────────────────┐
│  4. 스토리지 레이어                         │
│     S3 / MinIO / HDFS / Azure Blob        │
│  ┌──────────────────────────────────────┐  │
│  │ Parquet Files (Column-oriented)      │  │
│  │ - 비트맵 인덱싱                        │  │
│  │ - RLE 압축                            │  │
│  │ - Dictionary Encoding                 │  │
│  └──────────────────────────────────────┘  │
└─────────────────┬──────────────────────────┘
                  │
┌─────────────────▼──────────────────────────┐
│  5. 컴퓨팅 레이어                           │
│     Spark / Trino / Flink / Hive / Dremio│
│  ┌──────────────────────────────────────┐  │
│  │ 각 엔진이 동일한 데이터 접근            │  │
│  │ - Spark: 배치 처리                     │  │
│  │ - Trino: 대화형 쿼리                   │  │
│  │ - Flink: 실시간 스트리밍                │  │
│  └──────────────────────────────────────┘  │
└────────────────────────────────────────────┘
```

---

## 정리

### 데이터 웨어하우스 (Data Warehouse)

- **목표**: 비즈니스 인텔리전스(BI), 보고, 분석을 위한 통합된 데이터 제공
- **데이터**: 주로 정형, 반정형 데이터 (CRM, ERP 등)
- **특징**: 주제 중심, 통합, 시계열 데이터, 의사결정 지원
- **기술**: OLAP(온라인 분석 처리) 최적화, 복잡한 쿼리 수행
- **한계**: 비정형/대용량 데이터 처리, 실시간 분석에는 유연성 부족 (전통적 DW)
- **오픈소스 예시**: Apache Hive, Apache Tajo, Apache Druid

### 데이터 통합 플랫폼 (Data Integration Platform)

- **목표**: 데이터 수집, 준비, 저장, 분석의 전체 파이프라인 간소화
- **데이터**: 모든 종류의 데이터 (정형, 비정형, 반정형)
- **특징**: 유연성, 확장성, 상호운용성, 거버넌스 통합
- **기술**: DW, DL, 마트 등 다양한 기술 요소 통합 (레이크하우스 포함)
- **역할**: 현대 데이터 아키텍처의 '총괄' 역할, AI/머신러닝 요구사항 대응
- **오픈소스 예시**: Apache Polaris, Apache SeaTunnel, Apache Iceberg

---

## 주요 차이점 요약

| 구분 | 데이터 웨어하우스 | 데이터 통합 플랫폼 |
|------|-----------------|------------------|
| **역할** | 분석/보고를 위한 중앙 집중식 저장소 | 데이터 생명주기 전체를 관리하는 포괄적 솔루션 |
| **데이터 종류** | 주로 정형/반정형 | 모든 종류 (정형, 반정형, 비정형) |
| **주요 기능** | 데이터 통합, 분석, BI 제공 | 수집, 준비, 저장, 분석, 거버넌스 통합 |
| **기술 스택** | OLAP, 전통적 ETL, DW 기술 | DW, DL, 마트, AI/ML, 실시간 분석 등 포괄 |
| **관점** | 특정 목적(분석)에 최적화된 '시스템' | 모든 데이터 기술을 묶는 '아키텍처' |
| **데이터 복제** | 필요 (ETL로 복사) | 불필요 (단일 복사본) |
| **실시간 처리** | 어려움 | 가능 |
| **엔진 선택** | 고정 | 자유 |
