# 데이터 저장소 설계 가이드

## 목차
1. [해시 색인](#해시-색인)
2. [LSM과 SS 트리 비교](#lsm과-ss-트리-비교)
3. [B트리](#b트리)
4. [다중 컬럼 인덱싱](#다중-컬럼-인덱싱)
5. [트랜잭션 처리와 분석](#트랜잭션-처리와-분석)
6. [데이터 웨어하우징](#데이터-웨어하우징)
7. [컬럼 지향 저장소](#컬럼-지향-저장소)

---

## 해시 색인

### 개요
해시 색인은 메모리 기반의 단순한 인덱싱 기법으로, 키-값 쌍을 메모리 내의 해시맵으로 유지합니다. 추가 전용(append-only) 로그 파일에 데이터를 기록하고, 메모리의 해시맵이 가장 최신의 키 위치를 가리킵니다.

### 장점
- **매우 빠른 조회**: 해시 조회는 O(1) 시간 복잡도로 극도로 빠릅니다.
- **간단한 구현**: 메모리 해시맵을 사용하므로 구현이 단순합니다.
- **순차 쓰기**: 로그 파일에 순차적으로 기록되므로 쓰기 성능이 우수합니다.

### 단점
- **메모리 의존성**: 전체 키-값 쌍이 메모리에 있어야 하므로 저장소 크기가 RAM 크기로 제한됩니다.
- **범위 쿼리 불가**: 특정 범위의 키를 조회할 수 없습니다.
- **로그 파일 관리**: 로그 파일이 계속 증가하므로 압축(compaction)이 필요합니다.
- **충돌 처리**: 해시 충돌 시 추가 메모리 오버헤드가 발생합니다.

### 사용 사례
- 세션 저장소
- 캐시 메모리
- 카운터 업데이트
- 메모리 내 데이터베이스 (예: Redis)

---

## LSM과 SS 트리 비교

### LSM 트리 (Log-Structured Merge Tree)

#### 개념
LSM 트리는 쓰기 최적화된 자료구조로, 메모리와 디스크에 계층적인 트리 구조를 유지합니다. 새로운 데이터는 메모리의 멤테이블(memtable)에 먼저 기록되고, 일정 크기에 도달하면 디스크의 SSTable로 플러시됩니다.

#### 구조
```
메모리 계층:
  ┌─────────────┐
  │  Memtable   │ (Red-Black Tree 또는 Skip List)
  │  (정렬됨)    │
  └─────────────┘
        ↓ (플러시)
디스크 계층:
  ┌─────────────────────┐
  │ Level 0 (SSTable)   │
  ├─────────────────────┤
  │ Level 1 (SSTable)   │
  ├─────────────────────┤
  │ Level 2 (SSTable)   │
  └─────────────────────┘
```

#### 장점
- **빠른 쓰기**: 순차적 로그 기록과 메모리 쓰기로 매우 빠른 쓰기 성능
- **효율적인 압축**: 여러 SSTable을 병합하면서 불필요한 데이터 정리
- **디스크 공간 효율**: 압축 과정에서 삭제된 데이터와 중복 제거
- **범위 쿼리 지원**: 정렬된 키를 사용하므로 범위 쿼리 가능

#### 단점
- **복잡한 읽기**: 여러 레벨의 SSTable을 검색해야 할 수 있음
- **백그라운드 압축 오버헤드**: 압축 작업이 I/O 성능 영향
- **공간 증폭**: 압축 중 임시 디스크 공간 필요
- **읽기 지연성**: 블룸 필터(Bloom filter) 사용으로 완화하지만 여전히 오버헤드

#### 마각 알고리즘
LSM의 압축(Compaction) 전략:
- **Leveled**: 모든 레벨의 데이터가 정렬된 상태 유지
- **Tiered**: 레벨 내에서만 정렬
- **Hybrid**: 두 방식 결합

---

### SS 트리 (Sorted String Table)

#### 개념
SS 트리는 LSM의 기본 구성 단위로, 정렬된 키-값 쌍을 디스크에 저장하는 불변 파일 구조입니다. 일반적으로 LSM 트리의 각 레벨을 이루는 단위 저장소입니다.

#### 구조
```
SSTable 파일 구조:
┌──────────────────────────────────┐
│ Data Block 1                     │ (키-값 쌍, 정렬됨)
│ Data Block 2                     │
│ ...                              │
├──────────────────────────────────┤
│ Index Block                      │ (각 블록의 첫 키와 오프셋)
├──────────────────────────────────┤
│ Bloom Filter                     │ (키 존재 여부 빠른 판정)
├──────────────────────────────────┤
│ Footer                           │ (메타데이터, 오프셋 정보)
└──────────────────────────────────┘
```

#### 장점
- **불변성**: 읽기 성능이 안정적이고 캐싱이 용이
- **효율적인 압축**: 여러 SSTable을 순차 읽기로 병합
- **블룸 필터**: 존재하지 않는 키를 빠르게 판정하여 불필요한 읽기 방지
- **범위 쿼리**: 정렬된 구조로 범위 스캔 효율적

#### 단점
- **읽기 확대**: 여러 레벨의 SSTable을 모두 확인해야 할 수 있음
- **단일 테이블 제약**: 단일 SSTable은 쓰기 중단 후 생성되므로 대기 시간 존재
- **메모리 색인**: 각 SSTable마다 메모리의 색인 유지 필요

---

### LSM과 SS 트리 비교표

| 특성 | LSM 트리 | SS 트리 |
|------|---------|--------|
| **역할** | 전체 저장소 엔진 | LSM의 개별 레벨 구성 단위 |
| **구조** | 메모리 + 다층 디스크 계층 | 단일 정렬된 파일 |
| **쓰기 성능** | 매우 빠름 | 느림 (생성 후에는 불변) |
| **읽기 성능** | 중간 ~ 나쁨 | 좋음 (단일 테이블 시) |
| **압축** | 필수, 백그라운드 | 여러 테이블 병합으로 수행 |
| **범위 쿼리** | 지원 | 지원 |
| **메모리 사용** | 높음 (다층 인덱스) | 낮음 (블룸 필터) |
| **사용 목적** | 고속 쓰기 시스템 | LSM의 일부로 사용 |

---

### LSM vs SS 선택 기준

**LSM 트리를 선택할 때:**
- 쓰기가 매우 많은 워크로드 (예: 로그 수집, 시계열 데이터)
- 배치 로딩이 많은 환경
- 조회는 상대적으로 적은 상황

**SS 트리를 활용할 때:**
- LSM의 개별 레벨로 구성
- 블룸 필터와 함께 사용하여 읽기 성능 최적화
- 범위 쿼리 최적화 필요

---

## B트리

### 개념
B트리는 자가 균형 트리 구조로, 읽기 최적화된 인덱싱 기법입니다. 디스크 기반 데이터베이스에서 광범위하게 사용되며, 대부분의 관계형 데이터베이스(MySQL, PostgreSQL)와 일부 NoSQL 데이터베이스에서 기본 인덱스 구조로 채택됩니다.

### B트리의 특성

#### 1. 차수 (Order)와 노드 구조
B트리는 특정 차수 `m`을 가지며, 각 노드는 최대 `m-1`개의 키와 `m`개의 자식 포인터를 가집니다.

```
차수 4인 B트리 노드:
┌─────────────────────────────────────────────┐
│  │ 10 │  │ 20 │  │ 30 │  │              │
│  │    │  │    │  │    │  │              │
└─────────────────────────────────────────────┘
  ↓    ↓    ↓    ↓    ↓    ↓    ↓    ↓
 [1-9] [10-19] [20-29] [30-39] ...
```

#### 2. 균형성
- 모든 리프 노드는 같은 깊이에 위치
- 이는 모든 조회가 동일한 시간 복잡도를 보장
- 최악의 경우에도 O(log n) 조회 성능

#### 3. 노드 분할 (Node Split)
노드가 가득 차면, 중간 키를 기준으로 분할됩니다.

```
분할 전:
┌──────────────────────────────────┐
│ 10 │ 20 │ 30 │ 40 │ 50 │        │
└──────────────────────────────────┘

분할 후:
      ┌───────┐
      │  30   │
      └───────┘
      /       \
┌───────────┐  ┌───────────┐
│10 │ 20    │  │ 40 │ 50   │
└───────────┘  └───────────┘
```

### B트리의 장점

#### 1. 균형성 보장
```
n개의 원소에 대해 항상 O(log n) 조회 시간
```

#### 2. 디스크 I/O 최적화
- 한 노드가 여러 디스크 블록에 정렬된 여러 키를 저장
- 범위 검색 시 순차 I/O 가능
- 캐시 효율성이 높음

#### 3. 범위 쿼리 효율
```
예: 1000 < key <= 5000 조회
- 1000의 위치 찾음 (O(log n))
- 리프 노드의 형제들을 순차 스캔
- 매우 효율적
```

#### 4. 삽입 및 삭제 성능
- 노드 분할/병합으로 균형 유지
- 재정렬 불필요 (LSM의 압축 같은 대량 작업 없음)

### B트리의 단점

#### 1. 쓰기 성능
- 노드 분할 시 여러 쓰기 작업 필요
- WAL (Write-Ahead Log) 필수
- LSM에 비해 쓰기 성능 낮음

#### 2. 공간 활용
- 각 노드가 완전히 채워지지 않을 수 있음
- 평균적으로 66% 정도의 공간 활용

#### 3. 압축(Compaction) 필요 없음
- 장점처럼 보이지만 파편화 관리 필요
- 빈 페이지 재활용 메커니즘 필요

### B트리의 연산 복잡도

| 연산 | 시간복잡도 | 디스크 I/O |
|------|-----------|----------|
| 조회 | O(log n) | O(log n) 블록 읽기 |
| 삽입 | O(log n) | O(log n) 쓰기 |
| 삭제 | O(log n) | O(log n) 쓰기 |
| 범위 쿼리 | O(log n + k) | O(log n + k/b) (k:결과, b:블록크기) |

### B+ 트리 (B트리의 변형)

B+ 트리는 B트리의 개선 버전으로, 많은 현대 데이터베이스에서 사용됩니다.

#### B+ 트리와 B트리의 차이

```
B 트리:
       ┌─── 50 ───┐
      /            \
   ┌─30─┐        ┌─70─┐
  /  |  \        /  |  \
[10][30][50]  [70][90]

B+ 트리:
       ┌─── 50 ───┐
      /            \
   ┌─30─┐        ┌─70─┐
  /  |  \        /  |  \
[10][30][50]  [70][90]  <- 리프 노드만 데이터 포함
                         <- 리프 노드들이 링크됨
```

#### B+ 트리의 특징
- **데이터는 리프에만**: 내부 노드는 오직 색인만 저장
- **리프 노드 링크**: 범위 쿼리를 위해 리프 노드들이 순방향/역방향으로 링크됨
- **더 나은 범위 쿼리**: 리프 노드의 시작점을 찾은 후 링크를 따라 순회

#### B+ 트리의 장점
```
범위 쿼리 "100 <= key <= 500":
1. 100의 위치 찾기 (O(log n))
2. 리프 노드 링크를 따라 순회 (O(k/b))
   - 블룸 필터나 추가 검색 불필요
   - 매우 효율적
```

### 실제 B트리 구현 (의사코드)

```
class BTreeNode {
    keys: List[Key]           // 키 배열
    children: List[Pointer]   // 자식 포인터
    is_leaf: Boolean          // 리프 노드 여부
    num_keys: Integer         // 현재 키 개수
}

class BTree {
    root: BTreeNode
    order: Integer            // B트리 차수
    
    function search(key):
        return search_recursive(root, key)
    
    function search_recursive(node, key):
        // 이진 탐색으로 적절한 자식 찾기
        i = binary_search(node.keys, key)
        
        if key == node.keys[i]:
            return node.values[i]
        
        if node.is_leaf:
            return NOT_FOUND
        
        return search_recursive(node.children[i+1], key)
    
    function insert(key, value):
        if root.num_keys == (2*order - 1):
            // 루트가 가득 참 -> 새 루트 생성
            new_root = BTreeNode()
            new_root.children[0] = root
            split_child(new_root, 0)
            root = new_root
        
        insert_non_full(root, key, value)
    
    function split_child(parent, i):
        full_child = parent.children[i]
        new_child = BTreeNode()
        
        // 중간값을 기준으로 분할
        mid_index = order - 1
        new_child.keys = full_child.keys[mid_index+1:]
        new_child.children = full_child.children[mid_index+1:]
        
        // 부모에 중간값 삽입
        parent.keys.insert(i, full_child.keys[mid_index])
        parent.children.insert(i+1, new_child)
        
        full_child.keys = full_child.keys[:mid_index]
        full_child.children = full_child.children[:mid_index+1]
}
```

### B트리 vs LSM 트리 비교

| 특성 | B트리 | LSM 트리 |
|------|-------|---------|
| **읽기 성능** | 매우 좋음 | 중간 ~ 나쁨 |
| **쓰기 성능** | 중간 | 매우 좋음 |
| **범위 쿼리** | 효율적 (B+) | 효율적 |
| **공간 사용** | 66% 활용 | 높은 확대로 인한 낭비 |
| **압축 작업** | 없음 | 지속적 필요 |
| **사용 사례** | OLTP 데이터베이스 | 로그 저장소, NoSQL |

---

## 다중 컬럼 인덱싱

### 개념
다중 컬럼 인덱싱은 여러 컬럼을 기반으로 데이터를 빠르게 조회하는 기법입니다. 단일 컬럼 인덱스와 달리, 여러 조건을 동시에 만족하는 데이터를 효율적으로 찾을 수 있습니다.

### 1. 연결 인덱스 (Concatenated Index)

여러 컬럼을 순서대로 연결하여 하나의 키로 만드는 방식입니다.

#### 구조
```
테이블: users
┌────┬───────┬──────────┬────────┐
│ id │ name  │ city     │ age    │
├────┼───────┼──────────┼────────┤
│ 1  │ Alice │ Seoul    │ 25     │
│ 2  │ Bob   │ Busan    │ 30     │
│ 3  │ Carol │ Seoul    │ 28     │
│ 4  │ David │ Seoul    │ 25     │
└────┴───────┴──────────┴────────┘

인덱스: (city, age)
키 구성: "Seoul:25" → [1, 4]
        "Seoul:28" → [3]
        "Busan:30" → [2]
```

#### 예시: B트리에서의 연결 인덱스
```
B트리 인덱스 (city, age):

        ┌─────────────────┐
        │  "Seoul:28"     │
        └─────────────────┘
       /                  \
    ┌──────────────┐    ┌──────────────┐
    │ "Busan:30"   │    │ "Seoul:30"   │
    └──────────────┘    └──────────────┘
   /              \    /              \
[Busan:30]  [Seoul:25] [Seoul:28]  [Seoul:30]
   [2]      [1,4]        [3]          []
```

#### 장점
- 여러 컬럼 조건을 동시에 효율적으로 처리
- B트리와 결합하여 범위 쿼리 가능
- 정렬된 키로 인한 최적화

#### 단점
- 컬럼 순서가 매우 중요
- 첫 번째 컬럼이 항상 포함되어야 효율적
- 모든 가능한 컬럼 조합을 인덱싱할 수 없음

#### 쿼리 예시
```sql
-- 효율적인 쿼리 (첫 컬럼 포함)
SELECT * FROM users WHERE city = 'Seoul' AND age = 25;
→ 인덱스 사용 가능 ✓

-- 비효율적 (첫 컬럼 없음)
SELECT * FROM users WHERE age = 25;
→ 인덱스 사용 불가 ✗

-- 효율적 (첫 컬럼만)
SELECT * FROM users WHERE city = 'Seoul';
→ 인덱스 사용 가능 ✓

-- 범위 쿼리도 효율적
SELECT * FROM users WHERE city = 'Seoul' AND age > 25;
→ 인덱스로 "Seoul:26" 이상 범위 스캔 ✓
```

### 2. 다중 다중값 인덱스 (Multi-valued Index)

하나의 컬럼이 여러 값을 가질 수 있는 경우를 처리합니다.

#### 예시
```
테이블: products (태그가 배열)
┌────┬────────────┬──────────────────────┐
│ id │ name       │ tags                 │
├────┼────────────┼──────────────────────┤
│ 1  │ Laptop     │ ["electronics",      │
│    │            │  "computers",        │
│    │            │  "work"]             │
│ 2  │ Headphones │ ["electronics",      │
│    │            │  "audio"]            │
└────┴────────────┴──────────────────────┘

다중값 인덱스: tags
"electronics" → [1, 2]
"computers"   → [1]
"audio"       → [2]
"work"        → [1]
```

#### 쿼리 예시
```sql
-- 태그로 검색
SELECT * FROM products WHERE "electronics" IN tags;
→ [1, 2] 반환

-- 여러 태그 검색 (OR)
SELECT * FROM products WHERE "audio" IN tags OR "computers" IN tags;
→ [1, 2] 반환
```

### 3. 커버링 인덱스 (Covering Index)

인덱스에 실제 데이터도 포함하여, 테이블 조회 없이 인덱스만으로 결과를 반환할 수 있습니다.

#### 구조
```
일반 인덱스:
┌─────────────┐
│ (city, age) │ → 테이블 접근 필요
└─────────────┘

커버링 인덱스:
┌──────────────────────────────┐
│ (city, age, name, id)        │ → 테이블 접근 불필요
└──────────────────────────────┘
```

#### 예시
```sql
-- 일반 인덱스 (city, age)
SELECT name FROM users WHERE city = 'Seoul' AND age = 25;
→ 1. 인덱스에서 id 조회
→ 2. 테이블에서 name 조회 (추가 I/O)

-- 커버링 인덱스 (city, age, name)
SELECT name FROM users WHERE city = 'Seoul' AND age = 25;
→ 1. 인덱스에서 직접 name 조회 (추가 I/O 없음)
```

#### 장점
- **I/O 감소**: 테이블 접근 불필요
- **성능 향상**: 특히 대용량 테이블에서 효과적
- **캐시 효율**: 연속된 메모리 접근

#### 단점
- **저장 공간**: 중복 데이터 저장으로 인한 오버헤드
- **업데이트 비용**: 데이터 변경 시 인덱스도 함께 업데이트

### 4. 부분 인덱스 (Partial Index)

특정 조건을 만족하는 행만 인덱싱합니다.

#### 예시
```sql
-- 활성 사용자만 인덱싱
CREATE INDEX idx_active_users ON users(email) 
WHERE status = 'active';

-- 쿼리
SELECT email FROM users 
WHERE status = 'active' AND name = 'Alice';
→ 훨씬 작은 인덱스 사용
```

#### 장점
- **저장 공간**: 불필요한 데이터 제외
- **빠른 삽입**: 더 작은 인덱스 유지

### 5. 역 인덱스 (Inverted Index)

주로 텍스트 검색에 사용되며, 단어를 키로 하고 문서 목록을 값으로 합니다.

#### 구조
```
문서:
doc1: "alice works in seoul"
doc2: "bob lives in busan"
doc3: "carol is from seoul"

역 인덱스:
"alice"  → [doc1]
"bob"    → [doc2]
"busan"  → [doc2]
"carol"  → [doc3]
"from"   → [doc3]
"in"     → [doc1, doc2]
"is"     → [doc3]
"lives"  → [doc2]
"seoul"  → [doc1, doc3]
"works"  → [doc1]
```

#### 쿼리 예시
```
검색: "seoul" AND "alice"
→ "seoul": [doc1, doc3]
→ "alice": [doc1]
→ 교집합: [doc1]
```

#### 적용
- 전문 검색 (Full-text search)
- 검색 엔진 (Elasticsearch, Solr)
- 자동완성 기능

---

## 트랜잭션 처리와 분석

### OLTP vs OLAP

데이터베이스 워크로드는 크게 두 가지로 분류됩니다.

#### OLTP (Online Transaction Processing)

**정의**: 온라인 거래 처리, 짧은 시간의 빠른 트랜잭션 처리를 위한 시스템

##### 특성
```
요청 특성:
- 소량의 데이터 조회 (수 백 ~ 수 천 행)
- 보통 인덱스 기반 접근
- 높은 동시성 (많은 사용자)
- 짧은 응답 시간 요구

예시 쿼리:
SELECT email FROM users WHERE user_id = 12345;
INSERT INTO orders (user_id, product_id) VALUES (12345, 789);
UPDATE users SET balance = balance - 100 WHERE user_id = 12345;
```

##### 대표 시스템
- 은행 시스템 (계좌 이체)
- 전자상거래 (상품 주문)
- 예약 시스템 (항공, 호텔)
- SNS (게시물 작성, 좋아요)

##### 데이터베이스 요구사항
- 높은 쓰기 성능
- 정확한 트랜잭션 처리 (ACID)
- 효율적인 인덱싱
- 동시성 제어

##### 적합한 저장소
- **B트리 기반**: MySQL, PostgreSQL
- **LSM 트리**: HBase, Cassandra
- **메모리 기반**: Redis

#### OLAP (Online Analytical Processing)

**정의**: 온라인 분석 처리, 대규모 데이터에 대한 복잡한 분석 쿼리 처리

##### 특성
```
요청 특성:
- 대량의 데이터 조회 (수 백만 ~ 수 십억 행)
- 전체 테이블 스캔 또는 집계
- 낮은 동시성 (분석가, 의사결정자)
- 응답 시간이 상대적으로 길어도 됨

예시 쿼리:
SELECT category, SUM(amount) as total_sales 
FROM orders 
WHERE date >= '2024-01-01' 
GROUP BY category;

SELECT user_id, COUNT(*) as purchase_count 
FROM orders 
GROUP BY user_id 
HAVING COUNT(*) > 10;
```

##### 대표 시스템
- 비즈니스 인텔리전스 (BI)
- 데이터 웨어하우스 (DW)
- 시계열 분석 (시계열 DB)
- 머신러닝 특성 추출

##### 데이터베이스 요구사항
- 높은 읽기 성능 (특정 컬럼)
- 빠른 집계 연산
- 압축 (저장 공간 절감)
- 병렬 처리

##### 적합한 저장소
- **컬럼 지향**: Parquet, ORC, ClickHouse
- **OLAP 전용**: Redshift, BigQuery
- **데이터 웨어하우스**: Snowflake

### OLTP와 OLAP 비교표

| 특성 | OLTP | OLAP |
|------|------|------|
| **쿼리 패턴** | 단순, 인덱스 기반 | 복잡, 집계 기반 |
| **데이터 범위** | 작은 양 | 대량 |
| **동시성** | 높음 | 낮음 |
| **응답 시간** | 빠름 | 느림 (분 ~ 시간) |
| **데이터 구성** | 행 지향 | 컬럼 지향 |
| **업데이트** | 자주, 작은 양 | 배치, 대량 |
| **저장소 최적화** | B트리 | 컬럼 저장소 |

### 트랜잭션 처리 (ACID)

#### Atomicity (원자성)
트랜잭션은 모두 성공하거나 모두 실패해야 합니다.

```
계좌 이체 예시:
BEGIN TRANSACTION
  UPDATE accounts SET balance = balance - 100 WHERE id = 'A';
  UPDATE accounts SET balance = balance + 100 WHERE id = 'B';
COMMIT;

중간에 오류 발생 시:
- A의 인출은 취소
- B의 입금도 취소
- 최종 상태: A와 B 모두 원래 값
```

#### Consistency (일관성)
트랜잭션 후 데이터베이스는 항상 유효한 상태여야 합니다.

```
제약조건 예시:
- 계좌 잔액은 절대 음수가 될 수 없음
- 총 금액은 항상 유지되어야 함

위반 시나리오 방지:
- A의 잔액이 100 미만 → 이체 거절
```

#### Isolation (격리성)
동시 트랜잭션들이 서로 간섭하지 않아야 합니다.

```
격리 레벨:

1. Read Uncommitted (최하)
   - Dirty Read 가능
   트랜잭션 A: UPDATE balance = 100
   트랜잭션 B: SELECT balance (100 읽음)
   트랜잭션 A: ROLLBACK
   → B가 존재하지 않는 값을 읽음 ✗

2. Read Committed
   - Dirty Read 방지, 비반복 읽기 가능
   
3. Repeatable Read
   - 비반복 읽기 방지, 팬텀 읽기 가능
   
4. Serializable (최상)
   - 완벽한 격리, 성능 오버헤드
```

#### Durability (지속성)
커밋된 트랜잭션은 시스템 장애 후에도 유지되어야 합니다.

```
구현 방식:
1. WAL (Write-Ahead Log)
   - 메모리에 쓰기 전 로그에 기록
   
2. 이중 쓰기
   - 메인 저장소 + 복제본에 동시 기록
   
3. fsync() 호출
   - 버퍼에서 디스크로 강제 플러시
```

### 동시성 제어

#### 비관적 잠금 (Pessimistic Locking)

데이터를 읽기 전에 미리 잠금을 획득합니다.

```
트랜잭션 A:               트랜잭션 B:
SELECT ... FOR UPDATE     (대기)
  (row 잠금)
UPDATE ...
COMMIT                    (이제 실행)
  (잠금 해제)

장점: 충돌이 많을 때 효율적
단점: 대기 시간, 데드락 가능
```

#### 낙관적 잠금 (Optimistic Locking)

데이터를 읽고 수정 후, 커밋 시점에 충돌을 확인합니다.

```
트랜잭션 A:               트랜잭션 B:
SELECT version=1          SELECT version=1
UPDATE balance=900        UPDATE balance=900
  WHERE version=1         WHERE version=1
  (성공)                  (실패: version 변경됨)

장점: 높은 동시성
단점: 충돌 시 재시도 필요
```

#### MVCC (Multi-Version Concurrency Control)

여러 버전의 데이터를 유지하여 읽기와 쓰기가 충돌하지 않도록 합니다.

```
메모리 구조:
┌─ version 1 (트랜잭션 A가 읽음)
│  value: 100
├─ version 2 (트랜잭션 B가 쓴 최신)
│  value: 200
└─ version 3 (활성 트랜잭션 C가 쓰는 중)
   value: 150

- A는 버전 1을 일관되게 읽음
- C가 커밋해도 A는 영향 없음
- 높은 동시성 달성
```

---

## 데이터 웨어하우징

### 개념
데이터 웨어하우스(DW)는 조직의 모든 데이터를 중앙 집중식으로 저장하고, 분석 및 의사결정을 위해 가공하는 시스템입니다.

### 아키텍처

```
데이터 웨어하우스 시스템:

┌─────────────────────┐
│  다양한 소스들      │
├─────────────────────┤
│ - OLTP DB           │
│ - API, 3rd-party    │
│ - 로그 파일         │
│ - 센서 데이터       │
└──────────┬──────────┘
           │
     ┌─────▼─────┐
     │   ETL      │
     │ (추출,변환 │
     │  ,로드)    │
     └─────┬─────┘
           │
     ┌─────▼─────────────────┐
     │  데이터 웨어하우스    │
     │  (통합, 정제된 데이터)│
     └─────┬─────────────────┘
           │
   ┌───────┼───────┐
   │       │       │
┌──▼──┐ ┌──▼──┐ ┌──▼──┐
│BI   │ │분석 │ │탐색 │
│도구  │ │엔진 │ │도구 │
└─────┘ └─────┘ └─────┘
```

### 스타 스키마 (Star Schema)

데이터 웨어하우스의 가장 일반적인 설계 방식입니다.

#### 구조
```
              ┌─────────────┐
              │   일자      │
              │  Dimension  │
              ├─────────────┤
              │ date_id     │ (PK)
              │ year        │
              │ month       │
              │ day_of_week │
              │ is_holiday  │
              └────────┬────┘
                       │
    ┌──────────────────┼──────────────────┐
    │                  │                  │
┌───▼──────┐    ┌──────▼──────┐    ┌────▼────┐
│  상품    │    │  사실테이블 │    │  고객   │
│Dimension │    │   FACTS     │    │Dimension│
├──────────┤    ├─────────────┤    ├─────────┤
│product_id├───┐│product_id   │┌──┤customer_│
│name      │   ││customer_id  ││  │id       │
│category  │   ││date_id      ││  │name     │
│price     │   ││amount       ││  │age      │
│color     │   ││quantity     ││  │city     │
└──────────┘   ││discount     ││  │country  │
               └─────────────┘│  └─────────┘
                             │
                    ┌────────▼────────┐
                    │   지역          │
                    │  Dimension      │
                    ├─────────────────┤
                    │ region_id  (PK) │
                    │ region_name     │
                    │ country         │
                    │ continent       │
                    └─────────────────┘
```

#### 특징
- **사실 테이블 (Fact Table)**: 측정 가능한 데이터 (매출, 수량)
- **차원 테이블 (Dimension Table)**: 설명 데이터 (날짜, 상품, 고객)
- **비정규화**: 쿼리 성능을 위해 의도적으로 정규화 역행

#### 쿼리 예시
```sql
-- 월별 지역별 매출
SELECT 
    d.year,
    d.month,
    r.region_name,
    SUM(f.amount) as total_sales,
    SUM(f.quantity) as total_quantity
FROM facts f
JOIN date_dim d ON f.date_id = d.date_id
JOIN customer_dim c ON f.customer_id = c.customer_id
JOIN region_dim r ON c.region_id = r.region_id
WHERE d.year = 2024
GROUP BY d.year, d.month, r.region_name
ORDER BY d.month, total_sales DESC;
```

### 눈송이 스키마 (Snowflake Schema)

스타 스키마를 더 정규화한 형태입니다.

#### 구조
```
              ┌──────────────┐
              │     일자     │
              │  Dimension   │
              └──────┬───────┘
                     │
        ┌────────────┼────────────┐
        │            │            │
    ┌───▼─────┐ ┌────▼────┐ ┌───▼─────┐
    │ 상품    │ │ 사실    │ │ 고객    │
    │Dimension│ │ FACTS   │ │Dimension│
    └────┬────┘ └─────────┘ └────┬────┘
         │                       │
    ┌────▼─────┐          ┌──────▼──────┐
    │ 카테고리 │          │   지역      │
    │Dimension │          │ Dimension   │
    └──────────┘          └──────┬──────┘
                                 │
                          ┌──────▼──────┐
                          │   국가      │
                          │ Dimension   │
                          └─────────────┘
```

#### 스타 vs 눈송이 비교

| 특성 | 스타 스키마 | 눈송이 스키마 |
|------|-----------|------------|
| **정규화** | 낮음 | 높음 |
| **저장 공간** | 많음 | 적음 |
| **쿼리 성능** | 빠름 | 느림 |
| **복잡도** | 단순 | 복잡 |
| **조인 수** | 적음 | 많음 |

### ETL 프로세스

데이터 웨어하우스 구축의 핵심입니다.

#### Extract (추출)
```
소스 데이터 추출:
- OLTP 데이터베이스
- 외부 API
- 파일 (CSV, JSON, XML)
- 로그 스트림

추출 방식:
1. 전체 추출: 모든 데이터
2. 증분 추출: 변경된 데이터만 (타임스탬프 기반)
3. 변경 데이터 캡처 (CDC): 트랜잭션 로그 기반
```

#### Transform (변환)
```
데이터 정제 및 가공:
- 형식 변환 (타입 캐스팅)
- 결측치 처리
- 중복 제거
- 데이터 검증
- 데이터 농축 (참조 데이터 결합)
- 계산된 필드 추가

예시:
raw_date = "20240115"
→ Transform → date = 2024-01-15
→             year = 2024, month = 1, day = 15
```

#### Load (로드)
```
데이터 웨어하우스에 적재:
- 전체 로드: 초기 적재, 시간 소모
- 증분 로드: 정기적 업데이트
- 갱신 로드: 기존 데이터 덮어쓰기

방식:
1. 배치 로드: 정기적 (일 단위)
2. 스트림 로드: 실시간
3. 마이크로배치: 근실시간 (분 단위)
```

### 데이터 마트 (Data Mart)

데이터 웨어하우스의 부분 집합으로, 특정 부서나 팀의 분석 요구를 충족합니다.

```
데이터 웨어하우스 → 추출 → 데이터 마트
   (전사 통합)         (부서별 최적화)
                         │
            ┌────────┬───┼───┬────────┐
            │        │   │   │        │
        ┌───▼──┐ ┌──▼─┐│┌──▼──┐ ┌──▼──┐
        │ 영업 │ │마케│││재무  │ │ IT  │
        │마트  │ │팅  │││마트  │ │마트 │
        └──────┘ │마트││      │ └─────┘
                 └────┘└──────┘

각 마트의 특성:
- 작은 크기 (DW의 5-10%)
- 부서 맞춤 스키마
- 빠른 쿼리 성능
- 자체 ETL 프로세스
```

---

## 컬럼 지향 저장소

### 개념
컬럼 지향 저장소(Column-oriented storage)는 행 단위가 아닌 컬럼 단위로 데이터를 저장합니다. OLAP 워크로드에 최적화된 저장 방식입니다.

### 행 지향 vs 컬럼 지향

#### 행 지향 저장 (Row-oriented)

```
테이블: users
┌────┬───────┬──────────┬────────┬────────┐
│ id │ name  │ city     │ age    │ salary │
├────┼───────┼──────────┼────────┼────────┤
│ 1  │ Alice │ Seoul    │ 25     │ 50000  │
│ 2  │ Bob   │ Busan    │ 30     │ 60000  │
│ 3  │ Carol │ Seoul    │ 28     │ 55000  │
│ 4  │ David │ Daegu    │ 32     │ 70000  │
└────┴───────┴──────────┴────────┴────────┘

디스크 저장 (연속된 바이트):
[1][Alice][Seoul][25][50000]
[2][Bob][Busan][30][60000]
[3][Carol][Seoul][28][55000]
[4][David][Daegu][32][70000]
```

#### 컬럼 지향 저장 (Column-oriented)

```
디스크 저장 (컬럼별):
id 컬럼:      [1][2][3][4]
name 컬럼:    [Alice][Bob][Carol][David]
city 컬럼:    [Seoul][Busan][Seoul][Daegu]
age 컬럼:     [25][30][28][32]
salary 컬럼:  [50000][60000][55000][70000]
```

### 컬럼 지향 저장소의 장점

#### 1. 선택적 조회
```
쿼리: SELECT name, salary FROM users;

행 지향:
→ 모든 컬럼 읽기 필요
→ id, city, age도 함께 읽음 (낭비)

컬럼 지향:
→ name, salary 컬럼만 읽음
→ id, city, age는 읽지 않음 (효율)
```

#### 2. 압축 효율
컬럼의 값들이 동일하거나 유사한 경우가 많아 압축률이 높습니다.

```
city 컬럼 (행 지향):
[Seoul][Busan][Seoul][Daegu][Seoul][Seoul]...
메모리: 각 문자열 저장, 비효율

city 컬럼 (컬럼 지향 + 딕셔너리 인코딩):
값: Seoul(0), Busan(1), Daegu(2)
인덱스: [0][1][0][2][0][0]...
메모리: 매우 효율적

압축률 예시:
행 지향: 100MB
컬럼 지향: 10MB (10배 압축)
```

##### 딕셔너리 인코딩
```
원본:
┌────────────────────────────┐
│ region   │ region   │ region │
│ Seoul    │ Seoul    │ Busan  │
│ Seoul    │ Seoul    │ Seoul  │
└────────────────────────────┘

인코딩 후:
┌─────────────────┐    ┌────────────────────┐
│ 딕셔너리        │    │ 인덱스 배열        │
├─────────────────┤    ├────────────────────┤
│ Seoul  → 0      │    │ [0][0][1]          │
│ Busan  → 1      │    │ [0][0][0]          │
│ Daegu  → 2      │    │ ...                │
└─────────────────┘    └────────────────────┘

저장 크기:
- 행 지향: 30 bytes (Seoul 5*3, Busan 5)
- 컬럼 지향: 8 bytes (정수 배열) + 15 bytes (딕셔너리)
```

#### 3. 벡터화된 연산
CPU의 SIMD(Single Instruction Multiple Data) 명령어를 활용합니다.

```
집계 쿼리: SUM(salary)

행 지향:
result = 0
FOR i = 0 to n:
    result += get_field(row[i], 'salary')  // 개별 접근
    (CPU 캐시 미스 많음)

컬럼 지향:
result = 0
FOR i = 0 to n:
    result += salary_column[i]  // 연속된 메모리
    (CPU 캐시 히트 높음)
    (SIMD로 여러 값 동시 처리)
```

#### 4. 빠른 집계
그룹화와 집계 연산이 빠릅니다.

```
쿼리: SELECT city, COUNT(*), AVG(age) FROM users GROUP BY city;

행 지향:
→ 모든 행 스캔
→ 각 행에서 city, age 추출
→ 느림

컬럼 지향:
→ city 컬럼만 스캔
→ age 컬럼만 스캔
→ 메모리 효율적으로 그룹화
→ 빠름
```

### 컬럼 지향 저장소의 단점

#### 1. 쓰기 성능 저하
```
쿼리: INSERT INTO users VALUES (5, 'Eve', 'Incheon', 26, 52000);

행 지향:
→ 한 번에 한 행 추가
→ 빠름

컬럼 지향:
→ 각 컬럼 파일에 따로 추가
→ 5개 컬럼 = 5번의 쓰기
→ 느림
```

#### 2. 단일 행 조회 비효율
```
쿼리: SELECT * FROM users WHERE id = 3;

행 지향:
→ id=3인 행 하나 읽기
→ 빠름

컬럼 지향:
→ 모든 컬럼에서 row 3 찾기
→ 여러 번의 랜덤 접근
→ 느림
```

#### 3. 메모리 사용
여러 컬럼을 메모리에 올려야 할 때 증가합니다.

```
쿼리: SELECT id, name, city, age, salary FROM users;

컬럼 지향:
→ 5개 컬럼 모두 메모리 필요
→ 메모리 사용량 증가
```

### 컬럼 지향 저장소 구현 기법

#### 1. 패킹 및 압축
```
컬럼 저장소 구조:

┌─────────────────────────────┐
│ metadata                    │ (컬럼 타입, 압축 방식)
├─────────────────────────────┤
│ compressed data             │ (압축된 데이터)
├─────────────────────────────┤
│ secondary index             │ (빠른 조회)
├─────────────────────────────┤
│ Bloom filter                │ (존재 여부 확인)
└─────────────────────────────┘
```

#### 2. 벡터 메모리 레이아웃
```
salary 컬럼 메모리:
┌──────────────────────────────────┐
│ 50000 │ 60000 │ 55000 │ 70000 │  │
└──────────────────────────────────┘
 CPU 캐시 라인 (64 bytes)

- 순차 접근으로 캐시 히트율 높음
- SIMD 명령어 활용 가능
```

#### 3. 인덱싱
컬럼 지향 저장소의 인덱싱은 특별합니다.

```
비트맵 인덱스 예시:
city 컬럼: [Seoul][Busan][Seoul][Daegu][Seoul]

Seoul:  [1][0][1][0][1]
Busan:  [0][1][0][0][0]
Daegu:  [0][0][0][1][0]

쿼리: WHERE city IN ('Seoul', 'Daegu')
→ Seoul 비트맵 OR Daegu 비트맵
→ [1][0][1][1][1] (매우 빠름)
```

#### 4. 저장소 형식

##### Parquet (Apache)
```
특징:
- 스팍, 하이브에 최적화
- 자기 설명형 (스키마 포함)
- 블록 단위 압축
- 중첩 데이터 지원

구조:
파일 헤더 (4 bytes: "PAR1")
└─ Row Group 1
    ├─ Column 1 (id)
    │   └─ pages
    ├─ Column 2 (name)
    │   └─ pages
    ...
└─ Row Group 2
    ...
파일 푸터 (메타데이터)
```

##### ORC (Apache)
```
특징:
- 하이브 최적화
- Parquet보다 높은 압축률
- 스트라이프 기반 구조
- 생략된 인덱스 제공

구조:
파일 헤더
└─ Stripe 1 (여러 행 그룹)
    ├─ Column 1 데이터
    ├─ Column 2 데이터
    └─ 인덱스
└─ Stripe 2
    ...
```

### 컬럼 지향 데이터베이스

#### ClickHouse

**특징**:
- 러시아 Yandex에서 개발
- 실시간 분석에 최적화
- 매우 높은 압축률 (100-1000배)
- 사용하기 간단한 SQL

**성능 예시**:
```sql
쿼리: 10억 행 테이블에서 집계
SELECT COUNT(*) FROM events;

행 지향 DB: 30초
ClickHouse: 0.1초 (300배 빠름)

이유:
- 필요한 컬럼만 읽음
- 매우 높은 압축률 (I/O 감소)
- 벡터화된 연산
```

#### Redshift (AWS)

**특징**:
- AWS 기본 데이터 웨어하우스
- PostgreSQL 기반 (호환성)
- 분산 처리 (MPP)
- S3와 통합

**아키텍처**:
```
┌─────────────────────────┐
│  Leader Node            │ (쿼리 계획, 조율)
├─────────────────────────┤
│ Compute Node 1          │
│ (데이터 샤드 저장)      │
├─────────────────────────┤
│ Compute Node 2          │
│ (데이터 샤드 저장)      │
├─────────────────────────┤
│ ...                     │
└─────────────────────────┘
```

#### Snowflake

**특징**:
- 클라우드 네이티브 (AWS, Azure, GCP)
- 자동 스케일링
- 시간 여행 (과거 데이터 조회)
- SQL과 Python 통합

**가격 모델**:
```
비용 = 계산 비용 + 저장 비용

유연한 확장:
- 필요할 때만 리소스 사용
- 사용하지 않는 시간은 비용 없음
```

### 컬럼 지향 저장소 최적화 기법

#### 1. 파티셔닝
```
시계열 데이터의 경우:
파티션 1: 2024-01 데이터
파티션 2: 2024-02 데이터
파티션 3: 2024-03 데이터
...

쿼리: SELECT * FROM events WHERE date = '2024-02';
→ 파티션 2만 읽음 (다른 데이터 무시)
```

#### 2. 버킷팅
```
user_id로 버킷팅:
버킷 1: user_id % 10 == 0
버킷 2: user_id % 10 == 1
...
버킷 10: user_id % 10 == 9

조인 최적화:
- 같은 버킷의 테이블끼리만 조인
- 네트워크 전송 감소
```

#### 3. 정렬 순서
```
쿼리 패턴에 맞춘 정렬:
ORDER BY date, user_id, event_type

시간순 조회 최적화:
SELECT * WHERE date = '2024-01-15';
→ 연속된 블록에 존재
```

#### 4. 쿼리 재작성
```
비효율적:
SELECT * FROM large_table WHERE user_id IN (1,2,3,4,5);
(모든 컬럼 읽음)

효율적:
SELECT id, name, email FROM large_table WHERE user_id IN (1,2,3,4,5);
(필요한 컬럼만 읽음)
```

### 행 지향 vs 컬럼 지향 최종 비교

| 특성 | 행 지향 | 컬럼 지향 |
|------|--------|---------|
| **읽기 (부분 컬럼)** | 느림 | 빠름 ⭐ |
| **읽기 (전체 행)** | 빠름 ⭐ | 느림 |
| **쓰기** | 빠름 ⭐ | 느림 |
| **압축** | 낮음 | 높음 ⭐ |
| **메모리 효율** | 중간 | 높음 ⭐ |
| **OLTP** | 최적 ⭐ | 비효율 |
| **OLAP** | 비효율 | 최적 ⭐ |
| **구현 복잡도** | 단순 ⭐ | 복잡 |

---

## 결론

### 저장소 엔진 선택 가이드

#### OLTP 워크로드
- **작은 쓰기**: B트리 (MySQL, PostgreSQL)
- **큰 쓰기**: LSM 트리 (HBase, Cassandra)
- **메모리 기반**: Redis, Memcached

#### OLAP 워크로드
- **배치 분석**: 컬럼 지향 (Parquet, ORC)
- **실시간 분석**: ClickHouse, Redshift
- **클라우드**: Snowflake, BigQuery

### 최종 고려사항

1. **워크로드 특성 파악**
   - 읽기 vs 쓰기 비율
   - 데이터 크기
   - 응답 시간 요구사항

2. **인덱싱 전략**
   - 단일 컬럼: 해시 또는 B트리
   - 다중 컬럼: 연결 인덱스 또는 비트맵
   - 텍스트: 역 인덱스

3. **트레이드오프 인식**
   - 읽기 성능 vs 쓰기 성능
   - 메모리 vs 디스크
   - 복잡도 vs 기능성

4. **모니터링과 튜닝**
   - 쿼리 성능 분석
   - 인덱스 사용률 확인
   - 압축 효율 모니터링